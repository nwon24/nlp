{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nwon24/nlp/blob/main/W6/LSTM_WordEmbeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SNJn2LK1JFjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dWAcH6mWYxkE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "43445283-478d-4760-d2f7-bdcf2c7e68e2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m172\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │     \u001b[38;5;34m6,000,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m172\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │        \u001b[38;5;34m25,680\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m3440\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │         \u001b[38;5;34m3,441\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">172</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,000,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">172</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,680</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3440</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,441</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,029,121\u001b[0m (23.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,029,121</span> (23.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,029,121\u001b[0m (23.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,029,121</span> (23.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost: 0.692884, accuracy: 0.560000  [   50/45000]\n",
            "cost: 0.693603, accuracy: 0.480000  [  550/45000]\n",
            "cost: 0.702857, accuracy: 0.500000  [ 1050/45000]\n",
            "cost: 0.666839, accuracy: 0.560000  [ 1550/45000]\n",
            "cost: 0.623070, accuracy: 0.740000  [ 2050/45000]\n",
            "cost: 0.533550, accuracy: 0.740000  [ 2550/45000]\n",
            "cost: 0.543787, accuracy: 0.660000  [ 3050/45000]\n",
            "cost: 0.424928, accuracy: 0.860000  [ 3550/45000]\n",
            "cost: 0.507131, accuracy: 0.740000  [ 4050/45000]\n",
            "cost: 0.557867, accuracy: 0.720000  [ 4550/45000]\n",
            "cost: 0.385605, accuracy: 0.860000  [ 5050/45000]\n",
            "cost: 0.409285, accuracy: 0.820000  [ 5550/45000]\n",
            "cost: 0.445998, accuracy: 0.820000  [ 6050/45000]\n",
            "cost: 0.374773, accuracy: 0.820000  [ 6550/45000]\n",
            "cost: 0.371034, accuracy: 0.840000  [ 7050/45000]\n",
            "cost: 0.412651, accuracy: 0.780000  [ 7550/45000]\n",
            "cost: 0.343672, accuracy: 0.820000  [ 8050/45000]\n",
            "cost: 0.305243, accuracy: 0.920000  [ 8550/45000]\n",
            "cost: 0.427817, accuracy: 0.820000  [ 9050/45000]\n",
            "cost: 0.316411, accuracy: 0.900000  [ 9550/45000]\n",
            "cost: 0.529254, accuracy: 0.760000  [10050/45000]\n",
            "cost: 0.405806, accuracy: 0.840000  [10550/45000]\n",
            "cost: 0.469824, accuracy: 0.780000  [11050/45000]\n",
            "cost: 0.449353, accuracy: 0.780000  [11550/45000]\n",
            "cost: 0.443546, accuracy: 0.800000  [12050/45000]\n",
            "cost: 0.724675, accuracy: 0.700000  [12550/45000]\n",
            "cost: 0.313292, accuracy: 0.920000  [13050/45000]\n",
            "cost: 0.381223, accuracy: 0.840000  [13550/45000]\n",
            "cost: 0.460565, accuracy: 0.800000  [14050/45000]\n",
            "cost: 0.338292, accuracy: 0.920000  [14550/45000]\n",
            "cost: 0.423529, accuracy: 0.840000  [15050/45000]\n",
            "cost: 0.376005, accuracy: 0.880000  [15550/45000]\n",
            "cost: 0.462177, accuracy: 0.740000  [16050/45000]\n",
            "cost: 0.345108, accuracy: 0.820000  [16550/45000]\n",
            "cost: 0.442702, accuracy: 0.780000  [17050/45000]\n",
            "cost: 0.322623, accuracy: 0.880000  [17550/45000]\n",
            "cost: 0.435583, accuracy: 0.760000  [18050/45000]\n",
            "cost: 0.319984, accuracy: 0.880000  [18550/45000]\n",
            "cost: 0.337641, accuracy: 0.820000  [19050/45000]\n",
            "cost: 0.412533, accuracy: 0.800000  [19550/45000]\n",
            "cost: 0.423917, accuracy: 0.820000  [20050/45000]\n",
            "cost: 0.339253, accuracy: 0.800000  [20550/45000]\n",
            "cost: 0.291622, accuracy: 0.880000  [21050/45000]\n",
            "cost: 0.355079, accuracy: 0.880000  [21550/45000]\n",
            "cost: 0.275524, accuracy: 0.900000  [22050/45000]\n",
            "cost: 0.280638, accuracy: 0.920000  [22550/45000]\n",
            "cost: 0.427145, accuracy: 0.780000  [23050/45000]\n",
            "cost: 0.358029, accuracy: 0.900000  [23550/45000]\n",
            "cost: 0.342643, accuracy: 0.840000  [24050/45000]\n",
            "cost: 0.197860, accuracy: 0.920000  [24550/45000]\n",
            "cost: 0.420328, accuracy: 0.840000  [25050/45000]\n",
            "cost: 0.216465, accuracy: 0.940000  [25550/45000]\n",
            "cost: 0.403289, accuracy: 0.840000  [26050/45000]\n",
            "cost: 0.433092, accuracy: 0.840000  [26550/45000]\n",
            "cost: 0.344237, accuracy: 0.820000  [27050/45000]\n",
            "cost: 0.287454, accuracy: 0.860000  [27550/45000]\n",
            "cost: 0.245280, accuracy: 0.940000  [28050/45000]\n",
            "cost: 0.182551, accuracy: 0.920000  [28550/45000]\n",
            "cost: 0.231072, accuracy: 0.920000  [29050/45000]\n",
            "cost: 0.341154, accuracy: 0.860000  [29550/45000]\n",
            "cost: 0.239148, accuracy: 0.900000  [30050/45000]\n",
            "cost: 0.342490, accuracy: 0.880000  [30550/45000]\n",
            "cost: 0.297958, accuracy: 0.920000  [31050/45000]\n",
            "cost: 0.457871, accuracy: 0.820000  [31550/45000]\n",
            "cost: 0.258960, accuracy: 0.920000  [32050/45000]\n",
            "cost: 0.219491, accuracy: 0.920000  [32550/45000]\n",
            "cost: 0.182132, accuracy: 0.940000  [33050/45000]\n",
            "cost: 0.604230, accuracy: 0.760000  [33550/45000]\n",
            "cost: 0.397710, accuracy: 0.820000  [34050/45000]\n",
            "cost: 0.428723, accuracy: 0.860000  [34550/45000]\n",
            "cost: 0.266487, accuracy: 0.920000  [35050/45000]\n",
            "cost: 0.270494, accuracy: 0.900000  [35550/45000]\n",
            "cost: 0.281631, accuracy: 0.860000  [36050/45000]\n",
            "cost: 0.384517, accuracy: 0.820000  [36550/45000]\n",
            "cost: 0.368519, accuracy: 0.800000  [37050/45000]\n",
            "cost: 0.212814, accuracy: 0.920000  [37550/45000]\n",
            "cost: 0.306416, accuracy: 0.860000  [38050/45000]\n",
            "cost: 0.490752, accuracy: 0.820000  [38550/45000]\n",
            "cost: 0.135054, accuracy: 0.940000  [39050/45000]\n",
            "cost: 0.319322, accuracy: 0.900000  [39550/45000]\n",
            "cost: 0.235583, accuracy: 0.880000  [40050/45000]\n",
            "cost: 0.220456, accuracy: 0.940000  [40550/45000]\n",
            "cost: 0.368922, accuracy: 0.880000  [41050/45000]\n",
            "cost: 0.267781, accuracy: 0.840000  [41550/45000]\n",
            "cost: 0.187216, accuracy: 0.940000  [42050/45000]\n",
            "cost: 0.269770, accuracy: 0.900000  [42550/45000]\n",
            "cost: 0.385218, accuracy: 0.780000  [43050/45000]\n",
            "cost: 0.587687, accuracy: 0.800000  [43550/45000]\n",
            "cost: 0.243506, accuracy: 0.900000  [44050/45000]\n",
            "cost: 0.346905, accuracy: 0.880000  [44550/45000]\n",
            "cost: 0.283803, accuracy: 0.920000  [   50/45000]\n",
            "cost: 0.322130, accuracy: 0.860000  [  550/45000]\n",
            "cost: 0.277139, accuracy: 0.920000  [ 1050/45000]\n",
            "cost: 0.284767, accuracy: 0.880000  [ 1550/45000]\n",
            "cost: 0.272857, accuracy: 0.840000  [ 2050/45000]\n",
            "cost: 0.375102, accuracy: 0.820000  [ 2550/45000]\n",
            "cost: 0.232751, accuracy: 0.920000  [ 3050/45000]\n",
            "cost: 0.310445, accuracy: 0.800000  [ 3550/45000]\n",
            "cost: 0.173981, accuracy: 0.960000  [ 4050/45000]\n",
            "cost: 0.385177, accuracy: 0.820000  [ 4550/45000]\n",
            "cost: 0.401490, accuracy: 0.820000  [ 5050/45000]\n",
            "cost: 0.193036, accuracy: 0.900000  [ 5550/45000]\n",
            "cost: 0.241859, accuracy: 0.860000  [ 6050/45000]\n",
            "cost: 0.248682, accuracy: 0.880000  [ 6550/45000]\n",
            "cost: 0.262755, accuracy: 0.900000  [ 7050/45000]\n",
            "cost: 0.170123, accuracy: 0.940000  [ 7550/45000]\n",
            "cost: 0.308359, accuracy: 0.880000  [ 8050/45000]\n",
            "cost: 0.206920, accuracy: 0.920000  [ 8550/45000]\n",
            "cost: 0.267833, accuracy: 0.840000  [ 9050/45000]\n",
            "cost: 0.218925, accuracy: 0.860000  [ 9550/45000]\n",
            "cost: 0.525752, accuracy: 0.880000  [10050/45000]\n",
            "cost: 0.397688, accuracy: 0.820000  [10550/45000]\n",
            "cost: 0.293194, accuracy: 0.860000  [11050/45000]\n",
            "cost: 0.350422, accuracy: 0.840000  [11550/45000]\n",
            "cost: 0.230302, accuracy: 0.920000  [12050/45000]\n",
            "cost: 0.325580, accuracy: 0.860000  [12550/45000]\n",
            "cost: 0.248773, accuracy: 0.920000  [13050/45000]\n",
            "cost: 0.229377, accuracy: 0.880000  [13550/45000]\n",
            "cost: 0.210726, accuracy: 0.900000  [14050/45000]\n",
            "cost: 0.246613, accuracy: 0.900000  [14550/45000]\n",
            "cost: 0.209304, accuracy: 0.920000  [15050/45000]\n",
            "cost: 0.241732, accuracy: 0.920000  [15550/45000]\n",
            "cost: 0.121281, accuracy: 0.920000  [16050/45000]\n",
            "cost: 0.274175, accuracy: 0.860000  [16550/45000]\n",
            "cost: 0.247330, accuracy: 0.860000  [17050/45000]\n",
            "cost: 0.209232, accuracy: 0.920000  [17550/45000]\n",
            "cost: 0.226235, accuracy: 0.900000  [18050/45000]\n",
            "cost: 0.287105, accuracy: 0.840000  [18550/45000]\n",
            "cost: 0.188536, accuracy: 0.880000  [19050/45000]\n",
            "cost: 0.148657, accuracy: 0.960000  [19550/45000]\n",
            "cost: 0.224751, accuracy: 0.900000  [20050/45000]\n",
            "cost: 0.153205, accuracy: 0.920000  [20550/45000]\n",
            "cost: 0.381625, accuracy: 0.820000  [21050/45000]\n",
            "cost: 0.209858, accuracy: 0.880000  [21550/45000]\n",
            "cost: 0.188829, accuracy: 0.960000  [22050/45000]\n",
            "cost: 0.211660, accuracy: 0.900000  [22550/45000]\n",
            "cost: 0.212125, accuracy: 0.920000  [23050/45000]\n",
            "cost: 0.358964, accuracy: 0.860000  [23550/45000]\n",
            "cost: 0.318984, accuracy: 0.840000  [24050/45000]\n",
            "cost: 0.236384, accuracy: 0.900000  [24550/45000]\n",
            "cost: 0.425461, accuracy: 0.840000  [25050/45000]\n",
            "cost: 0.290965, accuracy: 0.920000  [25550/45000]\n",
            "cost: 0.230535, accuracy: 0.900000  [26050/45000]\n",
            "cost: 0.155567, accuracy: 0.940000  [26550/45000]\n",
            "cost: 0.283603, accuracy: 0.900000  [27050/45000]\n",
            "cost: 0.239285, accuracy: 0.920000  [27550/45000]\n",
            "cost: 0.298293, accuracy: 0.840000  [28050/45000]\n",
            "cost: 0.255974, accuracy: 0.880000  [28550/45000]\n",
            "cost: 0.204737, accuracy: 0.920000  [29050/45000]\n",
            "cost: 0.315271, accuracy: 0.840000  [29550/45000]\n",
            "cost: 0.172083, accuracy: 0.920000  [30050/45000]\n",
            "cost: 0.235186, accuracy: 0.880000  [30550/45000]\n",
            "cost: 0.184680, accuracy: 0.940000  [31050/45000]\n",
            "cost: 0.276984, accuracy: 0.860000  [31550/45000]\n",
            "cost: 0.130093, accuracy: 0.940000  [32050/45000]\n",
            "cost: 0.364705, accuracy: 0.820000  [32550/45000]\n",
            "cost: 0.306311, accuracy: 0.920000  [33050/45000]\n",
            "cost: 0.263837, accuracy: 0.900000  [33550/45000]\n",
            "cost: 0.321493, accuracy: 0.840000  [34050/45000]\n",
            "cost: 0.196026, accuracy: 0.900000  [34550/45000]\n",
            "cost: 0.156806, accuracy: 0.960000  [35050/45000]\n",
            "cost: 0.252481, accuracy: 0.900000  [35550/45000]\n",
            "cost: 0.409955, accuracy: 0.800000  [36050/45000]\n",
            "cost: 0.185155, accuracy: 0.920000  [36550/45000]\n",
            "cost: 0.170858, accuracy: 0.960000  [37050/45000]\n",
            "cost: 0.133152, accuracy: 0.960000  [37550/45000]\n",
            "cost: 0.214441, accuracy: 0.920000  [38050/45000]\n",
            "cost: 0.232487, accuracy: 0.880000  [38550/45000]\n",
            "cost: 0.222509, accuracy: 0.920000  [39050/45000]\n",
            "cost: 0.333923, accuracy: 0.840000  [39550/45000]\n",
            "cost: 0.504807, accuracy: 0.820000  [40050/45000]\n",
            "cost: 0.232053, accuracy: 0.900000  [40550/45000]\n",
            "cost: 0.341394, accuracy: 0.820000  [41050/45000]\n",
            "cost: 0.240772, accuracy: 0.900000  [41550/45000]\n",
            "cost: 0.232241, accuracy: 0.880000  [42050/45000]\n",
            "cost: 0.131691, accuracy: 0.980000  [42550/45000]\n",
            "cost: 0.387727, accuracy: 0.780000  [43050/45000]\n",
            "cost: 0.254351, accuracy: 0.920000  [43550/45000]\n",
            "cost: 0.278455, accuracy: 0.860000  [44050/45000]\n",
            "cost: 0.432487, accuracy: 0.840000  [44550/45000]\n",
            "cost: 0.171870, accuracy: 0.940000  [   50/45000]\n",
            "cost: 0.133033, accuracy: 0.960000  [  550/45000]\n",
            "cost: 0.188797, accuracy: 0.960000  [ 1050/45000]\n",
            "cost: 0.185994, accuracy: 0.920000  [ 1550/45000]\n",
            "cost: 0.114451, accuracy: 0.960000  [ 2050/45000]\n",
            "cost: 0.144883, accuracy: 0.940000  [ 2550/45000]\n",
            "cost: 0.126196, accuracy: 0.960000  [ 3050/45000]\n",
            "cost: 0.110880, accuracy: 0.940000  [ 3550/45000]\n",
            "cost: 0.324265, accuracy: 0.860000  [ 4050/45000]\n",
            "cost: 0.120476, accuracy: 0.940000  [ 4550/45000]\n",
            "cost: 0.213782, accuracy: 0.900000  [ 5050/45000]\n",
            "cost: 0.169059, accuracy: 0.920000  [ 5550/45000]\n",
            "cost: 0.160556, accuracy: 0.960000  [ 6050/45000]\n",
            "cost: 0.228272, accuracy: 0.960000  [ 6550/45000]\n",
            "cost: 0.211375, accuracy: 0.940000  [ 7050/45000]\n",
            "cost: 0.171692, accuracy: 0.920000  [ 7550/45000]\n",
            "cost: 0.311413, accuracy: 0.900000  [ 8050/45000]\n",
            "cost: 0.114616, accuracy: 0.940000  [ 8550/45000]\n",
            "cost: 0.176232, accuracy: 0.900000  [ 9050/45000]\n",
            "cost: 0.136067, accuracy: 0.960000  [ 9550/45000]\n",
            "cost: 0.176028, accuracy: 0.940000  [10050/45000]\n",
            "cost: 0.189677, accuracy: 0.920000  [10550/45000]\n",
            "cost: 0.115912, accuracy: 0.960000  [11050/45000]\n",
            "cost: 0.130224, accuracy: 0.960000  [11550/45000]\n",
            "cost: 0.206515, accuracy: 0.920000  [12050/45000]\n",
            "cost: 0.134566, accuracy: 0.960000  [12550/45000]\n",
            "cost: 0.212892, accuracy: 0.900000  [13050/45000]\n",
            "cost: 0.152718, accuracy: 0.940000  [13550/45000]\n",
            "cost: 0.228291, accuracy: 0.920000  [14050/45000]\n",
            "cost: 0.278329, accuracy: 0.920000  [14550/45000]\n",
            "cost: 0.088378, accuracy: 0.960000  [15050/45000]\n",
            "cost: 0.308893, accuracy: 0.880000  [15550/45000]\n",
            "cost: 0.284265, accuracy: 0.900000  [16050/45000]\n",
            "cost: 0.172270, accuracy: 0.960000  [16550/45000]\n",
            "cost: 0.202440, accuracy: 0.900000  [17050/45000]\n",
            "cost: 0.332997, accuracy: 0.880000  [17550/45000]\n",
            "cost: 0.134672, accuracy: 0.940000  [18050/45000]\n",
            "cost: 0.279846, accuracy: 0.900000  [18550/45000]\n",
            "cost: 0.154206, accuracy: 0.940000  [19050/45000]\n",
            "cost: 0.362266, accuracy: 0.940000  [19550/45000]\n",
            "cost: 0.209113, accuracy: 0.920000  [20050/45000]\n",
            "cost: 0.359836, accuracy: 0.900000  [20550/45000]\n",
            "cost: 0.149638, accuracy: 0.920000  [21050/45000]\n",
            "cost: 0.145795, accuracy: 0.980000  [21550/45000]\n",
            "cost: 0.206955, accuracy: 0.960000  [22050/45000]\n",
            "cost: 0.295675, accuracy: 0.820000  [22550/45000]\n",
            "cost: 0.246970, accuracy: 0.900000  [23050/45000]\n",
            "cost: 0.166716, accuracy: 0.940000  [23550/45000]\n",
            "cost: 0.125828, accuracy: 0.940000  [24050/45000]\n",
            "cost: 0.420692, accuracy: 0.780000  [24550/45000]\n",
            "cost: 0.126431, accuracy: 0.960000  [25050/45000]\n",
            "cost: 0.206955, accuracy: 0.940000  [25550/45000]\n",
            "cost: 0.167314, accuracy: 0.900000  [26050/45000]\n",
            "cost: 0.156813, accuracy: 0.920000  [26550/45000]\n",
            "cost: 0.283589, accuracy: 0.860000  [27050/45000]\n",
            "cost: 0.205326, accuracy: 0.920000  [27550/45000]\n",
            "cost: 0.185455, accuracy: 0.960000  [28050/45000]\n",
            "cost: 0.193595, accuracy: 0.960000  [28550/45000]\n",
            "cost: 0.260628, accuracy: 0.920000  [29050/45000]\n",
            "cost: 0.146424, accuracy: 0.940000  [29550/45000]\n",
            "cost: 0.215934, accuracy: 0.940000  [30050/45000]\n",
            "cost: 0.227451, accuracy: 0.880000  [30550/45000]\n",
            "cost: 0.184982, accuracy: 0.940000  [31050/45000]\n",
            "cost: 0.223959, accuracy: 0.880000  [31550/45000]\n",
            "cost: 0.150689, accuracy: 0.960000  [32050/45000]\n",
            "cost: 0.171757, accuracy: 0.920000  [32550/45000]\n",
            "cost: 0.189994, accuracy: 0.920000  [33050/45000]\n",
            "cost: 0.268098, accuracy: 0.880000  [33550/45000]\n",
            "cost: 0.238658, accuracy: 0.920000  [34050/45000]\n",
            "cost: 0.194912, accuracy: 0.900000  [34550/45000]\n",
            "cost: 0.197866, accuracy: 0.900000  [35050/45000]\n",
            "cost: 0.355173, accuracy: 0.860000  [35550/45000]\n",
            "cost: 0.285530, accuracy: 0.860000  [36050/45000]\n",
            "cost: 0.255983, accuracy: 0.860000  [36550/45000]\n",
            "cost: 0.114293, accuracy: 0.960000  [37050/45000]\n",
            "cost: 0.207154, accuracy: 0.920000  [37550/45000]\n",
            "cost: 0.247080, accuracy: 0.860000  [38050/45000]\n",
            "cost: 0.174079, accuracy: 0.940000  [38550/45000]\n",
            "cost: 0.202521, accuracy: 0.940000  [39050/45000]\n",
            "cost: 0.124269, accuracy: 0.960000  [39550/45000]\n",
            "cost: 0.136077, accuracy: 0.960000  [40050/45000]\n",
            "cost: 0.182808, accuracy: 0.880000  [40550/45000]\n",
            "cost: 0.267048, accuracy: 0.880000  [41050/45000]\n",
            "cost: 0.078820, accuracy: 1.000000  [41550/45000]\n",
            "cost: 0.209239, accuracy: 0.920000  [42050/45000]\n",
            "cost: 0.160390, accuracy: 0.960000  [42550/45000]\n",
            "cost: 0.232114, accuracy: 0.900000  [43050/45000]\n",
            "cost: 0.248331, accuracy: 0.860000  [43550/45000]\n",
            "cost: 0.261901, accuracy: 0.860000  [44050/45000]\n",
            "cost: 0.374130, accuracy: 0.840000  [44550/45000]\n",
            "cost: 0.160697, accuracy: 0.980000  [   50/45000]\n",
            "cost: 0.104561, accuracy: 0.960000  [  550/45000]\n",
            "cost: 0.079717, accuracy: 0.960000  [ 1050/45000]\n",
            "cost: 0.191420, accuracy: 0.920000  [ 1550/45000]\n",
            "cost: 0.136021, accuracy: 0.940000  [ 2050/45000]\n",
            "cost: 0.108214, accuracy: 0.940000  [ 2550/45000]\n",
            "cost: 0.116102, accuracy: 0.960000  [ 3050/45000]\n",
            "cost: 0.077514, accuracy: 0.980000  [ 3550/45000]\n",
            "cost: 0.134913, accuracy: 0.920000  [ 4050/45000]\n",
            "cost: 0.194635, accuracy: 0.940000  [ 4550/45000]\n",
            "cost: 0.106442, accuracy: 0.960000  [ 5050/45000]\n",
            "cost: 0.120420, accuracy: 0.940000  [ 5550/45000]\n",
            "cost: 0.292015, accuracy: 0.920000  [ 6050/45000]\n",
            "cost: 0.133511, accuracy: 0.920000  [ 6550/45000]\n",
            "cost: 0.217508, accuracy: 0.920000  [ 7050/45000]\n",
            "cost: 0.115308, accuracy: 0.980000  [ 7550/45000]\n",
            "cost: 0.121976, accuracy: 0.960000  [ 8050/45000]\n",
            "cost: 0.121961, accuracy: 0.960000  [ 8550/45000]\n",
            "cost: 0.135088, accuracy: 0.980000  [ 9050/45000]\n",
            "cost: 0.126067, accuracy: 0.920000  [ 9550/45000]\n",
            "cost: 0.125086, accuracy: 0.960000  [10050/45000]\n",
            "cost: 0.057776, accuracy: 1.000000  [10550/45000]\n",
            "cost: 0.277731, accuracy: 0.880000  [11050/45000]\n",
            "cost: 0.092788, accuracy: 0.940000  [11550/45000]\n",
            "cost: 0.095360, accuracy: 0.980000  [12050/45000]\n",
            "cost: 0.105848, accuracy: 0.940000  [12550/45000]\n",
            "cost: 0.147516, accuracy: 0.940000  [13050/45000]\n",
            "cost: 0.152162, accuracy: 0.960000  [13550/45000]\n",
            "cost: 0.182561, accuracy: 0.920000  [14050/45000]\n",
            "cost: 0.131459, accuracy: 0.980000  [14550/45000]\n",
            "cost: 0.090507, accuracy: 0.960000  [15050/45000]\n",
            "cost: 0.061480, accuracy: 0.980000  [15550/45000]\n",
            "cost: 0.143273, accuracy: 0.920000  [16050/45000]\n",
            "cost: 0.264562, accuracy: 0.900000  [16550/45000]\n",
            "cost: 0.262573, accuracy: 0.920000  [17050/45000]\n",
            "cost: 0.116642, accuracy: 0.960000  [17550/45000]\n",
            "cost: 0.078584, accuracy: 0.960000  [18050/45000]\n",
            "cost: 0.076472, accuracy: 0.980000  [18550/45000]\n",
            "cost: 0.237586, accuracy: 0.860000  [19050/45000]\n",
            "cost: 0.114676, accuracy: 0.960000  [19550/45000]\n",
            "cost: 0.109524, accuracy: 0.980000  [20050/45000]\n",
            "cost: 0.135272, accuracy: 0.960000  [20550/45000]\n",
            "cost: 0.068859, accuracy: 0.980000  [21050/45000]\n",
            "cost: 0.066848, accuracy: 1.000000  [21550/45000]\n",
            "cost: 0.114214, accuracy: 0.960000  [22050/45000]\n",
            "cost: 0.096945, accuracy: 0.980000  [22550/45000]\n",
            "cost: 0.222748, accuracy: 0.940000  [23050/45000]\n",
            "cost: 0.111166, accuracy: 0.940000  [23550/45000]\n",
            "cost: 0.119556, accuracy: 0.960000  [24050/45000]\n",
            "cost: 0.164423, accuracy: 0.920000  [24550/45000]\n",
            "cost: 0.241688, accuracy: 0.920000  [25050/45000]\n",
            "cost: 0.117100, accuracy: 0.960000  [25550/45000]\n",
            "cost: 0.110462, accuracy: 0.960000  [26050/45000]\n",
            "cost: 0.203062, accuracy: 0.940000  [26550/45000]\n",
            "cost: 0.180811, accuracy: 0.940000  [27050/45000]\n",
            "cost: 0.126679, accuracy: 0.940000  [27550/45000]\n",
            "cost: 0.113674, accuracy: 0.940000  [28050/45000]\n",
            "cost: 0.172588, accuracy: 0.940000  [28550/45000]\n",
            "cost: 0.139346, accuracy: 0.960000  [29050/45000]\n",
            "cost: 0.165106, accuracy: 0.920000  [29550/45000]\n",
            "cost: 0.172952, accuracy: 0.960000  [30050/45000]\n",
            "cost: 0.134230, accuracy: 0.960000  [30550/45000]\n",
            "cost: 0.145872, accuracy: 0.920000  [31050/45000]\n",
            "cost: 0.166975, accuracy: 0.920000  [31550/45000]\n",
            "cost: 0.236688, accuracy: 0.920000  [32050/45000]\n",
            "cost: 0.258766, accuracy: 0.860000  [32550/45000]\n",
            "cost: 0.195084, accuracy: 0.900000  [33050/45000]\n",
            "cost: 0.128868, accuracy: 0.960000  [33550/45000]\n",
            "cost: 0.169167, accuracy: 0.880000  [34050/45000]\n",
            "cost: 0.129011, accuracy: 0.960000  [34550/45000]\n",
            "cost: 0.094376, accuracy: 0.960000  [35050/45000]\n",
            "cost: 0.158198, accuracy: 0.940000  [35550/45000]\n",
            "cost: 0.092319, accuracy: 0.960000  [36050/45000]\n",
            "cost: 0.086594, accuracy: 0.960000  [36550/45000]\n",
            "cost: 0.188930, accuracy: 0.920000  [37050/45000]\n",
            "cost: 0.144345, accuracy: 0.920000  [37550/45000]\n",
            "cost: 0.104362, accuracy: 0.980000  [38050/45000]\n",
            "cost: 0.141847, accuracy: 0.940000  [38550/45000]\n",
            "cost: 0.109499, accuracy: 0.960000  [39050/45000]\n",
            "cost: 0.131057, accuracy: 0.940000  [39550/45000]\n",
            "cost: 0.058303, accuracy: 1.000000  [40050/45000]\n",
            "cost: 0.174600, accuracy: 0.940000  [40550/45000]\n",
            "cost: 0.030363, accuracy: 1.000000  [41050/45000]\n",
            "cost: 0.224092, accuracy: 0.880000  [41550/45000]\n",
            "cost: 0.112680, accuracy: 0.940000  [42050/45000]\n",
            "cost: 0.111375, accuracy: 0.960000  [42550/45000]\n",
            "cost: 0.198709, accuracy: 0.900000  [43050/45000]\n",
            "cost: 0.219156, accuracy: 0.880000  [43550/45000]\n",
            "cost: 0.121187, accuracy: 0.920000  [44050/45000]\n",
            "cost: 0.176560, accuracy: 0.900000  [44550/45000]\n",
            "cost: 0.108209, accuracy: 0.960000  [   50/45000]\n",
            "cost: 0.051400, accuracy: 0.960000  [  550/45000]\n",
            "cost: 0.093396, accuracy: 0.960000  [ 1050/45000]\n",
            "cost: 0.201342, accuracy: 0.920000  [ 1550/45000]\n",
            "cost: 0.179903, accuracy: 0.900000  [ 2050/45000]\n",
            "cost: 0.082076, accuracy: 0.980000  [ 2550/45000]\n",
            "cost: 0.060447, accuracy: 0.980000  [ 3050/45000]\n",
            "cost: 0.047569, accuracy: 0.980000  [ 3550/45000]\n",
            "cost: 0.137600, accuracy: 0.980000  [ 4050/45000]\n",
            "cost: 0.036927, accuracy: 1.000000  [ 4550/45000]\n",
            "cost: 0.131536, accuracy: 0.940000  [ 5050/45000]\n",
            "cost: 0.048880, accuracy: 0.980000  [ 5550/45000]\n",
            "cost: 0.038287, accuracy: 1.000000  [ 6050/45000]\n",
            "cost: 0.064624, accuracy: 0.980000  [ 6550/45000]\n",
            "cost: 0.038732, accuracy: 1.000000  [ 7050/45000]\n",
            "cost: 0.100231, accuracy: 0.940000  [ 7550/45000]\n",
            "cost: 0.015970, accuracy: 1.000000  [ 8050/45000]\n",
            "cost: 0.071685, accuracy: 0.980000  [ 8550/45000]\n",
            "cost: 0.055570, accuracy: 1.000000  [ 9050/45000]\n",
            "cost: 0.072470, accuracy: 0.980000  [ 9550/45000]\n",
            "cost: 0.034714, accuracy: 1.000000  [10050/45000]\n",
            "cost: 0.035409, accuracy: 1.000000  [10550/45000]\n",
            "cost: 0.133664, accuracy: 0.940000  [11050/45000]\n",
            "cost: 0.201873, accuracy: 0.940000  [11550/45000]\n",
            "cost: 0.055581, accuracy: 0.980000  [12050/45000]\n",
            "cost: 0.038251, accuracy: 0.980000  [12550/45000]\n",
            "cost: 0.069211, accuracy: 0.980000  [13050/45000]\n",
            "cost: 0.064973, accuracy: 0.980000  [13550/45000]\n",
            "cost: 0.059302, accuracy: 0.980000  [14050/45000]\n",
            "cost: 0.027159, accuracy: 1.000000  [14550/45000]\n",
            "cost: 0.062210, accuracy: 0.980000  [15050/45000]\n",
            "cost: 0.047568, accuracy: 1.000000  [15550/45000]\n",
            "cost: 0.196498, accuracy: 0.940000  [16050/45000]\n",
            "cost: 0.132113, accuracy: 0.940000  [16550/45000]\n",
            "cost: 0.061217, accuracy: 0.980000  [17050/45000]\n",
            "cost: 0.097695, accuracy: 0.960000  [17550/45000]\n",
            "cost: 0.066781, accuracy: 0.980000  [18050/45000]\n",
            "cost: 0.071667, accuracy: 0.980000  [18550/45000]\n",
            "cost: 0.065545, accuracy: 0.980000  [19050/45000]\n",
            "cost: 0.154088, accuracy: 0.940000  [19550/45000]\n",
            "cost: 0.126409, accuracy: 0.920000  [20050/45000]\n",
            "cost: 0.079051, accuracy: 0.960000  [20550/45000]\n",
            "cost: 0.043356, accuracy: 0.980000  [21050/45000]\n",
            "cost: 0.096275, accuracy: 0.980000  [21550/45000]\n",
            "cost: 0.042135, accuracy: 0.980000  [22050/45000]\n",
            "cost: 0.031452, accuracy: 1.000000  [22550/45000]\n",
            "cost: 0.062807, accuracy: 0.960000  [23050/45000]\n",
            "cost: 0.096233, accuracy: 0.980000  [23550/45000]\n",
            "cost: 0.229696, accuracy: 0.940000  [24050/45000]\n",
            "cost: 0.091080, accuracy: 0.980000  [24550/45000]\n",
            "cost: 0.077007, accuracy: 0.960000  [25050/45000]\n",
            "cost: 0.065399, accuracy: 0.980000  [25550/45000]\n",
            "cost: 0.077106, accuracy: 0.960000  [26050/45000]\n",
            "cost: 0.081466, accuracy: 0.960000  [26550/45000]\n",
            "cost: 0.207019, accuracy: 0.900000  [27050/45000]\n",
            "cost: 0.179152, accuracy: 0.880000  [27550/45000]\n",
            "cost: 0.135475, accuracy: 0.940000  [28050/45000]\n",
            "cost: 0.140814, accuracy: 0.940000  [28550/45000]\n",
            "cost: 0.081870, accuracy: 0.960000  [29050/45000]\n",
            "cost: 0.105446, accuracy: 0.960000  [29550/45000]\n",
            "cost: 0.101680, accuracy: 0.960000  [30050/45000]\n",
            "cost: 0.079111, accuracy: 0.960000  [30550/45000]\n",
            "cost: 0.093364, accuracy: 0.940000  [31050/45000]\n",
            "cost: 0.053773, accuracy: 0.980000  [31550/45000]\n",
            "cost: 0.109007, accuracy: 0.960000  [32050/45000]\n",
            "cost: 0.207241, accuracy: 0.980000  [32550/45000]\n",
            "cost: 0.056947, accuracy: 0.980000  [33050/45000]\n",
            "cost: 0.072254, accuracy: 0.960000  [33550/45000]\n",
            "cost: 0.038238, accuracy: 1.000000  [34050/45000]\n",
            "cost: 0.075959, accuracy: 0.960000  [34550/45000]\n",
            "cost: 0.057589, accuracy: 0.980000  [35050/45000]\n",
            "cost: 0.092295, accuracy: 0.960000  [35550/45000]\n",
            "cost: 0.084792, accuracy: 0.940000  [36050/45000]\n",
            "cost: 0.024192, accuracy: 1.000000  [36550/45000]\n",
            "cost: 0.064657, accuracy: 0.960000  [37050/45000]\n",
            "cost: 0.059209, accuracy: 1.000000  [37550/45000]\n",
            "cost: 0.072013, accuracy: 0.940000  [38050/45000]\n",
            "cost: 0.134804, accuracy: 0.920000  [38550/45000]\n",
            "cost: 0.121029, accuracy: 0.960000  [39050/45000]\n",
            "cost: 0.093258, accuracy: 0.940000  [39550/45000]\n",
            "cost: 0.166317, accuracy: 0.940000  [40050/45000]\n",
            "cost: 0.119027, accuracy: 0.940000  [40550/45000]\n",
            "cost: 0.080392, accuracy: 0.960000  [41050/45000]\n",
            "cost: 0.208056, accuracy: 0.920000  [41550/45000]\n",
            "cost: 0.070725, accuracy: 0.960000  [42050/45000]\n",
            "cost: 0.059267, accuracy: 0.960000  [42550/45000]\n",
            "cost: 0.109646, accuracy: 0.960000  [43050/45000]\n",
            "cost: 0.124954, accuracy: 0.960000  [43550/45000]\n",
            "cost: 0.111188, accuracy: 0.960000  [44050/45000]\n",
            "cost: 0.115904, accuracy: 0.960000  [44550/45000]\n",
            "cost: 0.043503, accuracy: 0.980000  [   50/45000]\n",
            "cost: 0.031775, accuracy: 1.000000  [  550/45000]\n",
            "cost: 0.020676, accuracy: 1.000000  [ 1050/45000]\n",
            "cost: 0.035169, accuracy: 0.980000  [ 1550/45000]\n",
            "cost: 0.007289, accuracy: 1.000000  [ 2050/45000]\n",
            "cost: 0.021734, accuracy: 1.000000  [ 2550/45000]\n",
            "cost: 0.017534, accuracy: 1.000000  [ 3050/45000]\n",
            "cost: 0.021140, accuracy: 1.000000  [ 3550/45000]\n",
            "cost: 0.042862, accuracy: 0.980000  [ 4050/45000]\n",
            "cost: 0.039624, accuracy: 1.000000  [ 4550/45000]\n",
            "cost: 0.039987, accuracy: 0.980000  [ 5050/45000]\n",
            "cost: 0.039376, accuracy: 0.980000  [ 5550/45000]\n",
            "cost: 0.035023, accuracy: 1.000000  [ 6050/45000]\n",
            "cost: 0.114568, accuracy: 0.940000  [ 6550/45000]\n",
            "cost: 0.036039, accuracy: 1.000000  [ 7050/45000]\n",
            "cost: 0.024855, accuracy: 1.000000  [ 7550/45000]\n",
            "cost: 0.023277, accuracy: 0.980000  [ 8050/45000]\n",
            "cost: 0.034950, accuracy: 0.980000  [ 8550/45000]\n",
            "cost: 0.067436, accuracy: 0.980000  [ 9050/45000]\n",
            "cost: 0.042249, accuracy: 0.980000  [ 9550/45000]\n",
            "cost: 0.166739, accuracy: 0.980000  [10050/45000]\n",
            "cost: 0.021293, accuracy: 1.000000  [10550/45000]\n",
            "cost: 0.085408, accuracy: 0.980000  [11050/45000]\n",
            "cost: 0.060525, accuracy: 0.980000  [11550/45000]\n",
            "cost: 0.051682, accuracy: 0.960000  [12050/45000]\n",
            "cost: 0.074569, accuracy: 0.980000  [12550/45000]\n",
            "cost: 0.051893, accuracy: 0.980000  [13050/45000]\n",
            "cost: 0.006698, accuracy: 1.000000  [13550/45000]\n",
            "cost: 0.053836, accuracy: 0.980000  [14050/45000]\n",
            "cost: 0.052810, accuracy: 0.960000  [14550/45000]\n",
            "cost: 0.083323, accuracy: 0.960000  [15050/45000]\n",
            "cost: 0.029674, accuracy: 0.980000  [15550/45000]\n",
            "cost: 0.010906, accuracy: 1.000000  [16050/45000]\n",
            "cost: 0.018771, accuracy: 0.980000  [16550/45000]\n",
            "cost: 0.013688, accuracy: 1.000000  [17050/45000]\n",
            "cost: 0.019696, accuracy: 1.000000  [17550/45000]\n",
            "cost: 0.068739, accuracy: 0.980000  [18050/45000]\n",
            "cost: 0.119663, accuracy: 0.920000  [18550/45000]\n",
            "cost: 0.051630, accuracy: 0.980000  [19050/45000]\n",
            "cost: 0.049317, accuracy: 0.980000  [19550/45000]\n",
            "cost: 0.049078, accuracy: 0.980000  [20050/45000]\n",
            "cost: 0.042672, accuracy: 0.980000  [20550/45000]\n",
            "cost: 0.016600, accuracy: 1.000000  [21050/45000]\n",
            "cost: 0.025531, accuracy: 1.000000  [21550/45000]\n",
            "cost: 0.014320, accuracy: 1.000000  [22050/45000]\n",
            "cost: 0.089783, accuracy: 0.960000  [22550/45000]\n",
            "cost: 0.043862, accuracy: 0.980000  [23050/45000]\n",
            "cost: 0.054416, accuracy: 0.960000  [23550/45000]\n",
            "cost: 0.029527, accuracy: 0.980000  [24050/45000]\n",
            "cost: 0.018072, accuracy: 1.000000  [24550/45000]\n",
            "cost: 0.038650, accuracy: 0.980000  [25050/45000]\n",
            "cost: 0.053926, accuracy: 0.980000  [25550/45000]\n",
            "cost: 0.026356, accuracy: 0.980000  [26050/45000]\n",
            "cost: 0.163044, accuracy: 0.940000  [26550/45000]\n",
            "cost: 0.018273, accuracy: 1.000000  [27050/45000]\n",
            "cost: 0.072491, accuracy: 0.980000  [27550/45000]\n",
            "cost: 0.045201, accuracy: 1.000000  [28050/45000]\n",
            "cost: 0.008792, accuracy: 1.000000  [28550/45000]\n",
            "cost: 0.049365, accuracy: 0.980000  [29050/45000]\n",
            "cost: 0.023899, accuracy: 0.980000  [29550/45000]\n",
            "cost: 0.048014, accuracy: 0.980000  [30050/45000]\n",
            "cost: 0.013869, accuracy: 1.000000  [30550/45000]\n",
            "cost: 0.109806, accuracy: 0.980000  [31050/45000]\n",
            "cost: 0.060424, accuracy: 0.980000  [31550/45000]\n",
            "cost: 0.141756, accuracy: 0.960000  [32050/45000]\n",
            "cost: 0.010757, accuracy: 1.000000  [32550/45000]\n",
            "cost: 0.019758, accuracy: 1.000000  [33050/45000]\n",
            "cost: 0.012469, accuracy: 1.000000  [33550/45000]\n",
            "cost: 0.016244, accuracy: 1.000000  [34050/45000]\n",
            "cost: 0.053583, accuracy: 0.980000  [34550/45000]\n",
            "cost: 0.101538, accuracy: 0.940000  [35050/45000]\n",
            "cost: 0.089799, accuracy: 0.960000  [35550/45000]\n",
            "cost: 0.117755, accuracy: 0.980000  [36050/45000]\n",
            "cost: 0.030710, accuracy: 0.980000  [36550/45000]\n",
            "cost: 0.024450, accuracy: 1.000000  [37050/45000]\n",
            "cost: 0.025666, accuracy: 1.000000  [37550/45000]\n",
            "cost: 0.076511, accuracy: 0.960000  [38050/45000]\n",
            "cost: 0.019391, accuracy: 1.000000  [38550/45000]\n",
            "cost: 0.042910, accuracy: 0.980000  [39050/45000]\n",
            "cost: 0.004882, accuracy: 1.000000  [39550/45000]\n",
            "cost: 0.062558, accuracy: 0.980000  [40050/45000]\n",
            "cost: 0.070984, accuracy: 0.980000  [40550/45000]\n",
            "cost: 0.057282, accuracy: 0.980000  [41050/45000]\n",
            "cost: 0.049873, accuracy: 0.980000  [41550/45000]\n",
            "cost: 0.061894, accuracy: 0.960000  [42050/45000]\n",
            "cost: 0.111991, accuracy: 0.960000  [42550/45000]\n",
            "cost: 0.013013, accuracy: 1.000000  [43050/45000]\n",
            "cost: 0.025638, accuracy: 1.000000  [43550/45000]\n",
            "cost: 0.041257, accuracy: 0.980000  [44050/45000]\n",
            "cost: 0.037055, accuracy: 0.980000  [44550/45000]\n",
            "cost: 0.014103, accuracy: 1.000000  [   50/45000]\n",
            "cost: 0.019360, accuracy: 1.000000  [  550/45000]\n",
            "cost: 0.008280, accuracy: 1.000000  [ 1050/45000]\n",
            "cost: 0.053390, accuracy: 0.960000  [ 1550/45000]\n",
            "cost: 0.008931, accuracy: 1.000000  [ 2050/45000]\n",
            "cost: 0.022848, accuracy: 1.000000  [ 2550/45000]\n",
            "cost: 0.047917, accuracy: 0.980000  [ 3050/45000]\n",
            "cost: 0.016949, accuracy: 1.000000  [ 3550/45000]\n",
            "cost: 0.003111, accuracy: 1.000000  [ 4050/45000]\n",
            "cost: 0.031746, accuracy: 0.980000  [ 4550/45000]\n",
            "cost: 0.007525, accuracy: 1.000000  [ 5050/45000]\n",
            "cost: 0.016216, accuracy: 1.000000  [ 5550/45000]\n",
            "cost: 0.129526, accuracy: 0.960000  [ 6050/45000]\n",
            "cost: 0.025840, accuracy: 1.000000  [ 6550/45000]\n",
            "cost: 0.012765, accuracy: 1.000000  [ 7050/45000]\n",
            "cost: 0.003058, accuracy: 1.000000  [ 7550/45000]\n",
            "cost: 0.004702, accuracy: 1.000000  [ 8050/45000]\n",
            "cost: 0.016554, accuracy: 1.000000  [ 8550/45000]\n",
            "cost: 0.004019, accuracy: 1.000000  [ 9050/45000]\n",
            "cost: 0.007147, accuracy: 1.000000  [ 9550/45000]\n",
            "cost: 0.018607, accuracy: 1.000000  [10050/45000]\n",
            "cost: 0.022937, accuracy: 0.980000  [10550/45000]\n",
            "cost: 0.024447, accuracy: 1.000000  [11050/45000]\n",
            "cost: 0.021274, accuracy: 1.000000  [11550/45000]\n",
            "cost: 0.029119, accuracy: 0.980000  [12050/45000]\n",
            "cost: 0.003295, accuracy: 1.000000  [12550/45000]\n",
            "cost: 0.018195, accuracy: 0.980000  [13050/45000]\n",
            "cost: 0.003780, accuracy: 1.000000  [13550/45000]\n",
            "cost: 0.014648, accuracy: 1.000000  [14050/45000]\n",
            "cost: 0.021784, accuracy: 0.980000  [14550/45000]\n",
            "cost: 0.024414, accuracy: 0.980000  [15050/45000]\n",
            "cost: 0.008443, accuracy: 1.000000  [15550/45000]\n",
            "cost: 0.134168, accuracy: 0.960000  [16050/45000]\n",
            "cost: 0.005778, accuracy: 1.000000  [16550/45000]\n",
            "cost: 0.032901, accuracy: 0.980000  [17050/45000]\n",
            "cost: 0.002486, accuracy: 1.000000  [17550/45000]\n",
            "cost: 0.038013, accuracy: 0.980000  [18050/45000]\n",
            "cost: 0.010076, accuracy: 1.000000  [18550/45000]\n",
            "cost: 0.004177, accuracy: 1.000000  [19050/45000]\n",
            "cost: 0.028537, accuracy: 0.980000  [19550/45000]\n",
            "cost: 0.040635, accuracy: 0.980000  [20050/45000]\n",
            "cost: 0.018311, accuracy: 1.000000  [20550/45000]\n",
            "cost: 0.007276, accuracy: 1.000000  [21050/45000]\n",
            "cost: 0.006032, accuracy: 1.000000  [21550/45000]\n",
            "cost: 0.020633, accuracy: 1.000000  [22050/45000]\n",
            "cost: 0.017482, accuracy: 1.000000  [22550/45000]\n",
            "cost: 0.033177, accuracy: 0.980000  [23050/45000]\n",
            "cost: 0.040231, accuracy: 0.960000  [23550/45000]\n",
            "cost: 0.013519, accuracy: 1.000000  [24050/45000]\n",
            "cost: 0.005428, accuracy: 1.000000  [24550/45000]\n",
            "cost: 0.010975, accuracy: 1.000000  [25050/45000]\n",
            "cost: 0.063101, accuracy: 0.980000  [25550/45000]\n",
            "cost: 0.043023, accuracy: 0.980000  [26050/45000]\n",
            "cost: 0.014944, accuracy: 1.000000  [26550/45000]\n",
            "cost: 0.032421, accuracy: 0.980000  [27050/45000]\n",
            "cost: 0.036968, accuracy: 0.980000  [27550/45000]\n",
            "cost: 0.003120, accuracy: 1.000000  [28050/45000]\n",
            "cost: 0.010345, accuracy: 1.000000  [28550/45000]\n",
            "cost: 0.013144, accuracy: 1.000000  [29050/45000]\n",
            "cost: 0.001913, accuracy: 1.000000  [29550/45000]\n",
            "cost: 0.066512, accuracy: 0.980000  [30050/45000]\n",
            "cost: 0.010680, accuracy: 1.000000  [30550/45000]\n",
            "cost: 0.008486, accuracy: 1.000000  [31050/45000]\n",
            "cost: 0.004986, accuracy: 1.000000  [31550/45000]\n",
            "cost: 0.007038, accuracy: 1.000000  [32050/45000]\n",
            "cost: 0.002807, accuracy: 1.000000  [32550/45000]\n",
            "cost: 0.016425, accuracy: 1.000000  [33050/45000]\n",
            "cost: 0.027079, accuracy: 1.000000  [33550/45000]\n",
            "cost: 0.020190, accuracy: 1.000000  [34050/45000]\n",
            "cost: 0.013418, accuracy: 1.000000  [34550/45000]\n",
            "cost: 0.019745, accuracy: 1.000000  [35050/45000]\n",
            "cost: 0.021524, accuracy: 1.000000  [35550/45000]\n",
            "cost: 0.004384, accuracy: 1.000000  [36050/45000]\n",
            "cost: 0.027060, accuracy: 1.000000  [36550/45000]\n",
            "cost: 0.039040, accuracy: 0.980000  [37050/45000]\n",
            "cost: 0.174830, accuracy: 0.940000  [37550/45000]\n",
            "cost: 0.090627, accuracy: 0.980000  [38050/45000]\n",
            "cost: 0.042604, accuracy: 0.980000  [38550/45000]\n",
            "cost: 0.036650, accuracy: 1.000000  [39050/45000]\n",
            "cost: 0.051779, accuracy: 0.980000  [39550/45000]\n",
            "cost: 0.030571, accuracy: 0.980000  [40050/45000]\n",
            "cost: 0.016265, accuracy: 1.000000  [40550/45000]\n",
            "cost: 0.005638, accuracy: 1.000000  [41050/45000]\n",
            "cost: 0.009699, accuracy: 1.000000  [41550/45000]\n",
            "cost: 0.041796, accuracy: 0.980000  [42050/45000]\n",
            "cost: 0.056095, accuracy: 0.960000  [42550/45000]\n",
            "cost: 0.011526, accuracy: 1.000000  [43050/45000]\n",
            "cost: 0.025121, accuracy: 1.000000  [43550/45000]\n",
            "cost: 0.054709, accuracy: 0.960000  [44050/45000]\n",
            "cost: 0.052684, accuracy: 0.960000  [44550/45000]\n",
            "cost: 0.053514, accuracy: 0.980000  [   50/45000]\n",
            "cost: 0.023251, accuracy: 1.000000  [  550/45000]\n",
            "cost: 0.011980, accuracy: 1.000000  [ 1050/45000]\n",
            "cost: 0.009850, accuracy: 1.000000  [ 1550/45000]\n",
            "cost: 0.010130, accuracy: 1.000000  [ 2050/45000]\n",
            "cost: 0.010136, accuracy: 1.000000  [ 2550/45000]\n",
            "cost: 0.007949, accuracy: 1.000000  [ 3050/45000]\n",
            "cost: 0.002170, accuracy: 1.000000  [ 3550/45000]\n",
            "cost: 0.003367, accuracy: 1.000000  [ 4050/45000]\n",
            "cost: 0.002301, accuracy: 1.000000  [ 4550/45000]\n",
            "cost: 0.006168, accuracy: 1.000000  [ 5050/45000]\n",
            "cost: 0.001802, accuracy: 1.000000  [ 5550/45000]\n",
            "cost: 0.007478, accuracy: 1.000000  [ 6050/45000]\n",
            "cost: 0.040836, accuracy: 0.980000  [ 6550/45000]\n",
            "cost: 0.030614, accuracy: 0.980000  [ 7050/45000]\n",
            "cost: 0.014750, accuracy: 1.000000  [ 7550/45000]\n",
            "cost: 0.004656, accuracy: 1.000000  [ 8050/45000]\n",
            "cost: 0.005171, accuracy: 1.000000  [ 8550/45000]\n",
            "cost: 0.031086, accuracy: 0.980000  [ 9050/45000]\n",
            "cost: 0.001126, accuracy: 1.000000  [ 9550/45000]\n",
            "cost: 0.003575, accuracy: 1.000000  [10050/45000]\n",
            "cost: 0.009371, accuracy: 1.000000  [10550/45000]\n",
            "cost: 0.006540, accuracy: 1.000000  [11050/45000]\n",
            "cost: 0.020344, accuracy: 0.980000  [11550/45000]\n",
            "cost: 0.021254, accuracy: 1.000000  [12050/45000]\n",
            "cost: 0.023621, accuracy: 0.980000  [12550/45000]\n",
            "cost: 0.001885, accuracy: 1.000000  [13050/45000]\n",
            "cost: 0.030109, accuracy: 0.980000  [13550/45000]\n",
            "cost: 0.000874, accuracy: 1.000000  [14050/45000]\n",
            "cost: 0.010036, accuracy: 1.000000  [14550/45000]\n",
            "cost: 0.004877, accuracy: 1.000000  [15050/45000]\n",
            "cost: 0.007094, accuracy: 1.000000  [15550/45000]\n",
            "cost: 0.005727, accuracy: 1.000000  [16050/45000]\n",
            "cost: 0.019421, accuracy: 1.000000  [16550/45000]\n",
            "cost: 0.001438, accuracy: 1.000000  [17050/45000]\n",
            "cost: 0.023067, accuracy: 0.980000  [17550/45000]\n",
            "cost: 0.032727, accuracy: 1.000000  [18050/45000]\n",
            "cost: 0.014818, accuracy: 1.000000  [18550/45000]\n",
            "cost: 0.001738, accuracy: 1.000000  [19050/45000]\n",
            "cost: 0.000911, accuracy: 1.000000  [19550/45000]\n",
            "cost: 0.023398, accuracy: 0.980000  [20050/45000]\n",
            "cost: 0.002313, accuracy: 1.000000  [20550/45000]\n",
            "cost: 0.047957, accuracy: 0.980000  [21050/45000]\n",
            "cost: 0.005831, accuracy: 1.000000  [21550/45000]\n",
            "cost: 0.001222, accuracy: 1.000000  [22050/45000]\n",
            "cost: 0.033701, accuracy: 0.980000  [22550/45000]\n",
            "cost: 0.043202, accuracy: 0.980000  [23050/45000]\n",
            "cost: 0.027654, accuracy: 0.980000  [23550/45000]\n",
            "cost: 0.003052, accuracy: 1.000000  [24050/45000]\n",
            "cost: 0.035379, accuracy: 0.980000  [24550/45000]\n",
            "cost: 0.010989, accuracy: 1.000000  [25050/45000]\n",
            "cost: 0.008033, accuracy: 1.000000  [25550/45000]\n",
            "cost: 0.029493, accuracy: 0.980000  [26050/45000]\n",
            "cost: 0.018628, accuracy: 1.000000  [26550/45000]\n",
            "cost: 0.006854, accuracy: 1.000000  [27050/45000]\n",
            "cost: 0.010789, accuracy: 1.000000  [27550/45000]\n",
            "cost: 0.039589, accuracy: 0.980000  [28050/45000]\n",
            "cost: 0.002507, accuracy: 1.000000  [28550/45000]\n",
            "cost: 0.005682, accuracy: 1.000000  [29050/45000]\n",
            "cost: 0.006266, accuracy: 1.000000  [29550/45000]\n",
            "cost: 0.004066, accuracy: 1.000000  [30050/45000]\n",
            "cost: 0.064368, accuracy: 0.980000  [30550/45000]\n",
            "cost: 0.012308, accuracy: 1.000000  [31050/45000]\n",
            "cost: 0.020487, accuracy: 1.000000  [31550/45000]\n",
            "cost: 0.004799, accuracy: 1.000000  [32050/45000]\n",
            "cost: 0.007533, accuracy: 1.000000  [32550/45000]\n",
            "cost: 0.008018, accuracy: 1.000000  [33050/45000]\n",
            "cost: 0.009796, accuracy: 1.000000  [33550/45000]\n",
            "cost: 0.052852, accuracy: 0.960000  [34050/45000]\n",
            "cost: 0.024961, accuracy: 0.980000  [34550/45000]\n",
            "cost: 0.010789, accuracy: 1.000000  [35050/45000]\n",
            "cost: 0.010425, accuracy: 1.000000  [35550/45000]\n",
            "cost: 0.082255, accuracy: 0.980000  [36050/45000]\n",
            "cost: 0.003901, accuracy: 1.000000  [36550/45000]\n",
            "cost: 0.063528, accuracy: 0.980000  [37050/45000]\n",
            "cost: 0.010889, accuracy: 1.000000  [37550/45000]\n",
            "cost: 0.040444, accuracy: 0.980000  [38050/45000]\n",
            "cost: 0.040193, accuracy: 0.980000  [38550/45000]\n",
            "cost: 0.014636, accuracy: 1.000000  [39050/45000]\n",
            "cost: 0.003203, accuracy: 1.000000  [39550/45000]\n",
            "cost: 0.001029, accuracy: 1.000000  [40050/45000]\n",
            "cost: 0.000225, accuracy: 1.000000  [40550/45000]\n",
            "cost: 0.017891, accuracy: 1.000000  [41050/45000]\n",
            "cost: 0.050780, accuracy: 0.980000  [41550/45000]\n",
            "cost: 0.054583, accuracy: 0.960000  [42050/45000]\n",
            "cost: 0.098252, accuracy: 0.960000  [42550/45000]\n",
            "cost: 0.008470, accuracy: 1.000000  [43050/45000]\n",
            "cost: 0.025787, accuracy: 1.000000  [43550/45000]\n",
            "cost: 0.025916, accuracy: 0.980000  [44050/45000]\n",
            "cost: 0.005643, accuracy: 1.000000  [44550/45000]\n",
            "cost: 0.006865, accuracy: 1.000000  [   50/45000]\n",
            "cost: 0.016950, accuracy: 1.000000  [  550/45000]\n",
            "cost: 0.004825, accuracy: 1.000000  [ 1050/45000]\n",
            "cost: 0.008406, accuracy: 1.000000  [ 1550/45000]\n",
            "cost: 0.002200, accuracy: 1.000000  [ 2050/45000]\n",
            "cost: 0.002764, accuracy: 1.000000  [ 2550/45000]\n",
            "cost: 0.017764, accuracy: 0.980000  [ 3050/45000]\n",
            "cost: 0.005383, accuracy: 1.000000  [ 3550/45000]\n",
            "cost: 0.010426, accuracy: 1.000000  [ 4050/45000]\n",
            "cost: 0.003309, accuracy: 1.000000  [ 4550/45000]\n",
            "cost: 0.014459, accuracy: 1.000000  [ 5050/45000]\n",
            "cost: 0.003250, accuracy: 1.000000  [ 5550/45000]\n",
            "cost: 0.001231, accuracy: 1.000000  [ 6050/45000]\n",
            "cost: 0.005205, accuracy: 1.000000  [ 6550/45000]\n",
            "cost: 0.001207, accuracy: 1.000000  [ 7050/45000]\n",
            "cost: 0.001428, accuracy: 1.000000  [ 7550/45000]\n",
            "cost: 0.005863, accuracy: 1.000000  [ 8050/45000]\n",
            "cost: 0.000317, accuracy: 1.000000  [ 8550/45000]\n",
            "cost: 0.002069, accuracy: 1.000000  [ 9050/45000]\n",
            "cost: 0.004967, accuracy: 1.000000  [ 9550/45000]\n",
            "cost: 0.017779, accuracy: 1.000000  [10050/45000]\n",
            "cost: 0.011372, accuracy: 1.000000  [10550/45000]\n",
            "cost: 0.003014, accuracy: 1.000000  [11050/45000]\n",
            "cost: 0.018365, accuracy: 0.980000  [11550/45000]\n",
            "cost: 0.076025, accuracy: 0.980000  [12050/45000]\n",
            "cost: 0.000566, accuracy: 1.000000  [12550/45000]\n",
            "cost: 0.001291, accuracy: 1.000000  [13050/45000]\n",
            "cost: 0.063397, accuracy: 0.980000  [13550/45000]\n",
            "cost: 0.009889, accuracy: 1.000000  [14050/45000]\n",
            "cost: 0.037030, accuracy: 0.980000  [14550/45000]\n",
            "cost: 0.001522, accuracy: 1.000000  [15050/45000]\n",
            "cost: 0.006639, accuracy: 1.000000  [15550/45000]\n",
            "cost: 0.002064, accuracy: 1.000000  [16050/45000]\n",
            "cost: 0.003249, accuracy: 1.000000  [16550/45000]\n",
            "cost: 0.027897, accuracy: 0.980000  [17050/45000]\n",
            "cost: 0.004020, accuracy: 1.000000  [17550/45000]\n",
            "cost: 0.005839, accuracy: 1.000000  [18050/45000]\n",
            "cost: 0.006284, accuracy: 1.000000  [18550/45000]\n",
            "cost: 0.006502, accuracy: 1.000000  [19050/45000]\n",
            "cost: 0.002500, accuracy: 1.000000  [19550/45000]\n",
            "cost: 0.135574, accuracy: 0.960000  [20050/45000]\n",
            "cost: 0.030817, accuracy: 0.980000  [20550/45000]\n",
            "cost: 0.005931, accuracy: 1.000000  [21050/45000]\n",
            "cost: 0.004778, accuracy: 1.000000  [21550/45000]\n",
            "cost: 0.017411, accuracy: 1.000000  [22050/45000]\n",
            "cost: 0.002989, accuracy: 1.000000  [22550/45000]\n",
            "cost: 0.001584, accuracy: 1.000000  [23050/45000]\n",
            "cost: 0.004675, accuracy: 1.000000  [23550/45000]\n",
            "cost: 0.042198, accuracy: 0.980000  [24050/45000]\n",
            "cost: 0.009199, accuracy: 1.000000  [24550/45000]\n",
            "cost: 0.015425, accuracy: 1.000000  [25050/45000]\n",
            "cost: 0.013821, accuracy: 1.000000  [25550/45000]\n",
            "cost: 0.003405, accuracy: 1.000000  [26050/45000]\n",
            "cost: 0.004158, accuracy: 1.000000  [26550/45000]\n",
            "cost: 0.009609, accuracy: 1.000000  [27050/45000]\n",
            "cost: 0.029890, accuracy: 0.980000  [27550/45000]\n",
            "cost: 0.101518, accuracy: 0.980000  [28050/45000]\n",
            "cost: 0.000237, accuracy: 1.000000  [28550/45000]\n",
            "cost: 0.005592, accuracy: 1.000000  [29050/45000]\n",
            "cost: 0.003176, accuracy: 1.000000  [29550/45000]\n",
            "cost: 0.002395, accuracy: 1.000000  [30050/45000]\n",
            "cost: 0.000153, accuracy: 1.000000  [30550/45000]\n",
            "cost: 0.003526, accuracy: 1.000000  [31050/45000]\n",
            "cost: 0.002617, accuracy: 1.000000  [31550/45000]\n",
            "cost: 0.010780, accuracy: 1.000000  [32050/45000]\n",
            "cost: 0.051313, accuracy: 0.980000  [32550/45000]\n",
            "cost: 0.005187, accuracy: 1.000000  [33050/45000]\n",
            "cost: 0.008099, accuracy: 1.000000  [33550/45000]\n",
            "cost: 0.030372, accuracy: 0.980000  [34050/45000]\n",
            "cost: 0.006981, accuracy: 1.000000  [34550/45000]\n",
            "cost: 0.002225, accuracy: 1.000000  [35050/45000]\n",
            "cost: 0.001227, accuracy: 1.000000  [35550/45000]\n",
            "cost: 0.005546, accuracy: 1.000000  [36050/45000]\n",
            "cost: 0.008031, accuracy: 1.000000  [36550/45000]\n",
            "cost: 0.095402, accuracy: 0.980000  [37050/45000]\n",
            "cost: 0.003620, accuracy: 1.000000  [37550/45000]\n",
            "cost: 0.007024, accuracy: 1.000000  [38050/45000]\n",
            "cost: 0.007019, accuracy: 1.000000  [38550/45000]\n",
            "cost: 0.005342, accuracy: 1.000000  [39050/45000]\n",
            "cost: 0.008386, accuracy: 1.000000  [39550/45000]\n",
            "cost: 0.001749, accuracy: 1.000000  [40050/45000]\n",
            "cost: 0.013583, accuracy: 1.000000  [40550/45000]\n",
            "cost: 0.010084, accuracy: 1.000000  [41050/45000]\n",
            "cost: 0.007483, accuracy: 1.000000  [41550/45000]\n",
            "cost: 0.014806, accuracy: 1.000000  [42050/45000]\n",
            "cost: 0.041591, accuracy: 0.980000  [42550/45000]\n",
            "cost: 0.010930, accuracy: 1.000000  [43050/45000]\n",
            "cost: 0.008838, accuracy: 1.000000  [43550/45000]\n",
            "cost: 0.014847, accuracy: 1.000000  [44050/45000]\n",
            "cost: 0.044009, accuracy: 0.980000  [44550/45000]\n",
            "cost: 0.000938, accuracy: 1.000000  [   50/45000]\n",
            "cost: 0.005235, accuracy: 1.000000  [  550/45000]\n",
            "cost: 0.000103, accuracy: 1.000000  [ 1050/45000]\n",
            "cost: 0.009151, accuracy: 1.000000  [ 1550/45000]\n",
            "cost: 0.004536, accuracy: 1.000000  [ 2050/45000]\n",
            "cost: 0.005109, accuracy: 1.000000  [ 2550/45000]\n",
            "cost: 0.003784, accuracy: 1.000000  [ 3050/45000]\n",
            "cost: 0.008237, accuracy: 1.000000  [ 3550/45000]\n",
            "cost: 0.000870, accuracy: 1.000000  [ 4050/45000]\n",
            "cost: 0.003789, accuracy: 1.000000  [ 4550/45000]\n",
            "cost: 0.000504, accuracy: 1.000000  [ 5050/45000]\n",
            "cost: 0.003253, accuracy: 1.000000  [ 5550/45000]\n",
            "cost: 0.000302, accuracy: 1.000000  [ 6050/45000]\n",
            "cost: 0.004181, accuracy: 1.000000  [ 6550/45000]\n",
            "cost: 0.013116, accuracy: 1.000000  [ 7050/45000]\n",
            "cost: 0.000795, accuracy: 1.000000  [ 7550/45000]\n",
            "cost: 0.006059, accuracy: 1.000000  [ 8050/45000]\n",
            "cost: 0.003519, accuracy: 1.000000  [ 8550/45000]\n",
            "cost: 0.001834, accuracy: 1.000000  [ 9050/45000]\n",
            "cost: 0.006789, accuracy: 1.000000  [ 9550/45000]\n",
            "cost: 0.017980, accuracy: 0.980000  [10050/45000]\n",
            "cost: 0.001020, accuracy: 1.000000  [10550/45000]\n",
            "cost: 0.000840, accuracy: 1.000000  [11050/45000]\n",
            "cost: 0.002387, accuracy: 1.000000  [11550/45000]\n",
            "cost: 0.004601, accuracy: 1.000000  [12050/45000]\n",
            "cost: 0.002962, accuracy: 1.000000  [12550/45000]\n",
            "cost: 0.004794, accuracy: 1.000000  [13050/45000]\n",
            "cost: 0.001072, accuracy: 1.000000  [13550/45000]\n",
            "cost: 0.002104, accuracy: 1.000000  [14050/45000]\n",
            "cost: 0.009199, accuracy: 1.000000  [14550/45000]\n",
            "cost: 0.011777, accuracy: 1.000000  [15050/45000]\n",
            "cost: 0.000801, accuracy: 1.000000  [15550/45000]\n",
            "cost: 0.007257, accuracy: 1.000000  [16050/45000]\n",
            "cost: 0.002227, accuracy: 1.000000  [16550/45000]\n",
            "cost: 0.002021, accuracy: 1.000000  [17050/45000]\n",
            "cost: 0.002172, accuracy: 1.000000  [17550/45000]\n",
            "cost: 0.003610, accuracy: 1.000000  [18050/45000]\n",
            "cost: 0.052459, accuracy: 0.980000  [18550/45000]\n",
            "cost: 0.000869, accuracy: 1.000000  [19050/45000]\n",
            "cost: 0.006408, accuracy: 1.000000  [19550/45000]\n",
            "cost: 0.005122, accuracy: 1.000000  [20050/45000]\n",
            "cost: 0.004040, accuracy: 1.000000  [20550/45000]\n",
            "cost: 0.000559, accuracy: 1.000000  [21050/45000]\n",
            "cost: 0.007095, accuracy: 1.000000  [21550/45000]\n",
            "cost: 0.003913, accuracy: 1.000000  [22050/45000]\n",
            "cost: 0.000667, accuracy: 1.000000  [22550/45000]\n",
            "cost: 0.001031, accuracy: 1.000000  [23050/45000]\n",
            "cost: 0.001169, accuracy: 1.000000  [23550/45000]\n",
            "cost: 0.017628, accuracy: 0.980000  [24050/45000]\n",
            "cost: 0.005664, accuracy: 1.000000  [24550/45000]\n",
            "cost: 0.003158, accuracy: 1.000000  [25050/45000]\n",
            "cost: 0.000808, accuracy: 1.000000  [25550/45000]\n",
            "cost: 0.059223, accuracy: 0.980000  [26050/45000]\n",
            "cost: 0.005135, accuracy: 1.000000  [26550/45000]\n",
            "cost: 0.036285, accuracy: 0.980000  [27050/45000]\n",
            "cost: 0.004018, accuracy: 1.000000  [27550/45000]\n",
            "cost: 0.001114, accuracy: 1.000000  [28050/45000]\n",
            "cost: 0.010737, accuracy: 1.000000  [28550/45000]\n",
            "cost: 0.000489, accuracy: 1.000000  [29050/45000]\n",
            "cost: 0.001681, accuracy: 1.000000  [29550/45000]\n",
            "cost: 0.002332, accuracy: 1.000000  [30050/45000]\n",
            "cost: 0.004749, accuracy: 1.000000  [30550/45000]\n",
            "cost: 0.005243, accuracy: 1.000000  [31050/45000]\n",
            "cost: 0.001095, accuracy: 1.000000  [31550/45000]\n",
            "cost: 0.001892, accuracy: 1.000000  [32050/45000]\n",
            "cost: 0.004237, accuracy: 1.000000  [32550/45000]\n",
            "cost: 0.007571, accuracy: 1.000000  [33050/45000]\n",
            "cost: 0.002500, accuracy: 1.000000  [33550/45000]\n",
            "cost: 0.017977, accuracy: 0.980000  [34050/45000]\n",
            "cost: 0.000274, accuracy: 1.000000  [34550/45000]\n",
            "cost: 0.000581, accuracy: 1.000000  [35050/45000]\n",
            "cost: 0.003216, accuracy: 1.000000  [35550/45000]\n",
            "cost: 0.002226, accuracy: 1.000000  [36050/45000]\n",
            "cost: 0.003596, accuracy: 1.000000  [36550/45000]\n",
            "cost: 0.000204, accuracy: 1.000000  [37050/45000]\n",
            "cost: 0.003356, accuracy: 1.000000  [37550/45000]\n",
            "cost: 0.002423, accuracy: 1.000000  [38050/45000]\n",
            "cost: 0.011109, accuracy: 1.000000  [38550/45000]\n",
            "cost: 0.055370, accuracy: 0.960000  [39050/45000]\n",
            "cost: 0.032510, accuracy: 0.980000  [39550/45000]\n",
            "cost: 0.032592, accuracy: 0.980000  [40050/45000]\n",
            "cost: 0.002542, accuracy: 1.000000  [40550/45000]\n",
            "cost: 0.029262, accuracy: 0.980000  [41050/45000]\n",
            "cost: 0.001488, accuracy: 1.000000  [41550/45000]\n",
            "cost: 0.007641, accuracy: 1.000000  [42050/45000]\n",
            "cost: 0.001890, accuracy: 1.000000  [42550/45000]\n",
            "cost: 0.005645, accuracy: 1.000000  [43050/45000]\n",
            "cost: 0.006203, accuracy: 1.000000  [43550/45000]\n",
            "cost: 0.000501, accuracy: 1.000000  [44050/45000]\n",
            "cost: 0.017123, accuracy: 1.000000  [44550/45000]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy: 86.48, best accuracy: 88.82\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import InputLayer\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn import model_selection\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "device=torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "\n",
        "data=pd.read_csv(\"xaa\",encoding=\"utf-8\")\n",
        "\n",
        "word2vec_model = KeyedVectors.load_word2vec_format(\"drive/MyDrive/Colab Notebooks/GoogleNews-vectors-negative300.bin.gz\", binary=True, limit=20000)\n",
        "#print(word2vec_model.get_index(\"the\"))\n",
        "vect  = CountVectorizer(stop_words=\"english\",max_df=0.7)\n",
        "#corpus = vect.fit_transform(data[\"text\"])\n",
        "#train_corpus, test_corpus, train_label, test_label = model_selection.train_test_split(data[\"text\"],data[\"label\"],test_size=0.4)\n",
        "#Encoder = LabelEncoder()\n",
        "#train_label = Encoder.fit_transform(train_label)\n",
        "#test_label = Encoder.fit_transform(test_label)\n",
        "#train_corpus_vect=vect.transform(train_corpus)\n",
        "#test_corpus_vect=vect.transform(test_corpus)\n",
        "\n",
        "# Initalise vect.vocabulary_\n",
        "vect.fit_transform(data[\"text\"])\n",
        "\n",
        "maxlen=0\n",
        "\n",
        "def transform(text,vect):\n",
        "    global maxlen\n",
        "    global word2vec_model\n",
        "    #d=vect.vocabulary_\n",
        "    d=word2vec_model\n",
        "    p=vect.build_preprocessor()\n",
        "    t=vect.build_tokenizer()\n",
        "    vec_list=[]\n",
        "    for doc in text:\n",
        "        tokens=t(p(doc))\n",
        "        doc_vec=np.array([d.get_index(token) for token in tokens if token in d])\n",
        "        s=len(doc_vec)\n",
        "        if s>maxlen:\n",
        "            maxlen=s\n",
        "        #doc_vec=sequence.pad_sequences(doc_vec,maxlen=maxlen)\n",
        "        vec_list.append(doc_vec)\n",
        "    vec_list=sequence.pad_sequences(vec_list,maxlen=maxlen,padding=\"post\")\n",
        "    corpus_vec=np.vstack(vec_list)\n",
        "    #return nn.functional.normalize(torch.tensor(corpus_vec).float())\n",
        "    return torch.tensor(corpus_vec)\n",
        "    #return torch.tensor(corpus_vec).float()\n",
        "\n",
        "# print(corpus_vec)\n",
        "\n",
        "bsize=50\n",
        "epochs=10\n",
        "lr=5e-4\n",
        "embed_dim=300\n",
        "\n",
        "class corpus(Dataset):\n",
        "    def __init__(self,corpus,label,seq):\n",
        "        self.corpus=corpus\n",
        "        self.label=label\n",
        "        self.seq=seq\n",
        "    def __len__(self):\n",
        "        return len(self.corpus)\n",
        "    def __getitem__(self,idx):\n",
        "        return self.corpus[idx],self.label[idx]\n",
        "\n",
        "class lstm(nn.Module):\n",
        "    def __init__(self,input_size,hidden_size,seq):\n",
        "        super(lstm,self).__init__()\n",
        "        self.input_size=input_size\n",
        "        self.hidden_size=hidden_size\n",
        "        self.seq=seq\n",
        "        self.rnn=True\n",
        "        self.lstm=nn.LSTM(input_size,hidden_size,batch_first=True,num_layers=1)\n",
        "        self.fc=nn.Linear(self.hidden_size*seq,1)\n",
        "        #self.fc=nn.Linear(self.hidden_size,1)\n",
        "        #self.embed=nn.Embedding(len(vect.vocabulary_),input_size)\n",
        "        self.embed=nn.Embedding.from_pretrained(torch.from_numpy(word2vec_model.vectors),freeze=False)\n",
        "\n",
        "    def forward(self,x,h0=None,c0=None):\n",
        "        x=self.embed(x)\n",
        "        if h0==None and c0==None:\n",
        "            x, (hn,cn) = self.lstm(x)\n",
        "        else:\n",
        "            x, (hn,cn) = self.lstm(x,(h0,c0))\n",
        "        #print(x[:,-1,:].shape)\n",
        "        #x = torch.flatten(x[:,-1,:],1)\n",
        "        # Flatten like this so that all information from previous time steps is fed into fully connected layer\n",
        "        x=torch.flatten(x,1)\n",
        "        x = self.fc(x)\n",
        "        return nn.Sigmoid()(x), hn,cn\n",
        "        #return nn.Softmax()(x), hn,cn\n",
        "\n",
        "class dense(nn.Module):\n",
        "    def __init__(self,seq,vocab,embed_dim):\n",
        "        super(dense,self).__init__()\n",
        "        self.seq=seq\n",
        "        self.rnn=False\n",
        "        self.network=nn.Sequential(\n",
        "            nn.Linear(embed_dim*seq,360),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(360,180),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(180,1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.embed=nn.Embedding(vocab,embed_dim)\n",
        "\n",
        "    def forward(self,x):\n",
        "        #print(x.shape)\n",
        "        x=self.embed(x)\n",
        "        x=torch.flatten(x,1)\n",
        "        #x=torch.transpose(x,1,2)\n",
        "        #x=torch.flatten(x,1)\n",
        "        return self.network(x)\n",
        "\n",
        "vocab=len(vect.vocabulary_)\n",
        "Encoder = LabelEncoder()\n",
        "corpus_vec = transform(data[\"text\"],vect)\n",
        "train_corpus_vec, test_corpus_vec, train_label, test_label = model_selection.train_test_split(corpus_vec,data[\"label\"],test_size=0.1)\n",
        "train_label = torch.from_numpy(Encoder.fit_transform(train_label)).float()\n",
        "test_label = torch.from_numpy(Encoder.fit_transform(test_label)).float()\n",
        "#train_corpus_vec = transform(train_corpus,vect)\n",
        "#test_corpus_vec = transform(test_corpus,vect)\n",
        "lstm_classifier=lstm(embed_dim,200,maxlen)\n",
        "loss_fn=nn.BCELoss()\n",
        "#loss_fn=nn.BCEWithLogitsLoss()\n",
        "#loss_fn=nn.MSELoss()\n",
        "optimizer=torch.optim.Adam(lstm_classifier.parameters(),lr=lr)\n",
        "#optimizer=torch.optim.SGD(lstm_classifier.parameters(),lr=lr)\n",
        "#print(len(lstm_classifier(torch.reshape(train_corpus_vec[0],(bsize,maxlen,1)))))\n",
        "\n",
        "dense_classifier=dense(maxlen,vocab,16)\n",
        "\n",
        "c=lstm_classifier\n",
        "\n",
        "c=c.to(device)\n",
        "\n",
        "train_dataloader=DataLoader(corpus(train_corpus_vec,train_label,maxlen),batch_size=bsize,shuffle=True)\n",
        "test_dataloader=DataLoader(corpus(test_corpus_vec,test_label,maxlen),batch_size=bsize,shuffle=True)\n",
        "\n",
        "def train(dataloader,model,loss_fn,optimizer):\n",
        "    hn,cn=None,None\n",
        "    size=len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch,(x,y) in enumerate(dataloader):\n",
        "        x,y=x.to(device),y.to(device)\n",
        "        #print(torch.sum(x[0]!=0))\n",
        "        if model.rnn==True:\n",
        "            #pred,hn,cn=model(x.reshape(bsize,dataloader.dataset.seq,1).to(device),hn,cn)\n",
        "            pred,hn,cn=model(x,hn,cn)\n",
        "        else:\n",
        "            pred=model(x)\n",
        "        #pred=model(x)\n",
        "        cost=loss_fn(pred.flatten(),y)\n",
        "        cost.backward()\n",
        "        #if model.rnn==True:\n",
        "        #    print(model.lstm.weight_ih_l0.grad[0][0])\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if model.rnn==True:\n",
        "            hn=hn.detach()\n",
        "            cn=cn.detach()\n",
        "        if batch % 10 == 0:\n",
        "            cost_val, current = cost.item(), batch * bsize + len(x)\n",
        "            print(f\"cost: {cost_val:>7f}, accuracy: {(torch.round(pred.flatten())==y).sum().item()/bsize:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x,y=x.to(device),y.to(device)\n",
        "            if model.rnn==True:\n",
        "                #pred,_,_=model(x.reshape(bsize,dataloader.dataset.seq,1).to(device))\n",
        "                pred,_,_=model(x)\n",
        "            else:\n",
        "                pred=model(x)\n",
        "            #pred=model(x)\n",
        "            #print(torch.round(pred.flatten()),y)\n",
        "            test_loss += loss_fn(pred.flatten(), y).item()\n",
        "            ncorrect = (torch.round(pred.flatten()) == y).sum().item()\n",
        "            #print(ncorrect)\n",
        "            correct += ncorrect\n",
        "\n",
        "    #print(correct,size)\n",
        "    #print(f\"Test Error: \\n Accuracy: {(100*correct/size):>0.1f}%, Avg loss: {100*test_loss/size:>8f} \\n\")\n",
        "    return 100*correct/size\n",
        "\n",
        "#keras_model=Sequential([InputLayer(input_shape=(maxlen,),batch_size=bsize),\n",
        "#                        Embedding(len(vect.vocabulary_),16),\n",
        "#                  Flatten(),\n",
        "#                  Dense(1,activation=\"sigmoid\")])\n",
        "keras_model=Sequential([InputLayer(shape=(maxlen,),batch_size=bsize),\n",
        "                        Embedding(len(word2vec_model),embed_dim),\n",
        "                        LSTM(20,return_sequences=True),\n",
        "                  Flatten(),\n",
        "                  Dense(1,activation=\"sigmoid\")])\n",
        "keras_model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "keras_model.summary()\n",
        "\n",
        "use_torch=True\n",
        "\n",
        "x=np.arange(epochs)\n",
        "y=np.zeros(epochs)\n",
        "#print(corpus_vec[0])\n",
        "if use_torch==True:\n",
        "    for epoch in range(epochs):\n",
        "        train(train_dataloader,c,loss_fn,optimizer)\n",
        "        y[epoch] = test_loop(test_dataloader,c,loss_fn)\n",
        "    plt.plot(x,y)\n",
        "    plt.show()\n",
        "    print(f\"Final accuracy: {y[-1]:.2f}, best accuracy: {y[np.argmax(y)]:.2f}\")\n",
        "else:\n",
        "    keras_model.fit(train_corpus_vec,train_label,batch_size=bsize,epochs=epochs,validation_data=(test_corpus_vec,test_label))\n",
        "    keras_model.evaluate(test_corpus_vec,test_label,batch_size=bsize)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "cy5ekCL0mHOK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "outputId": "e39f3001-2f32-4ce6-fab0-09c8942b7283"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              },
              "id": "582aa023f51e442fa9099689695ad27f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vx6v266o_lK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(word2vec_model))\n",
        "word2vec_model[\"horse\"]"
      ],
      "metadata": {
        "id": "0EdHfJkrFBpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a61279-c917-4845-f223-6b7729de06f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.34057617e-04,  3.11279297e-02,  5.03540039e-03, -9.17968750e-02,\n",
              "       -8.36181641e-03, -1.66015625e-01,  3.93066406e-02,  2.97851562e-02,\n",
              "        1.69921875e-01, -2.04101562e-01,  2.41210938e-01, -3.04687500e-01,\n",
              "       -2.24609375e-02, -3.71093750e-01, -5.61523438e-02,  1.51367188e-01,\n",
              "       -1.21582031e-01,  3.41796875e-01,  3.05175781e-02, -2.94921875e-01,\n",
              "        6.54296875e-02, -9.27734375e-02,  1.49414062e-01,  8.15429688e-02,\n",
              "       -6.93359375e-02,  1.98242188e-01, -1.66015625e-01,  2.00195312e-01,\n",
              "        1.16699219e-01, -3.69140625e-01, -2.48046875e-01,  1.25976562e-01,\n",
              "        3.59375000e-01,  1.51367188e-01, -7.76367188e-02,  2.91015625e-01,\n",
              "       -1.74560547e-02, -1.21093750e-01, -1.00097656e-01,  1.43554688e-01,\n",
              "        5.92041016e-03,  2.35595703e-02,  3.20312500e-01,  1.82617188e-01,\n",
              "        9.52148438e-02,  9.22851562e-02,  8.30078125e-02, -1.33789062e-01,\n",
              "        9.57031250e-02,  1.66992188e-01,  1.87988281e-02, -2.79541016e-02,\n",
              "       -1.03149414e-02,  1.11816406e-01, -8.10546875e-02,  1.79687500e-01,\n",
              "        8.34960938e-02, -5.90820312e-02,  1.70898438e-01,  1.68457031e-02,\n",
              "        8.74023438e-02,  9.03320312e-02,  9.22851562e-02, -9.76562500e-02,\n",
              "       -2.39257812e-02, -2.07031250e-01, -1.21459961e-02,  1.44531250e-01,\n",
              "        6.20117188e-02, -1.44042969e-02,  2.81250000e-01,  6.83593750e-02,\n",
              "       -2.12890625e-01,  4.68750000e-02, -1.00097656e-01, -1.35742188e-01,\n",
              "        7.47070312e-02, -2.69531250e-01,  7.56835938e-02, -5.51757812e-02,\n",
              "       -2.01416016e-02, -3.80859375e-01,  1.67968750e-01, -3.90625000e-01,\n",
              "        5.54199219e-02,  2.23632812e-01, -6.28662109e-03,  7.76367188e-02,\n",
              "        2.03125000e-01, -1.04980469e-01, -3.12500000e-02,  3.53515625e-01,\n",
              "        1.54296875e-01, -1.25976562e-01, -2.24609375e-02, -3.80859375e-01,\n",
              "        3.12500000e-01,  2.12890625e-01,  1.97265625e-01, -4.49218750e-01,\n",
              "       -9.22851562e-02, -2.94921875e-01,  2.21679688e-01, -2.58789062e-02,\n",
              "        1.38671875e-01,  7.37304688e-02, -1.10839844e-01, -3.00781250e-01,\n",
              "        1.29882812e-01, -1.74804688e-01,  1.37939453e-02,  7.51953125e-02,\n",
              "        2.98828125e-01, -7.61718750e-02,  9.76562500e-02, -2.53906250e-01,\n",
              "       -8.69140625e-02, -9.86328125e-02, -4.49218750e-02,  1.00585938e-01,\n",
              "       -1.68945312e-01,  1.06933594e-01, -1.07910156e-01, -3.57421875e-01,\n",
              "       -3.58886719e-02, -3.24707031e-02,  1.62109375e-01, -1.17187500e-01,\n",
              "       -1.49414062e-01,  2.31933594e-02, -4.14062500e-01,  2.85644531e-02,\n",
              "       -2.57812500e-01, -6.59179688e-02, -4.80957031e-02, -1.87500000e-01,\n",
              "        5.10253906e-02,  7.86132812e-02, -7.56835938e-02,  3.20312500e-01,\n",
              "        7.08007812e-02, -1.08886719e-01, -3.03955078e-02,  1.53320312e-01,\n",
              "        8.93554688e-02,  8.83789062e-02, -2.01416016e-02, -1.66992188e-01,\n",
              "       -8.88671875e-02,  7.20214844e-03,  4.88281250e-01,  7.66601562e-02,\n",
              "        6.68945312e-02, -4.34570312e-02, -2.41210938e-01, -9.71679688e-02,\n",
              "        7.47070312e-02, -3.24218750e-01, -3.14453125e-01, -8.74023438e-02,\n",
              "       -8.20312500e-02,  2.33154297e-02,  2.55859375e-01, -1.06445312e-01,\n",
              "        1.13769531e-01, -4.71191406e-02, -4.83398438e-02, -4.31640625e-01,\n",
              "        3.41796875e-02,  1.66015625e-02, -6.00585938e-02, -1.82617188e-01,\n",
              "       -3.56445312e-02, -8.59375000e-02, -5.88378906e-02,  1.19628906e-01,\n",
              "        1.33789062e-01, -3.73535156e-02, -1.79687500e-01,  8.59375000e-02,\n",
              "       -2.63671875e-01, -3.36914062e-02, -2.22167969e-02,  9.52148438e-02,\n",
              "        1.05468750e-01, -1.63085938e-01,  2.65625000e-01,  1.77734375e-01,\n",
              "       -2.37304688e-01,  1.58203125e-01, -4.00390625e-02, -5.71289062e-02,\n",
              "        1.51367188e-01,  1.52343750e-01,  2.71484375e-01, -2.13867188e-01,\n",
              "        1.81884766e-02, -4.98046875e-02, -2.65625000e-01, -1.05468750e-01,\n",
              "        4.98046875e-02, -5.54687500e-01, -2.91015625e-01, -9.61914062e-02,\n",
              "       -9.52148438e-02, -4.17480469e-02, -2.57812500e-01, -6.25000000e-02,\n",
              "        9.37500000e-02, -2.09960938e-02, -2.48046875e-01,  4.51660156e-02,\n",
              "        1.56250000e-01, -1.74804688e-01, -1.37695312e-01,  1.54296875e-01,\n",
              "       -3.94531250e-01, -1.66992188e-01,  2.07031250e-01,  1.55273438e-01,\n",
              "        2.08984375e-01,  2.69531250e-01,  3.26171875e-01, -1.24023438e-01,\n",
              "        1.64794922e-02, -5.05371094e-02,  3.10546875e-01, -3.24707031e-02,\n",
              "        3.41796875e-01, -9.96093750e-02,  4.15039062e-02, -3.06640625e-01,\n",
              "        4.83398438e-02,  2.08007812e-01, -4.10156250e-01, -7.22656250e-02,\n",
              "        1.09863281e-01, -2.67578125e-01,  2.28515625e-01, -1.02050781e-01,\n",
              "        1.83593750e-01, -2.44140625e-01,  2.21679688e-01,  2.01171875e-01,\n",
              "        3.10546875e-01, -2.14843750e-01, -3.41796875e-02,  2.57812500e-01,\n",
              "        2.53906250e-02,  7.66601562e-02, -1.18164062e-01,  2.41210938e-01,\n",
              "       -9.61914062e-02, -1.16699219e-01, -8.34960938e-02,  2.37304688e-01,\n",
              "       -1.10839844e-01,  6.73828125e-02, -4.35546875e-01, -3.32641602e-03,\n",
              "       -1.27929688e-01, -6.53076172e-03,  2.72216797e-02,  2.83203125e-01,\n",
              "       -4.19921875e-02,  8.00781250e-02,  1.12792969e-01, -2.73437500e-01,\n",
              "       -2.63671875e-01,  2.04101562e-01, -8.54492188e-02,  1.91497803e-03,\n",
              "       -2.04101562e-01,  6.83593750e-02, -6.54296875e-02, -1.35742188e-01,\n",
              "       -2.57568359e-02, -3.96484375e-01, -2.94189453e-02,  4.33593750e-01,\n",
              "        6.03027344e-02,  3.41796875e-03,  1.74804688e-01,  6.44531250e-02,\n",
              "       -3.97949219e-02, -7.32421875e-02, -1.50390625e-01,  2.56347656e-02,\n",
              "        2.91015625e-01,  2.61718750e-01, -2.32421875e-01,  1.13769531e-01,\n",
              "       -2.53906250e-01,  1.75781250e-01,  1.89453125e-01,  2.65625000e-01,\n",
              "        1.66015625e-01,  2.85156250e-01, -1.63085938e-01,  6.07910156e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Md7zxWTk9AhSbKVVPH3m-w-W4QP5_WDX",
      "authorship_tag": "ABX9TyM+JR1E1fkNtoxneNd0icqZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}