{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nwon24/nlp/blob/main/W6/LSTM_WordEmbeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "dWAcH6mWYxkE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c9356e00-9495-4a5e-d046-3b4da1d3f264"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_36\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_36\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_36 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m172\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │     \u001b[38;5;34m6,000,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_36 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m172\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │        \u001b[38;5;34m25,680\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_36 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m3440\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │         \u001b[38;5;34m3,441\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">172</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,000,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">172</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,680</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3440</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,441</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,029,121\u001b[0m (23.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,029,121</span> (23.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,029,121\u001b[0m (23.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,029,121</span> (23.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost: 0.692998, accuracy: 0.540000  [   50/22500]\n",
            "cost: 0.685004, accuracy: 0.580000  [  550/22500]\n",
            "cost: 0.692112, accuracy: 0.560000  [ 1050/22500]\n",
            "cost: 0.687638, accuracy: 0.560000  [ 1550/22500]\n",
            "cost: 0.700548, accuracy: 0.380000  [ 2050/22500]\n",
            "cost: 0.695701, accuracy: 0.480000  [ 2550/22500]\n",
            "cost: 0.692693, accuracy: 0.480000  [ 3050/22500]\n",
            "cost: 0.669710, accuracy: 0.620000  [ 3550/22500]\n",
            "cost: 0.653757, accuracy: 0.600000  [ 4050/22500]\n",
            "cost: 0.546658, accuracy: 0.780000  [ 4550/22500]\n",
            "cost: 0.653363, accuracy: 0.740000  [ 5050/22500]\n",
            "cost: 0.518265, accuracy: 0.760000  [ 5550/22500]\n",
            "cost: 0.629661, accuracy: 0.680000  [ 6050/22500]\n",
            "cost: 0.486594, accuracy: 0.840000  [ 6550/22500]\n",
            "cost: 0.647712, accuracy: 0.680000  [ 7050/22500]\n",
            "cost: 0.366806, accuracy: 0.820000  [ 7550/22500]\n",
            "cost: 0.634665, accuracy: 0.620000  [ 8050/22500]\n",
            "cost: 0.640579, accuracy: 0.740000  [ 8550/22500]\n",
            "cost: 0.398103, accuracy: 0.860000  [ 9050/22500]\n",
            "cost: 0.381328, accuracy: 0.780000  [ 9550/22500]\n",
            "cost: 0.448801, accuracy: 0.780000  [10050/22500]\n",
            "cost: 0.420516, accuracy: 0.820000  [10550/22500]\n",
            "cost: 0.507349, accuracy: 0.820000  [11050/22500]\n",
            "cost: 0.350640, accuracy: 0.880000  [11550/22500]\n",
            "cost: 0.460326, accuracy: 0.760000  [12050/22500]\n",
            "cost: 0.627081, accuracy: 0.620000  [12550/22500]\n",
            "cost: 0.568204, accuracy: 0.680000  [13050/22500]\n",
            "cost: 0.430729, accuracy: 0.840000  [13550/22500]\n",
            "cost: 0.424841, accuracy: 0.800000  [14050/22500]\n",
            "cost: 0.463607, accuracy: 0.800000  [14550/22500]\n",
            "cost: 0.439638, accuracy: 0.780000  [15050/22500]\n",
            "cost: 0.410629, accuracy: 0.780000  [15550/22500]\n",
            "cost: 0.472332, accuracy: 0.760000  [16050/22500]\n",
            "cost: 0.531848, accuracy: 0.780000  [16550/22500]\n",
            "cost: 0.477875, accuracy: 0.840000  [17050/22500]\n",
            "cost: 0.664307, accuracy: 0.820000  [17550/22500]\n",
            "cost: 0.672648, accuracy: 0.580000  [18050/22500]\n",
            "cost: 0.692731, accuracy: 0.540000  [18550/22500]\n",
            "cost: 0.693986, accuracy: 0.460000  [19050/22500]\n",
            "cost: 0.699163, accuracy: 0.480000  [19550/22500]\n",
            "cost: 0.694914, accuracy: 0.440000  [20050/22500]\n",
            "cost: 0.692887, accuracy: 0.560000  [20550/22500]\n",
            "cost: 0.692375, accuracy: 0.560000  [21050/22500]\n",
            "cost: 0.691623, accuracy: 0.600000  [21550/22500]\n",
            "cost: 0.693694, accuracy: 0.480000  [22050/22500]\n",
            "cost: 0.517470, accuracy: 0.820000  [   50/22500]\n",
            "cost: 0.694196, accuracy: 0.420000  [  550/22500]\n",
            "cost: 0.693154, accuracy: 0.500000  [ 1050/22500]\n",
            "cost: 0.693355, accuracy: 0.480000  [ 1550/22500]\n",
            "cost: 0.692637, accuracy: 0.560000  [ 2050/22500]\n",
            "cost: 0.693056, accuracy: 0.500000  [ 2550/22500]\n",
            "cost: 0.693377, accuracy: 0.480000  [ 3050/22500]\n",
            "cost: 0.693467, accuracy: 0.480000  [ 3550/22500]\n",
            "cost: 0.697588, accuracy: 0.380000  [ 4050/22500]\n",
            "cost: 0.693964, accuracy: 0.480000  [ 4550/22500]\n",
            "cost: 0.696314, accuracy: 0.400000  [ 5050/22500]\n",
            "cost: 0.691847, accuracy: 0.540000  [ 5550/22500]\n",
            "cost: 0.691753, accuracy: 0.580000  [ 6050/22500]\n",
            "cost: 0.693638, accuracy: 0.460000  [ 6550/22500]\n",
            "cost: 0.692614, accuracy: 0.540000  [ 7050/22500]\n",
            "cost: 0.690911, accuracy: 0.580000  [ 7550/22500]\n",
            "cost: 0.690695, accuracy: 0.540000  [ 8050/22500]\n",
            "cost: 0.694017, accuracy: 0.480000  [ 8550/22500]\n",
            "cost: 0.691173, accuracy: 0.560000  [ 9050/22500]\n",
            "cost: 0.694578, accuracy: 0.420000  [ 9550/22500]\n",
            "cost: 0.691609, accuracy: 0.660000  [10050/22500]\n",
            "cost: 0.699717, accuracy: 0.420000  [10550/22500]\n",
            "cost: 0.690105, accuracy: 0.500000  [11050/22500]\n",
            "cost: 0.693174, accuracy: 0.500000  [11550/22500]\n",
            "cost: 0.694600, accuracy: 0.440000  [12050/22500]\n",
            "cost: 0.692204, accuracy: 0.540000  [12550/22500]\n",
            "cost: 0.692683, accuracy: 0.520000  [13050/22500]\n",
            "cost: 0.692962, accuracy: 0.500000  [13550/22500]\n",
            "cost: 0.693213, accuracy: 0.440000  [14050/22500]\n",
            "cost: 0.692678, accuracy: 0.700000  [14550/22500]\n",
            "cost: 0.688964, accuracy: 0.600000  [15050/22500]\n",
            "cost: 0.687145, accuracy: 0.580000  [15550/22500]\n",
            "cost: 0.691053, accuracy: 0.640000  [16050/22500]\n",
            "cost: 0.690522, accuracy: 0.760000  [16550/22500]\n",
            "cost: 0.692003, accuracy: 0.460000  [17050/22500]\n",
            "cost: 0.686418, accuracy: 0.520000  [17550/22500]\n",
            "cost: 0.682073, accuracy: 0.520000  [18050/22500]\n",
            "cost: 0.700926, accuracy: 0.440000  [18550/22500]\n",
            "cost: 0.688993, accuracy: 0.520000  [19050/22500]\n",
            "cost: 0.586763, accuracy: 0.720000  [19550/22500]\n",
            "cost: 0.699253, accuracy: 0.520000  [20050/22500]\n",
            "cost: 0.678873, accuracy: 0.440000  [20550/22500]\n",
            "cost: 0.498422, accuracy: 0.720000  [21050/22500]\n",
            "cost: 0.667656, accuracy: 0.560000  [21550/22500]\n",
            "cost: 0.552175, accuracy: 0.740000  [22050/22500]\n",
            "cost: 0.486892, accuracy: 0.780000  [   50/22500]\n",
            "cost: 0.646589, accuracy: 0.680000  [  550/22500]\n",
            "cost: 0.476900, accuracy: 0.820000  [ 1050/22500]\n",
            "cost: 0.322473, accuracy: 0.900000  [ 1550/22500]\n",
            "cost: 0.414288, accuracy: 0.780000  [ 2050/22500]\n",
            "cost: 0.382281, accuracy: 0.880000  [ 2550/22500]\n",
            "cost: 0.543586, accuracy: 0.700000  [ 3050/22500]\n",
            "cost: 0.467497, accuracy: 0.800000  [ 3550/22500]\n",
            "cost: 0.394538, accuracy: 0.820000  [ 4050/22500]\n",
            "cost: 0.492453, accuracy: 0.740000  [ 4550/22500]\n",
            "cost: 0.398365, accuracy: 0.860000  [ 5050/22500]\n",
            "cost: 0.393640, accuracy: 0.760000  [ 5550/22500]\n",
            "cost: 0.434791, accuracy: 0.860000  [ 6050/22500]\n",
            "cost: 0.262079, accuracy: 0.880000  [ 6550/22500]\n",
            "cost: 0.488231, accuracy: 0.780000  [ 7050/22500]\n",
            "cost: 0.393278, accuracy: 0.780000  [ 7550/22500]\n",
            "cost: 0.356576, accuracy: 0.860000  [ 8050/22500]\n",
            "cost: 0.399150, accuracy: 0.820000  [ 8550/22500]\n",
            "cost: 0.575227, accuracy: 0.700000  [ 9050/22500]\n",
            "cost: 0.563678, accuracy: 0.720000  [ 9550/22500]\n",
            "cost: 0.499992, accuracy: 0.780000  [10050/22500]\n",
            "cost: 0.412585, accuracy: 0.800000  [10550/22500]\n",
            "cost: 0.369080, accuracy: 0.760000  [11050/22500]\n",
            "cost: 0.262147, accuracy: 0.940000  [11550/22500]\n",
            "cost: 0.440045, accuracy: 0.800000  [12050/22500]\n",
            "cost: 0.337232, accuracy: 0.880000  [12550/22500]\n",
            "cost: 0.355457, accuracy: 0.780000  [13050/22500]\n",
            "cost: 0.439307, accuracy: 0.820000  [13550/22500]\n",
            "cost: 0.457959, accuracy: 0.820000  [14050/22500]\n",
            "cost: 0.343753, accuracy: 0.840000  [14550/22500]\n",
            "cost: 0.510507, accuracy: 0.740000  [15050/22500]\n",
            "cost: 0.401841, accuracy: 0.820000  [15550/22500]\n",
            "cost: 0.371277, accuracy: 0.880000  [16050/22500]\n",
            "cost: 0.252993, accuracy: 0.920000  [16550/22500]\n",
            "cost: 0.452300, accuracy: 0.760000  [17050/22500]\n",
            "cost: 0.370731, accuracy: 0.880000  [17550/22500]\n",
            "cost: 0.302490, accuracy: 0.900000  [18050/22500]\n",
            "cost: 0.297148, accuracy: 0.880000  [18550/22500]\n",
            "cost: 0.284964, accuracy: 0.820000  [19050/22500]\n",
            "cost: 0.440742, accuracy: 0.800000  [19550/22500]\n",
            "cost: 0.379706, accuracy: 0.840000  [20050/22500]\n",
            "cost: 0.330981, accuracy: 0.840000  [20550/22500]\n",
            "cost: 0.377788, accuracy: 0.820000  [21050/22500]\n",
            "cost: 0.509674, accuracy: 0.760000  [21550/22500]\n",
            "cost: 0.396466, accuracy: 0.800000  [22050/22500]\n",
            "cost: 0.261382, accuracy: 0.840000  [   50/22500]\n",
            "cost: 0.343407, accuracy: 0.880000  [  550/22500]\n",
            "cost: 0.522618, accuracy: 0.800000  [ 1050/22500]\n",
            "cost: 0.396846, accuracy: 0.820000  [ 1550/22500]\n",
            "cost: 0.448070, accuracy: 0.840000  [ 2050/22500]\n",
            "cost: 0.374613, accuracy: 0.800000  [ 2550/22500]\n",
            "cost: 0.476759, accuracy: 0.800000  [ 3050/22500]\n",
            "cost: 0.250812, accuracy: 0.900000  [ 3550/22500]\n",
            "cost: 0.206871, accuracy: 0.920000  [ 4050/22500]\n",
            "cost: 0.304169, accuracy: 0.880000  [ 4550/22500]\n",
            "cost: 0.302365, accuracy: 0.900000  [ 5050/22500]\n",
            "cost: 0.385434, accuracy: 0.800000  [ 5550/22500]\n",
            "cost: 0.355548, accuracy: 0.860000  [ 6050/22500]\n",
            "cost: 0.428287, accuracy: 0.780000  [ 6550/22500]\n",
            "cost: 0.222089, accuracy: 0.940000  [ 7050/22500]\n",
            "cost: 0.208372, accuracy: 0.960000  [ 7550/22500]\n",
            "cost: 0.366064, accuracy: 0.800000  [ 8050/22500]\n",
            "cost: 0.292394, accuracy: 0.880000  [ 8550/22500]\n",
            "cost: 0.351745, accuracy: 0.840000  [ 9050/22500]\n",
            "cost: 0.391901, accuracy: 0.800000  [ 9550/22500]\n",
            "cost: 0.389717, accuracy: 0.760000  [10050/22500]\n",
            "cost: 0.424982, accuracy: 0.780000  [10550/22500]\n",
            "cost: 0.380415, accuracy: 0.860000  [11050/22500]\n",
            "cost: 0.369753, accuracy: 0.760000  [11550/22500]\n",
            "cost: 0.432854, accuracy: 0.820000  [12050/22500]\n",
            "cost: 0.436361, accuracy: 0.780000  [12550/22500]\n",
            "cost: 0.288781, accuracy: 0.860000  [13050/22500]\n",
            "cost: 0.429348, accuracy: 0.760000  [13550/22500]\n",
            "cost: 0.393721, accuracy: 0.840000  [14050/22500]\n",
            "cost: 0.411970, accuracy: 0.840000  [14550/22500]\n",
            "cost: 0.318566, accuracy: 0.880000  [15050/22500]\n",
            "cost: 0.397161, accuracy: 0.840000  [15550/22500]\n",
            "cost: 0.454402, accuracy: 0.780000  [16050/22500]\n",
            "cost: 0.570512, accuracy: 0.760000  [16550/22500]\n",
            "cost: 0.338032, accuracy: 0.880000  [17050/22500]\n",
            "cost: 0.448634, accuracy: 0.800000  [17550/22500]\n",
            "cost: 0.467453, accuracy: 0.780000  [18050/22500]\n",
            "cost: 0.402679, accuracy: 0.820000  [18550/22500]\n",
            "cost: 0.347447, accuracy: 0.900000  [19050/22500]\n",
            "cost: 0.367206, accuracy: 0.800000  [19550/22500]\n",
            "cost: 0.417733, accuracy: 0.840000  [20050/22500]\n",
            "cost: 0.478515, accuracy: 0.740000  [20550/22500]\n",
            "cost: 0.363093, accuracy: 0.900000  [21050/22500]\n",
            "cost: 0.406441, accuracy: 0.820000  [21550/22500]\n",
            "cost: 0.327221, accuracy: 0.820000  [22050/22500]\n",
            "cost: 0.518146, accuracy: 0.720000  [   50/22500]\n",
            "cost: 0.257660, accuracy: 0.880000  [  550/22500]\n",
            "cost: 0.291138, accuracy: 0.880000  [ 1050/22500]\n",
            "cost: 0.315570, accuracy: 0.860000  [ 1550/22500]\n",
            "cost: 0.321617, accuracy: 0.860000  [ 2050/22500]\n",
            "cost: 0.355942, accuracy: 0.840000  [ 2550/22500]\n",
            "cost: 0.249231, accuracy: 0.940000  [ 3050/22500]\n",
            "cost: 0.291612, accuracy: 0.840000  [ 3550/22500]\n",
            "cost: 0.301699, accuracy: 0.860000  [ 4050/22500]\n",
            "cost: 0.300153, accuracy: 0.820000  [ 4550/22500]\n",
            "cost: 0.309844, accuracy: 0.860000  [ 5050/22500]\n",
            "cost: 0.436966, accuracy: 0.760000  [ 5550/22500]\n",
            "cost: 0.350671, accuracy: 0.880000  [ 6050/22500]\n",
            "cost: 0.341065, accuracy: 0.820000  [ 6550/22500]\n",
            "cost: 0.330862, accuracy: 0.800000  [ 7050/22500]\n",
            "cost: 0.239051, accuracy: 0.900000  [ 7550/22500]\n",
            "cost: 0.292534, accuracy: 0.880000  [ 8050/22500]\n",
            "cost: 0.320652, accuracy: 0.860000  [ 8550/22500]\n",
            "cost: 0.376980, accuracy: 0.880000  [ 9050/22500]\n",
            "cost: 0.570700, accuracy: 0.700000  [ 9550/22500]\n",
            "cost: 0.349362, accuracy: 0.880000  [10050/22500]\n",
            "cost: 0.258763, accuracy: 0.900000  [10550/22500]\n",
            "cost: 0.319561, accuracy: 0.880000  [11050/22500]\n",
            "cost: 0.186565, accuracy: 0.940000  [11550/22500]\n",
            "cost: 0.402153, accuracy: 0.780000  [12050/22500]\n",
            "cost: 0.639179, accuracy: 0.740000  [12550/22500]\n",
            "cost: 0.239578, accuracy: 0.900000  [13050/22500]\n",
            "cost: 0.344061, accuracy: 0.800000  [13550/22500]\n",
            "cost: 0.333358, accuracy: 0.860000  [14050/22500]\n",
            "cost: 0.445310, accuracy: 0.800000  [14550/22500]\n",
            "cost: 0.278712, accuracy: 0.900000  [15050/22500]\n",
            "cost: 0.337176, accuracy: 0.880000  [15550/22500]\n",
            "cost: 0.389579, accuracy: 0.780000  [16050/22500]\n",
            "cost: 0.278610, accuracy: 0.860000  [16550/22500]\n",
            "cost: 0.437520, accuracy: 0.820000  [17050/22500]\n",
            "cost: 0.485755, accuracy: 0.800000  [17550/22500]\n",
            "cost: 0.349175, accuracy: 0.880000  [18050/22500]\n",
            "cost: 0.140781, accuracy: 0.960000  [18550/22500]\n",
            "cost: 0.409082, accuracy: 0.780000  [19050/22500]\n",
            "cost: 0.470339, accuracy: 0.800000  [19550/22500]\n",
            "cost: 0.269017, accuracy: 0.880000  [20050/22500]\n",
            "cost: 0.447495, accuracy: 0.780000  [20550/22500]\n",
            "cost: 0.210660, accuracy: 0.920000  [21050/22500]\n",
            "cost: 0.351263, accuracy: 0.840000  [21550/22500]\n",
            "cost: 0.309259, accuracy: 0.900000  [22050/22500]\n",
            "cost: 0.307215, accuracy: 0.860000  [   50/22500]\n",
            "cost: 0.213022, accuracy: 0.940000  [  550/22500]\n",
            "cost: 0.245020, accuracy: 0.900000  [ 1050/22500]\n",
            "cost: 0.266597, accuracy: 0.920000  [ 1550/22500]\n",
            "cost: 0.320480, accuracy: 0.800000  [ 2050/22500]\n",
            "cost: 0.294780, accuracy: 0.820000  [ 2550/22500]\n",
            "cost: 0.375127, accuracy: 0.820000  [ 3050/22500]\n",
            "cost: 0.304006, accuracy: 0.880000  [ 3550/22500]\n",
            "cost: 0.465819, accuracy: 0.820000  [ 4050/22500]\n",
            "cost: 0.156917, accuracy: 0.940000  [ 4550/22500]\n",
            "cost: 0.264416, accuracy: 0.880000  [ 5050/22500]\n",
            "cost: 0.298253, accuracy: 0.880000  [ 5550/22500]\n",
            "cost: 0.330836, accuracy: 0.920000  [ 6050/22500]\n",
            "cost: 0.247176, accuracy: 0.880000  [ 6550/22500]\n",
            "cost: 0.405958, accuracy: 0.800000  [ 7050/22500]\n",
            "cost: 0.406799, accuracy: 0.860000  [ 7550/22500]\n",
            "cost: 0.454876, accuracy: 0.820000  [ 8050/22500]\n",
            "cost: 0.452787, accuracy: 0.800000  [ 8550/22500]\n",
            "cost: 0.299807, accuracy: 0.880000  [ 9050/22500]\n",
            "cost: 0.487314, accuracy: 0.780000  [ 9550/22500]\n",
            "cost: 0.353665, accuracy: 0.840000  [10050/22500]\n",
            "cost: 0.254002, accuracy: 0.900000  [10550/22500]\n",
            "cost: 0.291170, accuracy: 0.880000  [11050/22500]\n",
            "cost: 0.358732, accuracy: 0.880000  [11550/22500]\n",
            "cost: 0.357909, accuracy: 0.820000  [12050/22500]\n",
            "cost: 0.298691, accuracy: 0.880000  [12550/22500]\n",
            "cost: 0.281019, accuracy: 0.860000  [13050/22500]\n",
            "cost: 0.317063, accuracy: 0.900000  [13550/22500]\n",
            "cost: 0.258587, accuracy: 0.900000  [14050/22500]\n",
            "cost: 0.276613, accuracy: 0.840000  [14550/22500]\n",
            "cost: 0.329507, accuracy: 0.860000  [15050/22500]\n",
            "cost: 0.367458, accuracy: 0.820000  [15550/22500]\n",
            "cost: 0.320541, accuracy: 0.860000  [16050/22500]\n",
            "cost: 0.183351, accuracy: 0.980000  [16550/22500]\n",
            "cost: 0.264083, accuracy: 0.860000  [17050/22500]\n",
            "cost: 0.325764, accuracy: 0.840000  [17550/22500]\n",
            "cost: 0.300453, accuracy: 0.840000  [18050/22500]\n",
            "cost: 0.320908, accuracy: 0.840000  [18550/22500]\n",
            "cost: 0.288889, accuracy: 0.860000  [19050/22500]\n",
            "cost: 0.297033, accuracy: 0.900000  [19550/22500]\n",
            "cost: 0.463682, accuracy: 0.820000  [20050/22500]\n",
            "cost: 0.392055, accuracy: 0.840000  [20550/22500]\n",
            "cost: 0.441976, accuracy: 0.820000  [21050/22500]\n",
            "cost: 0.268432, accuracy: 0.860000  [21550/22500]\n",
            "cost: 0.380065, accuracy: 0.820000  [22050/22500]\n",
            "cost: 0.186492, accuracy: 0.960000  [   50/22500]\n",
            "cost: 0.229474, accuracy: 0.940000  [  550/22500]\n",
            "cost: 0.267966, accuracy: 0.880000  [ 1050/22500]\n",
            "cost: 0.224294, accuracy: 0.900000  [ 1550/22500]\n",
            "cost: 0.466773, accuracy: 0.780000  [ 2050/22500]\n",
            "cost: 0.264926, accuracy: 0.860000  [ 2550/22500]\n",
            "cost: 0.281319, accuracy: 0.880000  [ 3050/22500]\n",
            "cost: 0.293278, accuracy: 0.900000  [ 3550/22500]\n",
            "cost: 0.252380, accuracy: 0.880000  [ 4050/22500]\n",
            "cost: 0.277866, accuracy: 0.900000  [ 4550/22500]\n",
            "cost: 0.231152, accuracy: 0.920000  [ 5050/22500]\n",
            "cost: 0.331364, accuracy: 0.840000  [ 5550/22500]\n",
            "cost: 0.273807, accuracy: 0.940000  [ 6050/22500]\n",
            "cost: 0.389636, accuracy: 0.820000  [ 6550/22500]\n",
            "cost: 0.122145, accuracy: 0.960000  [ 7050/22500]\n",
            "cost: 0.310402, accuracy: 0.900000  [ 7550/22500]\n",
            "cost: 0.213950, accuracy: 0.920000  [ 8050/22500]\n",
            "cost: 0.391612, accuracy: 0.800000  [ 8550/22500]\n",
            "cost: 0.386046, accuracy: 0.840000  [ 9050/22500]\n",
            "cost: 0.387390, accuracy: 0.800000  [ 9550/22500]\n",
            "cost: 0.188558, accuracy: 0.920000  [10050/22500]\n",
            "cost: 0.263571, accuracy: 0.920000  [10550/22500]\n",
            "cost: 0.279818, accuracy: 0.840000  [11050/22500]\n",
            "cost: 0.326409, accuracy: 0.800000  [11550/22500]\n",
            "cost: 0.248361, accuracy: 0.920000  [12050/22500]\n",
            "cost: 0.343464, accuracy: 0.820000  [12550/22500]\n",
            "cost: 0.410325, accuracy: 0.820000  [13050/22500]\n",
            "cost: 0.201268, accuracy: 0.880000  [13550/22500]\n",
            "cost: 0.360105, accuracy: 0.880000  [14050/22500]\n",
            "cost: 0.367490, accuracy: 0.920000  [14550/22500]\n",
            "cost: 0.359869, accuracy: 0.880000  [15050/22500]\n",
            "cost: 0.267607, accuracy: 0.940000  [15550/22500]\n",
            "cost: 0.194517, accuracy: 0.940000  [16050/22500]\n",
            "cost: 0.487390, accuracy: 0.820000  [16550/22500]\n",
            "cost: 0.318533, accuracy: 0.820000  [17050/22500]\n",
            "cost: 0.392859, accuracy: 0.800000  [17550/22500]\n",
            "cost: 0.506223, accuracy: 0.880000  [18050/22500]\n",
            "cost: 0.392293, accuracy: 0.900000  [18550/22500]\n",
            "cost: 0.339170, accuracy: 0.880000  [19050/22500]\n",
            "cost: 0.263417, accuracy: 0.860000  [19550/22500]\n",
            "cost: 0.205984, accuracy: 0.920000  [20050/22500]\n",
            "cost: 0.205352, accuracy: 0.900000  [20550/22500]\n",
            "cost: 0.393953, accuracy: 0.820000  [21050/22500]\n",
            "cost: 0.258672, accuracy: 0.920000  [21550/22500]\n",
            "cost: 0.240297, accuracy: 0.880000  [22050/22500]\n",
            "cost: 0.293645, accuracy: 0.880000  [   50/22500]\n",
            "cost: 0.292053, accuracy: 0.880000  [  550/22500]\n",
            "cost: 0.404423, accuracy: 0.820000  [ 1050/22500]\n",
            "cost: 0.240617, accuracy: 0.920000  [ 1550/22500]\n",
            "cost: 0.174717, accuracy: 0.940000  [ 2050/22500]\n",
            "cost: 0.254660, accuracy: 0.860000  [ 2550/22500]\n",
            "cost: 0.332040, accuracy: 0.840000  [ 3050/22500]\n",
            "cost: 0.269197, accuracy: 0.860000  [ 3550/22500]\n",
            "cost: 0.276077, accuracy: 0.840000  [ 4050/22500]\n",
            "cost: 0.282085, accuracy: 0.920000  [ 4550/22500]\n",
            "cost: 0.341064, accuracy: 0.820000  [ 5050/22500]\n",
            "cost: 0.280377, accuracy: 0.880000  [ 5550/22500]\n",
            "cost: 0.260447, accuracy: 0.860000  [ 6050/22500]\n",
            "cost: 0.314980, accuracy: 0.840000  [ 6550/22500]\n",
            "cost: 0.418560, accuracy: 0.800000  [ 7050/22500]\n",
            "cost: 0.189789, accuracy: 0.900000  [ 7550/22500]\n",
            "cost: 0.491889, accuracy: 0.860000  [ 8050/22500]\n",
            "cost: 0.288300, accuracy: 0.820000  [ 8550/22500]\n",
            "cost: 0.246683, accuracy: 0.880000  [ 9050/22500]\n",
            "cost: 0.278313, accuracy: 0.860000  [ 9550/22500]\n",
            "cost: 0.199885, accuracy: 0.920000  [10050/22500]\n",
            "cost: 0.285334, accuracy: 0.880000  [10550/22500]\n",
            "cost: 0.383568, accuracy: 0.820000  [11050/22500]\n",
            "cost: 0.423019, accuracy: 0.860000  [11550/22500]\n",
            "cost: 0.144681, accuracy: 0.940000  [12050/22500]\n",
            "cost: 0.331122, accuracy: 0.880000  [12550/22500]\n",
            "cost: 0.277680, accuracy: 0.860000  [13050/22500]\n",
            "cost: 0.184439, accuracy: 0.960000  [13550/22500]\n",
            "cost: 0.219418, accuracy: 0.940000  [14050/22500]\n",
            "cost: 0.398031, accuracy: 0.820000  [14550/22500]\n",
            "cost: 0.371624, accuracy: 0.840000  [15050/22500]\n",
            "cost: 0.288813, accuracy: 0.880000  [15550/22500]\n",
            "cost: 0.218089, accuracy: 0.900000  [16050/22500]\n",
            "cost: 0.377861, accuracy: 0.860000  [16550/22500]\n",
            "cost: 0.220901, accuracy: 0.940000  [17050/22500]\n",
            "cost: 0.244216, accuracy: 0.900000  [17550/22500]\n",
            "cost: 0.188905, accuracy: 0.940000  [18050/22500]\n",
            "cost: 0.207838, accuracy: 0.900000  [18550/22500]\n",
            "cost: 0.292085, accuracy: 0.880000  [19050/22500]\n",
            "cost: 0.267203, accuracy: 0.900000  [19550/22500]\n",
            "cost: 0.211565, accuracy: 0.880000  [20050/22500]\n",
            "cost: 0.171596, accuracy: 0.940000  [20550/22500]\n",
            "cost: 0.269994, accuracy: 0.880000  [21050/22500]\n",
            "cost: 0.333864, accuracy: 0.880000  [21550/22500]\n",
            "cost: 0.289619, accuracy: 0.900000  [22050/22500]\n",
            "cost: 0.401798, accuracy: 0.840000  [   50/22500]\n",
            "cost: 0.321436, accuracy: 0.880000  [  550/22500]\n",
            "cost: 0.199521, accuracy: 0.960000  [ 1050/22500]\n",
            "cost: 0.220827, accuracy: 0.940000  [ 1550/22500]\n",
            "cost: 0.399580, accuracy: 0.800000  [ 2050/22500]\n",
            "cost: 0.211010, accuracy: 0.900000  [ 2550/22500]\n",
            "cost: 0.303966, accuracy: 0.860000  [ 3050/22500]\n",
            "cost: 0.388388, accuracy: 0.860000  [ 3550/22500]\n",
            "cost: 0.164972, accuracy: 0.960000  [ 4050/22500]\n",
            "cost: 0.241563, accuracy: 0.940000  [ 4550/22500]\n",
            "cost: 0.284157, accuracy: 0.880000  [ 5050/22500]\n",
            "cost: 0.247876, accuracy: 0.900000  [ 5550/22500]\n",
            "cost: 0.384318, accuracy: 0.860000  [ 6050/22500]\n",
            "cost: 0.242940, accuracy: 0.900000  [ 6550/22500]\n",
            "cost: 0.327294, accuracy: 0.820000  [ 7050/22500]\n",
            "cost: 0.157186, accuracy: 0.920000  [ 7550/22500]\n",
            "cost: 0.256618, accuracy: 0.900000  [ 8050/22500]\n",
            "cost: 0.285254, accuracy: 0.900000  [ 8550/22500]\n",
            "cost: 0.137488, accuracy: 0.980000  [ 9050/22500]\n",
            "cost: 0.131137, accuracy: 0.960000  [ 9550/22500]\n",
            "cost: 0.359359, accuracy: 0.800000  [10050/22500]\n",
            "cost: 0.186878, accuracy: 0.920000  [10550/22500]\n",
            "cost: 0.168982, accuracy: 0.940000  [11050/22500]\n",
            "cost: 0.197196, accuracy: 0.900000  [11550/22500]\n",
            "cost: 0.304206, accuracy: 0.880000  [12050/22500]\n",
            "cost: 0.385623, accuracy: 0.840000  [12550/22500]\n",
            "cost: 0.164501, accuracy: 0.960000  [13050/22500]\n",
            "cost: 0.310747, accuracy: 0.880000  [13550/22500]\n",
            "cost: 0.282478, accuracy: 0.880000  [14050/22500]\n",
            "cost: 0.236329, accuracy: 0.920000  [14550/22500]\n",
            "cost: 0.222869, accuracy: 0.880000  [15050/22500]\n",
            "cost: 0.330334, accuracy: 0.780000  [15550/22500]\n",
            "cost: 0.291668, accuracy: 0.880000  [16050/22500]\n",
            "cost: 0.166092, accuracy: 0.940000  [16550/22500]\n",
            "cost: 0.219357, accuracy: 0.940000  [17050/22500]\n",
            "cost: 0.325249, accuracy: 0.920000  [17550/22500]\n",
            "cost: 0.280451, accuracy: 0.860000  [18050/22500]\n",
            "cost: 0.143726, accuracy: 0.920000  [18550/22500]\n",
            "cost: 0.264265, accuracy: 0.920000  [19050/22500]\n",
            "cost: 0.265003, accuracy: 0.880000  [19550/22500]\n",
            "cost: 0.237171, accuracy: 0.880000  [20050/22500]\n",
            "cost: 0.328850, accuracy: 0.900000  [20550/22500]\n",
            "cost: 0.384198, accuracy: 0.900000  [21050/22500]\n",
            "cost: 0.315269, accuracy: 0.860000  [21550/22500]\n",
            "cost: 0.171589, accuracy: 0.920000  [22050/22500]\n",
            "cost: 0.232507, accuracy: 0.900000  [   50/22500]\n",
            "cost: 0.208029, accuracy: 0.900000  [  550/22500]\n",
            "cost: 0.268340, accuracy: 0.900000  [ 1050/22500]\n",
            "cost: 0.262177, accuracy: 0.940000  [ 1550/22500]\n",
            "cost: 0.247858, accuracy: 0.900000  [ 2050/22500]\n",
            "cost: 0.179860, accuracy: 0.920000  [ 2550/22500]\n",
            "cost: 0.205663, accuracy: 0.920000  [ 3050/22500]\n",
            "cost: 0.266105, accuracy: 0.900000  [ 3550/22500]\n",
            "cost: 0.475147, accuracy: 0.800000  [ 4050/22500]\n",
            "cost: 0.333722, accuracy: 0.900000  [ 4550/22500]\n",
            "cost: 0.234632, accuracy: 0.920000  [ 5050/22500]\n",
            "cost: 0.253853, accuracy: 0.920000  [ 5550/22500]\n",
            "cost: 0.244300, accuracy: 0.900000  [ 6050/22500]\n",
            "cost: 0.182444, accuracy: 0.940000  [ 6550/22500]\n",
            "cost: 0.326591, accuracy: 0.820000  [ 7050/22500]\n",
            "cost: 0.284317, accuracy: 0.920000  [ 7550/22500]\n",
            "cost: 0.197561, accuracy: 0.900000  [ 8050/22500]\n",
            "cost: 0.332206, accuracy: 0.900000  [ 8550/22500]\n",
            "cost: 0.269636, accuracy: 0.900000  [ 9050/22500]\n",
            "cost: 0.280530, accuracy: 0.840000  [ 9550/22500]\n",
            "cost: 0.249481, accuracy: 0.880000  [10050/22500]\n",
            "cost: 0.246452, accuracy: 0.940000  [10550/22500]\n",
            "cost: 0.337281, accuracy: 0.820000  [11050/22500]\n",
            "cost: 0.245083, accuracy: 0.960000  [11550/22500]\n",
            "cost: 0.186846, accuracy: 0.940000  [12050/22500]\n",
            "cost: 0.226397, accuracy: 0.940000  [12550/22500]\n",
            "cost: 0.249390, accuracy: 0.880000  [13050/22500]\n",
            "cost: 0.358315, accuracy: 0.800000  [13550/22500]\n",
            "cost: 0.244812, accuracy: 0.880000  [14050/22500]\n",
            "cost: 0.321356, accuracy: 0.900000  [14550/22500]\n",
            "cost: 0.298882, accuracy: 0.880000  [15050/22500]\n",
            "cost: 0.464673, accuracy: 0.840000  [15550/22500]\n",
            "cost: 0.134121, accuracy: 0.960000  [16050/22500]\n",
            "cost: 0.178090, accuracy: 0.940000  [16550/22500]\n",
            "cost: 0.330512, accuracy: 0.840000  [17050/22500]\n",
            "cost: 0.305736, accuracy: 0.920000  [17550/22500]\n",
            "cost: 0.208129, accuracy: 0.940000  [18050/22500]\n",
            "cost: 0.228213, accuracy: 0.920000  [18550/22500]\n",
            "cost: 0.394584, accuracy: 0.880000  [19050/22500]\n",
            "cost: 0.355826, accuracy: 0.840000  [19550/22500]\n",
            "cost: 0.554527, accuracy: 0.860000  [20050/22500]\n",
            "cost: 0.309265, accuracy: 0.900000  [20550/22500]\n",
            "cost: 0.220121, accuracy: 0.880000  [21050/22500]\n",
            "cost: 0.072259, accuracy: 1.000000  [21550/22500]\n",
            "cost: 0.231416, accuracy: 0.900000  [22050/22500]\n",
            "cost: 0.134712, accuracy: 0.960000  [   50/22500]\n",
            "cost: 0.109160, accuracy: 0.980000  [  550/22500]\n",
            "cost: 0.137653, accuracy: 0.920000  [ 1050/22500]\n",
            "cost: 0.278089, accuracy: 0.920000  [ 1550/22500]\n",
            "cost: 0.247954, accuracy: 0.940000  [ 2050/22500]\n",
            "cost: 0.259713, accuracy: 0.880000  [ 2550/22500]\n",
            "cost: 0.130889, accuracy: 0.960000  [ 3050/22500]\n",
            "cost: 0.207239, accuracy: 0.940000  [ 3550/22500]\n",
            "cost: 0.190367, accuracy: 0.920000  [ 4050/22500]\n",
            "cost: 0.241230, accuracy: 0.900000  [ 4550/22500]\n",
            "cost: 0.237893, accuracy: 0.860000  [ 5050/22500]\n",
            "cost: 0.207932, accuracy: 0.900000  [ 5550/22500]\n",
            "cost: 0.175206, accuracy: 0.920000  [ 6050/22500]\n",
            "cost: 0.162132, accuracy: 0.960000  [ 6550/22500]\n",
            "cost: 0.199742, accuracy: 0.920000  [ 7050/22500]\n",
            "cost: 0.185183, accuracy: 0.900000  [ 7550/22500]\n",
            "cost: 0.419194, accuracy: 0.840000  [ 8050/22500]\n",
            "cost: 0.238413, accuracy: 0.920000  [ 8550/22500]\n",
            "cost: 0.181838, accuracy: 0.960000  [ 9050/22500]\n",
            "cost: 0.312863, accuracy: 0.900000  [ 9550/22500]\n",
            "cost: 0.172469, accuracy: 0.940000  [10050/22500]\n",
            "cost: 0.307752, accuracy: 0.860000  [10550/22500]\n",
            "cost: 0.295925, accuracy: 0.880000  [11050/22500]\n",
            "cost: 0.291784, accuracy: 0.800000  [11550/22500]\n",
            "cost: 0.376456, accuracy: 0.800000  [12050/22500]\n",
            "cost: 0.172748, accuracy: 0.900000  [12550/22500]\n",
            "cost: 0.187068, accuracy: 0.920000  [13050/22500]\n",
            "cost: 0.198348, accuracy: 0.920000  [13550/22500]\n",
            "cost: 0.482014, accuracy: 0.900000  [14050/22500]\n",
            "cost: 0.135878, accuracy: 0.960000  [14550/22500]\n",
            "cost: 0.121672, accuracy: 0.960000  [15050/22500]\n",
            "cost: 0.181419, accuracy: 0.920000  [15550/22500]\n",
            "cost: 0.208847, accuracy: 0.900000  [16050/22500]\n",
            "cost: 0.172566, accuracy: 0.900000  [16550/22500]\n",
            "cost: 0.237690, accuracy: 0.880000  [17050/22500]\n",
            "cost: 0.359294, accuracy: 0.880000  [17550/22500]\n",
            "cost: 0.209144, accuracy: 0.940000  [18050/22500]\n",
            "cost: 0.122874, accuracy: 0.940000  [18550/22500]\n",
            "cost: 0.146047, accuracy: 0.940000  [19050/22500]\n",
            "cost: 0.281082, accuracy: 0.920000  [19550/22500]\n",
            "cost: 0.201354, accuracy: 0.940000  [20050/22500]\n",
            "cost: 0.259190, accuracy: 0.860000  [20550/22500]\n",
            "cost: 0.096352, accuracy: 1.000000  [21050/22500]\n",
            "cost: 0.127480, accuracy: 0.960000  [21550/22500]\n",
            "cost: 0.214591, accuracy: 0.940000  [22050/22500]\n",
            "cost: 0.144572, accuracy: 0.940000  [   50/22500]\n",
            "cost: 0.206893, accuracy: 0.940000  [  550/22500]\n",
            "cost: 0.183627, accuracy: 0.960000  [ 1050/22500]\n",
            "cost: 0.294579, accuracy: 0.900000  [ 1550/22500]\n",
            "cost: 0.208954, accuracy: 0.900000  [ 2050/22500]\n",
            "cost: 0.099237, accuracy: 0.940000  [ 2550/22500]\n",
            "cost: 0.170723, accuracy: 0.940000  [ 3050/22500]\n",
            "cost: 0.255824, accuracy: 0.920000  [ 3550/22500]\n",
            "cost: 0.196197, accuracy: 0.920000  [ 4050/22500]\n",
            "cost: 0.232454, accuracy: 0.900000  [ 4550/22500]\n",
            "cost: 0.289528, accuracy: 0.900000  [ 5050/22500]\n",
            "cost: 0.311616, accuracy: 0.900000  [ 5550/22500]\n",
            "cost: 0.232950, accuracy: 0.880000  [ 6050/22500]\n",
            "cost: 0.171211, accuracy: 0.920000  [ 6550/22500]\n",
            "cost: 0.360760, accuracy: 0.880000  [ 7050/22500]\n",
            "cost: 0.285125, accuracy: 0.920000  [ 7550/22500]\n",
            "cost: 0.265686, accuracy: 0.860000  [ 8050/22500]\n",
            "cost: 0.261581, accuracy: 0.900000  [ 8550/22500]\n",
            "cost: 0.296148, accuracy: 0.860000  [ 9050/22500]\n",
            "cost: 0.307263, accuracy: 0.900000  [ 9550/22500]\n",
            "cost: 0.170758, accuracy: 0.940000  [10050/22500]\n",
            "cost: 0.136524, accuracy: 0.980000  [10550/22500]\n",
            "cost: 0.160652, accuracy: 0.940000  [11050/22500]\n",
            "cost: 0.300500, accuracy: 0.840000  [11550/22500]\n",
            "cost: 0.214147, accuracy: 0.940000  [12050/22500]\n",
            "cost: 0.231446, accuracy: 0.920000  [12550/22500]\n",
            "cost: 0.407875, accuracy: 0.820000  [13050/22500]\n",
            "cost: 0.205577, accuracy: 0.900000  [13550/22500]\n",
            "cost: 0.154941, accuracy: 0.940000  [14050/22500]\n",
            "cost: 0.160085, accuracy: 0.960000  [14550/22500]\n",
            "cost: 0.252477, accuracy: 0.920000  [15050/22500]\n",
            "cost: 0.137163, accuracy: 0.940000  [15550/22500]\n",
            "cost: 0.287911, accuracy: 0.860000  [16050/22500]\n",
            "cost: 0.187520, accuracy: 0.900000  [16550/22500]\n",
            "cost: 0.233474, accuracy: 0.940000  [17050/22500]\n",
            "cost: 0.236859, accuracy: 0.920000  [17550/22500]\n",
            "cost: 0.176369, accuracy: 0.940000  [18050/22500]\n",
            "cost: 0.242500, accuracy: 0.900000  [18550/22500]\n",
            "cost: 0.413854, accuracy: 0.860000  [19050/22500]\n",
            "cost: 0.222728, accuracy: 0.900000  [19550/22500]\n",
            "cost: 0.239903, accuracy: 0.860000  [20050/22500]\n",
            "cost: 0.257869, accuracy: 0.860000  [20550/22500]\n",
            "cost: 0.253891, accuracy: 0.860000  [21050/22500]\n",
            "cost: 0.236076, accuracy: 0.940000  [21550/22500]\n",
            "cost: 0.248499, accuracy: 0.880000  [22050/22500]\n",
            "cost: 0.275079, accuracy: 0.920000  [   50/22500]\n",
            "cost: 0.110870, accuracy: 0.980000  [  550/22500]\n",
            "cost: 0.132302, accuracy: 0.920000  [ 1050/22500]\n",
            "cost: 0.372757, accuracy: 0.860000  [ 1550/22500]\n",
            "cost: 0.250506, accuracy: 0.900000  [ 2050/22500]\n",
            "cost: 0.337454, accuracy: 0.920000  [ 2550/22500]\n",
            "cost: 0.402764, accuracy: 0.880000  [ 3050/22500]\n",
            "cost: 0.070546, accuracy: 0.980000  [ 3550/22500]\n",
            "cost: 0.118777, accuracy: 0.960000  [ 4050/22500]\n",
            "cost: 0.147218, accuracy: 0.920000  [ 4550/22500]\n",
            "cost: 0.169165, accuracy: 0.940000  [ 5050/22500]\n",
            "cost: 0.252228, accuracy: 0.900000  [ 5550/22500]\n",
            "cost: 0.205848, accuracy: 0.900000  [ 6050/22500]\n",
            "cost: 0.134690, accuracy: 0.940000  [ 6550/22500]\n",
            "cost: 0.162347, accuracy: 0.920000  [ 7050/22500]\n",
            "cost: 0.177134, accuracy: 0.920000  [ 7550/22500]\n",
            "cost: 0.218030, accuracy: 0.880000  [ 8050/22500]\n",
            "cost: 0.156587, accuracy: 0.940000  [ 8550/22500]\n",
            "cost: 0.107692, accuracy: 0.960000  [ 9050/22500]\n",
            "cost: 0.161535, accuracy: 0.920000  [ 9550/22500]\n",
            "cost: 0.147004, accuracy: 0.940000  [10050/22500]\n",
            "cost: 0.275349, accuracy: 0.860000  [10550/22500]\n",
            "cost: 0.237118, accuracy: 0.920000  [11050/22500]\n",
            "cost: 0.188889, accuracy: 0.960000  [11550/22500]\n",
            "cost: 0.093103, accuracy: 0.960000  [12050/22500]\n",
            "cost: 0.214516, accuracy: 0.880000  [12550/22500]\n",
            "cost: 0.309959, accuracy: 0.880000  [13050/22500]\n",
            "cost: 0.133180, accuracy: 0.920000  [13550/22500]\n",
            "cost: 0.147259, accuracy: 0.940000  [14050/22500]\n",
            "cost: 0.150752, accuracy: 0.960000  [14550/22500]\n",
            "cost: 0.264862, accuracy: 0.920000  [15050/22500]\n",
            "cost: 0.157783, accuracy: 0.920000  [15550/22500]\n",
            "cost: 0.110615, accuracy: 0.960000  [16050/22500]\n",
            "cost: 0.330976, accuracy: 0.860000  [16550/22500]\n",
            "cost: 0.182569, accuracy: 0.920000  [17050/22500]\n",
            "cost: 0.154445, accuracy: 0.940000  [17550/22500]\n",
            "cost: 0.149508, accuracy: 0.960000  [18050/22500]\n",
            "cost: 0.160874, accuracy: 0.960000  [18550/22500]\n",
            "cost: 0.329681, accuracy: 0.820000  [19050/22500]\n",
            "cost: 0.195852, accuracy: 0.940000  [19550/22500]\n",
            "cost: 0.111780, accuracy: 0.960000  [20050/22500]\n",
            "cost: 0.162235, accuracy: 0.920000  [20550/22500]\n",
            "cost: 0.094932, accuracy: 0.980000  [21050/22500]\n",
            "cost: 0.185130, accuracy: 0.920000  [21550/22500]\n",
            "cost: 0.186451, accuracy: 0.900000  [22050/22500]\n",
            "cost: 0.255582, accuracy: 0.880000  [   50/22500]\n",
            "cost: 0.131718, accuracy: 0.960000  [  550/22500]\n",
            "cost: 0.132386, accuracy: 0.940000  [ 1050/22500]\n",
            "cost: 0.120455, accuracy: 0.960000  [ 1550/22500]\n",
            "cost: 0.089261, accuracy: 0.980000  [ 2050/22500]\n",
            "cost: 0.235156, accuracy: 0.900000  [ 2550/22500]\n",
            "cost: 0.112755, accuracy: 0.940000  [ 3050/22500]\n",
            "cost: 0.077280, accuracy: 0.980000  [ 3550/22500]\n",
            "cost: 0.092903, accuracy: 1.000000  [ 4050/22500]\n",
            "cost: 0.089154, accuracy: 0.980000  [ 4550/22500]\n",
            "cost: 0.237237, accuracy: 0.940000  [ 5050/22500]\n",
            "cost: 0.146822, accuracy: 0.960000  [ 5550/22500]\n",
            "cost: 0.218855, accuracy: 0.900000  [ 6050/22500]\n",
            "cost: 0.104358, accuracy: 0.980000  [ 6550/22500]\n",
            "cost: 0.240610, accuracy: 0.920000  [ 7050/22500]\n",
            "cost: 0.062264, accuracy: 0.980000  [ 7550/22500]\n",
            "cost: 0.257831, accuracy: 0.860000  [ 8050/22500]\n",
            "cost: 0.112757, accuracy: 0.980000  [ 8550/22500]\n",
            "cost: 0.203751, accuracy: 0.920000  [ 9050/22500]\n",
            "cost: 0.134372, accuracy: 0.920000  [ 9550/22500]\n",
            "cost: 0.098187, accuracy: 0.980000  [10050/22500]\n",
            "cost: 0.111976, accuracy: 0.980000  [10550/22500]\n",
            "cost: 0.490416, accuracy: 0.800000  [11050/22500]\n",
            "cost: 0.077569, accuracy: 0.980000  [11550/22500]\n",
            "cost: 0.121119, accuracy: 0.980000  [12050/22500]\n",
            "cost: 0.118711, accuracy: 0.960000  [12550/22500]\n",
            "cost: 0.073663, accuracy: 0.980000  [13050/22500]\n",
            "cost: 0.170498, accuracy: 0.860000  [13550/22500]\n",
            "cost: 0.150928, accuracy: 0.960000  [14050/22500]\n",
            "cost: 0.189962, accuracy: 0.900000  [14550/22500]\n",
            "cost: 0.225657, accuracy: 0.940000  [15050/22500]\n",
            "cost: 0.150243, accuracy: 0.900000  [15550/22500]\n",
            "cost: 0.163581, accuracy: 0.920000  [16050/22500]\n",
            "cost: 0.202152, accuracy: 0.880000  [16550/22500]\n",
            "cost: 0.072714, accuracy: 0.980000  [17050/22500]\n",
            "cost: 0.138499, accuracy: 0.980000  [17550/22500]\n",
            "cost: 0.085329, accuracy: 0.960000  [18050/22500]\n",
            "cost: 0.191795, accuracy: 0.920000  [18550/22500]\n",
            "cost: 0.176452, accuracy: 0.940000  [19050/22500]\n",
            "cost: 0.135048, accuracy: 0.960000  [19550/22500]\n",
            "cost: 0.206730, accuracy: 0.960000  [20050/22500]\n",
            "cost: 0.331958, accuracy: 0.860000  [20550/22500]\n",
            "cost: 0.118614, accuracy: 0.960000  [21050/22500]\n",
            "cost: 0.100027, accuracy: 0.980000  [21550/22500]\n",
            "cost: 0.085826, accuracy: 0.960000  [22050/22500]\n",
            "cost: 0.236588, accuracy: 0.940000  [   50/22500]\n",
            "cost: 0.060469, accuracy: 0.960000  [  550/22500]\n",
            "cost: 0.157678, accuracy: 0.940000  [ 1050/22500]\n",
            "cost: 0.105782, accuracy: 0.980000  [ 1550/22500]\n",
            "cost: 0.126088, accuracy: 0.940000  [ 2050/22500]\n",
            "cost: 0.150441, accuracy: 0.960000  [ 2550/22500]\n",
            "cost: 0.289065, accuracy: 0.900000  [ 3050/22500]\n",
            "cost: 0.091289, accuracy: 0.980000  [ 3550/22500]\n",
            "cost: 0.134367, accuracy: 0.960000  [ 4050/22500]\n",
            "cost: 0.057090, accuracy: 1.000000  [ 4550/22500]\n",
            "cost: 0.098584, accuracy: 0.920000  [ 5050/22500]\n",
            "cost: 0.089067, accuracy: 0.960000  [ 5550/22500]\n",
            "cost: 0.049624, accuracy: 0.980000  [ 6050/22500]\n",
            "cost: 0.163198, accuracy: 0.920000  [ 6550/22500]\n",
            "cost: 0.163000, accuracy: 0.920000  [ 7050/22500]\n",
            "cost: 0.055731, accuracy: 0.980000  [ 7550/22500]\n",
            "cost: 0.046826, accuracy: 0.980000  [ 8050/22500]\n",
            "cost: 0.093200, accuracy: 0.940000  [ 8550/22500]\n",
            "cost: 0.214383, accuracy: 0.880000  [ 9050/22500]\n",
            "cost: 0.137415, accuracy: 0.920000  [ 9550/22500]\n",
            "cost: 0.098329, accuracy: 0.960000  [10050/22500]\n",
            "cost: 0.131870, accuracy: 0.940000  [10550/22500]\n",
            "cost: 0.067963, accuracy: 0.980000  [11050/22500]\n",
            "cost: 0.159930, accuracy: 0.960000  [11550/22500]\n",
            "cost: 0.122922, accuracy: 0.960000  [12050/22500]\n",
            "cost: 0.221124, accuracy: 0.900000  [12550/22500]\n",
            "cost: 0.204081, accuracy: 0.940000  [13050/22500]\n",
            "cost: 0.079506, accuracy: 0.940000  [13550/22500]\n",
            "cost: 0.130642, accuracy: 0.960000  [14050/22500]\n",
            "cost: 0.123769, accuracy: 0.920000  [14550/22500]\n",
            "cost: 0.157266, accuracy: 0.920000  [15050/22500]\n",
            "cost: 0.085931, accuracy: 0.960000  [15550/22500]\n",
            "cost: 0.054650, accuracy: 0.980000  [16050/22500]\n",
            "cost: 0.238305, accuracy: 0.920000  [16550/22500]\n",
            "cost: 0.099466, accuracy: 0.960000  [17050/22500]\n",
            "cost: 0.075867, accuracy: 1.000000  [17550/22500]\n",
            "cost: 0.120512, accuracy: 0.960000  [18050/22500]\n",
            "cost: 0.150920, accuracy: 0.920000  [18550/22500]\n",
            "cost: 0.142124, accuracy: 0.940000  [19050/22500]\n",
            "cost: 0.130208, accuracy: 0.960000  [19550/22500]\n",
            "cost: 0.113769, accuracy: 0.960000  [20050/22500]\n",
            "cost: 0.109883, accuracy: 0.960000  [20550/22500]\n",
            "cost: 0.215651, accuracy: 0.940000  [21050/22500]\n",
            "cost: 0.128321, accuracy: 0.960000  [21550/22500]\n",
            "cost: 0.119551, accuracy: 0.980000  [22050/22500]\n",
            "cost: 0.112112, accuracy: 0.960000  [   50/22500]\n",
            "cost: 0.098759, accuracy: 0.960000  [  550/22500]\n",
            "cost: 0.097573, accuracy: 0.940000  [ 1050/22500]\n",
            "cost: 0.083737, accuracy: 0.960000  [ 1550/22500]\n",
            "cost: 0.124447, accuracy: 0.960000  [ 2050/22500]\n",
            "cost: 0.069106, accuracy: 0.980000  [ 2550/22500]\n",
            "cost: 0.041481, accuracy: 1.000000  [ 3050/22500]\n",
            "cost: 0.034132, accuracy: 1.000000  [ 3550/22500]\n",
            "cost: 0.239061, accuracy: 0.940000  [ 4050/22500]\n",
            "cost: 0.073795, accuracy: 0.960000  [ 4550/22500]\n",
            "cost: 0.075167, accuracy: 0.980000  [ 5050/22500]\n",
            "cost: 0.071705, accuracy: 0.960000  [ 5550/22500]\n",
            "cost: 0.101250, accuracy: 0.960000  [ 6050/22500]\n",
            "cost: 0.094582, accuracy: 0.980000  [ 6550/22500]\n",
            "cost: 0.152321, accuracy: 0.960000  [ 7050/22500]\n",
            "cost: 0.086711, accuracy: 0.980000  [ 7550/22500]\n",
            "cost: 0.127032, accuracy: 0.900000  [ 8050/22500]\n",
            "cost: 0.057468, accuracy: 1.000000  [ 8550/22500]\n",
            "cost: 0.132115, accuracy: 0.940000  [ 9050/22500]\n",
            "cost: 0.033092, accuracy: 1.000000  [ 9550/22500]\n",
            "cost: 0.117954, accuracy: 0.980000  [10050/22500]\n",
            "cost: 0.058915, accuracy: 0.980000  [10550/22500]\n",
            "cost: 0.296685, accuracy: 0.880000  [11050/22500]\n",
            "cost: 0.063921, accuracy: 0.980000  [11550/22500]\n",
            "cost: 0.130466, accuracy: 0.960000  [12050/22500]\n",
            "cost: 0.146751, accuracy: 0.940000  [12550/22500]\n",
            "cost: 0.158633, accuracy: 0.920000  [13050/22500]\n",
            "cost: 0.050872, accuracy: 1.000000  [13550/22500]\n",
            "cost: 0.031218, accuracy: 1.000000  [14050/22500]\n",
            "cost: 0.088696, accuracy: 0.960000  [14550/22500]\n",
            "cost: 0.163431, accuracy: 0.940000  [15050/22500]\n",
            "cost: 0.078329, accuracy: 0.980000  [15550/22500]\n",
            "cost: 0.124941, accuracy: 0.940000  [16050/22500]\n",
            "cost: 0.094891, accuracy: 0.980000  [16550/22500]\n",
            "cost: 0.050917, accuracy: 0.980000  [17050/22500]\n",
            "cost: 0.138918, accuracy: 0.980000  [17550/22500]\n",
            "cost: 0.091615, accuracy: 0.980000  [18050/22500]\n",
            "cost: 0.190812, accuracy: 0.920000  [18550/22500]\n",
            "cost: 0.175400, accuracy: 0.900000  [19050/22500]\n",
            "cost: 0.208953, accuracy: 0.880000  [19550/22500]\n",
            "cost: 0.249225, accuracy: 0.900000  [20050/22500]\n",
            "cost: 0.098763, accuracy: 0.980000  [20550/22500]\n",
            "cost: 0.096932, accuracy: 0.980000  [21050/22500]\n",
            "cost: 0.084132, accuracy: 1.000000  [21550/22500]\n",
            "cost: 0.113280, accuracy: 0.940000  [22050/22500]\n",
            "cost: 0.040759, accuracy: 1.000000  [   50/22500]\n",
            "cost: 0.095562, accuracy: 0.940000  [  550/22500]\n",
            "cost: 0.105085, accuracy: 0.980000  [ 1050/22500]\n",
            "cost: 0.122797, accuracy: 0.980000  [ 1550/22500]\n",
            "cost: 0.061598, accuracy: 0.960000  [ 2050/22500]\n",
            "cost: 0.051547, accuracy: 0.980000  [ 2550/22500]\n",
            "cost: 0.115248, accuracy: 0.960000  [ 3050/22500]\n",
            "cost: 0.035219, accuracy: 0.980000  [ 3550/22500]\n",
            "cost: 0.043582, accuracy: 1.000000  [ 4050/22500]\n",
            "cost: 0.080398, accuracy: 0.980000  [ 4550/22500]\n",
            "cost: 0.086903, accuracy: 0.940000  [ 5050/22500]\n",
            "cost: 0.126641, accuracy: 0.960000  [ 5550/22500]\n",
            "cost: 0.167773, accuracy: 0.940000  [ 6050/22500]\n",
            "cost: 0.033993, accuracy: 1.000000  [ 6550/22500]\n",
            "cost: 0.162942, accuracy: 0.940000  [ 7050/22500]\n",
            "cost: 0.097498, accuracy: 0.960000  [ 7550/22500]\n",
            "cost: 0.027287, accuracy: 1.000000  [ 8050/22500]\n",
            "cost: 0.076828, accuracy: 0.960000  [ 8550/22500]\n",
            "cost: 0.280931, accuracy: 0.920000  [ 9050/22500]\n",
            "cost: 0.053009, accuracy: 0.980000  [ 9550/22500]\n",
            "cost: 0.065881, accuracy: 0.980000  [10050/22500]\n",
            "cost: 0.236140, accuracy: 0.880000  [10550/22500]\n",
            "cost: 0.102872, accuracy: 0.940000  [11050/22500]\n",
            "cost: 0.163395, accuracy: 0.940000  [11550/22500]\n",
            "cost: 0.046199, accuracy: 0.980000  [12050/22500]\n",
            "cost: 0.052520, accuracy: 0.980000  [12550/22500]\n",
            "cost: 0.079201, accuracy: 0.960000  [13050/22500]\n",
            "cost: 0.090389, accuracy: 0.980000  [13550/22500]\n",
            "cost: 0.054883, accuracy: 0.980000  [14050/22500]\n",
            "cost: 0.078315, accuracy: 0.960000  [14550/22500]\n",
            "cost: 0.114060, accuracy: 0.980000  [15050/22500]\n",
            "cost: 0.323761, accuracy: 0.920000  [15550/22500]\n",
            "cost: 0.063601, accuracy: 0.960000  [16050/22500]\n",
            "cost: 0.025441, accuracy: 1.000000  [16550/22500]\n",
            "cost: 0.061528, accuracy: 1.000000  [17050/22500]\n",
            "cost: 0.088123, accuracy: 0.960000  [17550/22500]\n",
            "cost: 0.273027, accuracy: 0.920000  [18050/22500]\n",
            "cost: 0.087216, accuracy: 0.980000  [18550/22500]\n",
            "cost: 0.098316, accuracy: 0.960000  [19050/22500]\n",
            "cost: 0.083415, accuracy: 0.940000  [19550/22500]\n",
            "cost: 0.036847, accuracy: 1.000000  [20050/22500]\n",
            "cost: 0.235814, accuracy: 0.860000  [20550/22500]\n",
            "cost: 0.070226, accuracy: 0.980000  [21050/22500]\n",
            "cost: 0.100666, accuracy: 0.960000  [21550/22500]\n",
            "cost: 0.129714, accuracy: 0.940000  [22050/22500]\n",
            "cost: 0.101977, accuracy: 0.960000  [   50/22500]\n",
            "cost: 0.105635, accuracy: 0.940000  [  550/22500]\n",
            "cost: 0.061518, accuracy: 0.960000  [ 1050/22500]\n",
            "cost: 0.041286, accuracy: 0.980000  [ 1550/22500]\n",
            "cost: 0.047879, accuracy: 0.980000  [ 2050/22500]\n",
            "cost: 0.041876, accuracy: 0.980000  [ 2550/22500]\n",
            "cost: 0.103415, accuracy: 0.960000  [ 3050/22500]\n",
            "cost: 0.068950, accuracy: 0.960000  [ 3550/22500]\n",
            "cost: 0.283262, accuracy: 0.940000  [ 4050/22500]\n",
            "cost: 0.098541, accuracy: 0.940000  [ 4550/22500]\n",
            "cost: 0.023835, accuracy: 1.000000  [ 5050/22500]\n",
            "cost: 0.153156, accuracy: 0.960000  [ 5550/22500]\n",
            "cost: 0.058499, accuracy: 0.960000  [ 6050/22500]\n",
            "cost: 0.095047, accuracy: 0.960000  [ 6550/22500]\n",
            "cost: 0.184505, accuracy: 0.900000  [ 7050/22500]\n",
            "cost: 0.132312, accuracy: 0.940000  [ 7550/22500]\n",
            "cost: 0.099373, accuracy: 0.960000  [ 8050/22500]\n",
            "cost: 0.130330, accuracy: 0.940000  [ 8550/22500]\n",
            "cost: 0.050230, accuracy: 0.980000  [ 9050/22500]\n",
            "cost: 0.110705, accuracy: 0.980000  [ 9550/22500]\n",
            "cost: 0.084185, accuracy: 0.940000  [10050/22500]\n",
            "cost: 0.111538, accuracy: 0.940000  [10550/22500]\n",
            "cost: 0.025748, accuracy: 1.000000  [11050/22500]\n",
            "cost: 0.011239, accuracy: 1.000000  [11550/22500]\n",
            "cost: 0.035896, accuracy: 0.980000  [12050/22500]\n",
            "cost: 0.123866, accuracy: 0.960000  [12550/22500]\n",
            "cost: 0.185457, accuracy: 0.940000  [13050/22500]\n",
            "cost: 0.030260, accuracy: 1.000000  [13550/22500]\n",
            "cost: 0.033498, accuracy: 0.980000  [14050/22500]\n",
            "cost: 0.134586, accuracy: 0.940000  [14550/22500]\n",
            "cost: 0.053522, accuracy: 0.980000  [15050/22500]\n",
            "cost: 0.229921, accuracy: 0.960000  [15550/22500]\n",
            "cost: 0.041489, accuracy: 1.000000  [16050/22500]\n",
            "cost: 0.193743, accuracy: 0.940000  [16550/22500]\n",
            "cost: 0.215160, accuracy: 0.880000  [17050/22500]\n",
            "cost: 0.028627, accuracy: 1.000000  [17550/22500]\n",
            "cost: 0.037446, accuracy: 0.980000  [18050/22500]\n",
            "cost: 0.056822, accuracy: 0.980000  [18550/22500]\n",
            "cost: 0.046294, accuracy: 0.980000  [19050/22500]\n",
            "cost: 0.038652, accuracy: 1.000000  [19550/22500]\n",
            "cost: 0.042933, accuracy: 0.980000  [20050/22500]\n",
            "cost: 0.089033, accuracy: 0.960000  [20550/22500]\n",
            "cost: 0.069766, accuracy: 0.980000  [21050/22500]\n",
            "cost: 0.165873, accuracy: 0.960000  [21550/22500]\n",
            "cost: 0.112437, accuracy: 0.940000  [22050/22500]\n",
            "cost: 0.075290, accuracy: 0.940000  [   50/22500]\n",
            "cost: 0.067343, accuracy: 0.980000  [  550/22500]\n",
            "cost: 0.027082, accuracy: 1.000000  [ 1050/22500]\n",
            "cost: 0.088172, accuracy: 0.960000  [ 1550/22500]\n",
            "cost: 0.028057, accuracy: 1.000000  [ 2050/22500]\n",
            "cost: 0.031001, accuracy: 1.000000  [ 2550/22500]\n",
            "cost: 0.017970, accuracy: 1.000000  [ 3050/22500]\n",
            "cost: 0.100638, accuracy: 0.940000  [ 3550/22500]\n",
            "cost: 0.056884, accuracy: 0.980000  [ 4050/22500]\n",
            "cost: 0.063395, accuracy: 0.960000  [ 4550/22500]\n",
            "cost: 0.125899, accuracy: 0.920000  [ 5050/22500]\n",
            "cost: 0.056494, accuracy: 0.980000  [ 5550/22500]\n",
            "cost: 0.094014, accuracy: 0.960000  [ 6050/22500]\n",
            "cost: 0.069875, accuracy: 0.980000  [ 6550/22500]\n",
            "cost: 0.024754, accuracy: 1.000000  [ 7050/22500]\n",
            "cost: 0.035439, accuracy: 0.980000  [ 7550/22500]\n",
            "cost: 0.019268, accuracy: 1.000000  [ 8050/22500]\n",
            "cost: 0.155981, accuracy: 0.900000  [ 8550/22500]\n",
            "cost: 0.019318, accuracy: 1.000000  [ 9050/22500]\n",
            "cost: 0.148759, accuracy: 0.920000  [ 9550/22500]\n",
            "cost: 0.043795, accuracy: 0.980000  [10050/22500]\n",
            "cost: 0.046536, accuracy: 0.980000  [10550/22500]\n",
            "cost: 0.014985, accuracy: 1.000000  [11050/22500]\n",
            "cost: 0.004324, accuracy: 1.000000  [11550/22500]\n",
            "cost: 0.064968, accuracy: 0.960000  [12050/22500]\n",
            "cost: 0.055595, accuracy: 0.980000  [12550/22500]\n",
            "cost: 0.085750, accuracy: 0.960000  [13050/22500]\n",
            "cost: 0.028543, accuracy: 1.000000  [13550/22500]\n",
            "cost: 0.074000, accuracy: 0.960000  [14050/22500]\n",
            "cost: 0.177725, accuracy: 0.940000  [14550/22500]\n",
            "cost: 0.051512, accuracy: 1.000000  [15050/22500]\n",
            "cost: 0.042713, accuracy: 0.980000  [15550/22500]\n",
            "cost: 0.004674, accuracy: 1.000000  [16050/22500]\n",
            "cost: 0.078549, accuracy: 0.960000  [16550/22500]\n",
            "cost: 0.204703, accuracy: 0.980000  [17050/22500]\n",
            "cost: 0.017011, accuracy: 1.000000  [17550/22500]\n",
            "cost: 0.028476, accuracy: 1.000000  [18050/22500]\n",
            "cost: 0.073612, accuracy: 0.960000  [18550/22500]\n",
            "cost: 0.040010, accuracy: 0.980000  [19050/22500]\n",
            "cost: 0.079231, accuracy: 0.980000  [19550/22500]\n",
            "cost: 0.038267, accuracy: 0.980000  [20050/22500]\n",
            "cost: 0.103807, accuracy: 0.980000  [20550/22500]\n",
            "cost: 0.027981, accuracy: 1.000000  [21050/22500]\n",
            "cost: 0.066998, accuracy: 0.980000  [21550/22500]\n",
            "cost: 0.027372, accuracy: 1.000000  [22050/22500]\n",
            "cost: 0.060784, accuracy: 0.980000  [   50/22500]\n",
            "cost: 0.055737, accuracy: 0.960000  [  550/22500]\n",
            "cost: 0.033471, accuracy: 0.980000  [ 1050/22500]\n",
            "cost: 0.033820, accuracy: 1.000000  [ 1550/22500]\n",
            "cost: 0.019297, accuracy: 1.000000  [ 2050/22500]\n",
            "cost: 0.011829, accuracy: 1.000000  [ 2550/22500]\n",
            "cost: 0.009179, accuracy: 1.000000  [ 3050/22500]\n",
            "cost: 0.023664, accuracy: 1.000000  [ 3550/22500]\n",
            "cost: 0.019785, accuracy: 1.000000  [ 4050/22500]\n",
            "cost: 0.042308, accuracy: 0.980000  [ 4550/22500]\n",
            "cost: 0.099280, accuracy: 0.960000  [ 5050/22500]\n",
            "cost: 0.022262, accuracy: 1.000000  [ 5550/22500]\n",
            "cost: 0.056368, accuracy: 0.960000  [ 6050/22500]\n",
            "cost: 0.033825, accuracy: 0.980000  [ 6550/22500]\n",
            "cost: 0.033934, accuracy: 0.980000  [ 7050/22500]\n",
            "cost: 0.073816, accuracy: 0.960000  [ 7550/22500]\n",
            "cost: 0.037144, accuracy: 1.000000  [ 8050/22500]\n",
            "cost: 0.028040, accuracy: 1.000000  [ 8550/22500]\n",
            "cost: 0.031881, accuracy: 1.000000  [ 9050/22500]\n",
            "cost: 0.013377, accuracy: 1.000000  [ 9550/22500]\n",
            "cost: 0.109675, accuracy: 0.960000  [10050/22500]\n",
            "cost: 0.024697, accuracy: 1.000000  [10550/22500]\n",
            "cost: 0.013207, accuracy: 1.000000  [11050/22500]\n",
            "cost: 0.037950, accuracy: 0.960000  [11550/22500]\n",
            "cost: 0.076851, accuracy: 0.980000  [12050/22500]\n",
            "cost: 0.185551, accuracy: 0.980000  [12550/22500]\n",
            "cost: 0.052766, accuracy: 0.980000  [13050/22500]\n",
            "cost: 0.054232, accuracy: 0.980000  [13550/22500]\n",
            "cost: 0.110658, accuracy: 0.920000  [14050/22500]\n",
            "cost: 0.102732, accuracy: 0.940000  [14550/22500]\n",
            "cost: 0.020200, accuracy: 1.000000  [15050/22500]\n",
            "cost: 0.155995, accuracy: 0.940000  [15550/22500]\n",
            "cost: 0.042406, accuracy: 0.980000  [16050/22500]\n",
            "cost: 0.169997, accuracy: 0.940000  [16550/22500]\n",
            "cost: 0.087327, accuracy: 0.960000  [17050/22500]\n",
            "cost: 0.028171, accuracy: 1.000000  [17550/22500]\n",
            "cost: 0.032858, accuracy: 0.980000  [18050/22500]\n",
            "cost: 0.132379, accuracy: 0.940000  [18550/22500]\n",
            "cost: 0.032352, accuracy: 1.000000  [19050/22500]\n",
            "cost: 0.068036, accuracy: 0.980000  [19550/22500]\n",
            "cost: 0.069788, accuracy: 0.980000  [20050/22500]\n",
            "cost: 0.043381, accuracy: 0.960000  [20550/22500]\n",
            "cost: 0.021922, accuracy: 1.000000  [21050/22500]\n",
            "cost: 0.018968, accuracy: 0.980000  [21550/22500]\n",
            "cost: 0.001888, accuracy: 1.000000  [22050/22500]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQzpJREFUeJzt3Xl4U2X+NvA7Sdt0oU3p3nSnQFsKlEVgwAUFZLGyKMoyvMjiKCou6AwCjgX5CYOow6DoADMKoiyCIDiKioCAIGtbdspWSmnpRte0TZumyXn/KI0U2tKUJCfL/bmuXNrk5OR7ekhz5znPIhEEQQARERGRhUjFLoCIiIgcC8MHERERWRTDBxEREVkUwwcRERFZFMMHERERWRTDBxEREVkUwwcRERFZFMMHERERWZST2AXcTq/XIycnB56enpBIJGKXQ0RERC0gCALKy8uhVCohlTbftmF14SMnJwdhYWFil0FEREStkJWVhdDQ0Ga3sbrw4enpCaCueC8vL5GrISIiopZQqVQICwszfI43x+rCR/2lFi8vL4YPIiIiG9OSLhPscEpEREQWxfBBREREFsXwQURERBbF8EFEREQWxfBBREREFsXwQURERBbF8EFEREQWxfBBREREFsXwQURERBbF8EFEREQWxfBBREREFsXwQURERBbF8EFEViv1Wgk+238F1Vqd2KUQkQlZ3aq2RESVmlp8sOMC1hy6CkEAcsuqkfR4J7HLIiITYcsHEVmV/ZduYPC/fsMXB+uCBwCsOXgVlwvKxS2MiEyG4YOIrEKZWouZ35zExM+P4nppFUK83fDVs70xKC4AtXoB//dDGoT6NEJENo2XXYhIdDvO5iFp2xkUlGsgkQCT+kZi5pAYeMidENbWHfsu3sBvF2/g1/MFGBgXKHa5RHSP2PJBRKIprNBg+vpUTPsqBQXlGrTz98A30/rinRHx8JDXfTeK9PPA1AeiAADv/nAONbV6MUsmIhNg+CAiixMEAduOX8ejS/Zh+6lcyKQSvPhwNH589UHcF+lzx/avDOgAf085rhapsfr3DBEqJiJTYvggIovKLavCs2uSMWPjCZSotYgL9sJ30+/HrKGxcHWWNfqcNnInvDkkBgCw7NfLKCivtmTJRGRiDB9EZBF6vYD1R65h8JLf8Ov5ArjIpPjrox3xv5fvR+cQxV2fP7pHKBJCFajQ1OKDny9YoGIiMheGDyIyu8yiSvz5s8N4a+tplGtq0T3cG9tffQCvDOwAZ1nL/gxJpRLMGxEPAPgmJRsns0rNWDERmRPDBxGZjU4v4LP9VzBk6W84fKUYrs5SJD3eCZtf6IcOgZ5G769HeFs82T0EADD/+7McektkozjUlojM4mJ+Od7cfAonbrZQ9Iv2xXtPdkW4r/s97XfWsFj8fDYPqddKse3EdTzRPdQE1RKRJbHlg4hMSqvT4+Pdl5D48X6cyCqFp9wJi57sgnV/6XPPwQMAAr1cMf2R9gCA9346j0pN7T3vk4gsi+GDiEzmdHYZhi87gCU7L0KrEzAwNgC/vPEQxvcOh0QiMdnrPPtAFMJ93JGv0uDfey+bbL9EZBkMH0R0z6q1Orz303mM+vfvOJ9XjrbuzvhoXDd8Nuk+BCvcTP56rs4y/D0xDgDw3/0ZuFakNvlrmEJBeTVbZogawT4fRHRPjmYUY/aWU7hSWAkAeLxrMN4ZEQ+/NnKzvu7gToF4oL0fDlwuxMIfz2HlxPvM+nrG2nkuHy+tS4GTVIqhnYPwVM9Q9G3nC6nUdC1ARLZKIlhZd3GVSgWFQoGysjJ4eXmJXQ4R3aTTC8gorMDZHBXScstxLleFczkqFFZoAAABnnIsGNUZg+ODLFbTxfxyDPtoP3R6Aev+0gf3t/ez2Gs3JyWzBBM+O4xqbcOp4JUKVzzRIwSje4SinX8bkaojMg9jPr8ZPojoDhWaWpzPVSEtV2UIGRfyy+/4MAUAqQR4umcY3kqMg8LN2eK1vvO/s/ji4FXEBHpi+6sPwKmF84aYy+WCCjy14iBK1Vo8EuOPlwe0x7ep1/H9yRyoqv+4BNMj3Buje4bi8a5KUX5vRKbG8EFELSIIAnLLqutCRk5d0EjLVeFqE30o3JxliAv2RFywFzopvdAp2AsxQZ5wdxHvCm6pugaPfLgXJWot/m9kPJ7pGylaLfmqajz574O4XlqFhDBvbHiuj+F3U63VYVdaPrakZGPfxRvQ3/zL6+IkxeBOgXiqZyge7OAPGS/LkI1i+CCiO2h1elwuqGgQMs7lqlCq1ja6fZCXK+KCPW+GDAXigj0R4ethlR+OXx3ORNK2M1C4OWPv3x5GWw8Xi9egqtZi7MrDSMtVIcrPA5tf6AvfJvq9FKiqse3EdWxJuY4L+eWG+wM85XiiewhG9wxFx1ZMwkYkJoYPIoIgCEjOLMG249dx/FopLhdUoEZ352UTmVSC9v5tDC0ZccFeiAv2bPKD0xrV6vR4fNkBnM8rxzN9I/B/Iztb9PU1tTpMWX0MB9OL4NdGjm9f7NeiOU0EQcDZHBU2p2TjuxPXUXJLEOwaqsDoHqEYkaAUJUwRGYvhg8iBZZeo8W3qdXybmn3H5RNPuRPiboaMTjcvnbQPaNPkarK25FB6Ecb/9zCkEuDH1x5EbJBl/n7o9QJe23gC35/MgYeLDBun9W3RQnm3q6nV49fzBdiSmo095wtQe/O6jLNMgoGxgRjdMxQPx/i3eC0cIktj+CByMJWaWvx0Jg9bUrJx6EqR4X53Fxke6xKMQXGBiFd6IbStm0kn+7I2L61LwY+n89C3nS/WP9fHIse64Idz+OxABpykEqye0gsPdvC/530WVWjw3YkcbEnNxtkcleF+Xw8XjOwWgqd6hqKTkn8fybowfBA5AL1ewOGMImxJuY6fzuRCXaMzPNYv2heje4RiaOcgeMgdZzqfrGI1Bi3ZB02tHiv+Xw8M7Rxs1tf7bP8VLNieBgBYOrYbRt1c9M6U0nJV2JKSjW0nrqOwosZwf1ywF0b3CMHDMf6I9m9j16GSbIPZwodOp8M777yDtWvXIi8vD0qlEpMnT8bbb7/d4B9+WloaZs2ahX379qG2thadOnXCli1bEB4ebtLiiRxRZlEltqRkY0vqdVwvrTLcH+nrjtE9QvFEjxCEtr33NVRs1ZJfLuDjXy8jtK0bdr3R32yXlL47cR2vfX0CADBnWCym9Y82y+vU0+r0+O3iDWxJzcaucwUN+u+0dXdGz4i2uC/SB70i26JziAJyJ9u/lEa2xZjPb6O+Ei1evBjLly/HmjVrEB8fj+TkZEyZMgUKhQKvvvoqACA9PR0PPPAAnn32WcyfPx9eXl44e/YsXF1dW39ERA6uvFqL7adysSU1G8eulhju95Q74fGEYIzuEYqeEW357RfACw9H45uUbGSXVOGz/Vfw8oAOJn+N3y8X4m/fnAQATLk/Es8/1M7kr3E7Z5kUA+MCMTAuEKXqGnx/MgfbT+fi+LVSlKi12JVWgF1pBQDqhu8mhCrQM6IujPSMaAtvd3ZaJethVMvH448/jsDAQHz++eeG+0aPHg03NzesXbsWADBu3Dg4Ozvjq6++alVBbPkgqqPTCziYXojNKdnYcTbPMMGXVAI80MEfo3uEYEh8kF10FjW1+lYJN2cZfv1bf5OuL3M2pwxjVx5GhaYWiV2DsWxcd1GnTK+p1eNsThmSr5YgObMYyVdLUFRZc8d2HQLa4L5IH9wX0Ra9In0Q5mPf/X/I8sx22eUf//gH/vOf/+CXX35Bx44dcfLkSQwePBhLlizBhAkToNfroVAo8Oabb+LAgQM4fvw4oqKiMGfOHIwaNarRfWo0Gmg0mgbFh4WFMXyQw7pcUIEtqdnYmnodeapqw/3tA9rUXVbpHoIgBVsSmyMIAp5ecQjJmSUY1U2JpeO6m2S/WcVqPLn8IG6Ua/Cndj5YM7W31V3eEAQBGYWVSM4sQfLVYiRnluDKjco7tgvwlOO+yLa4L8IHvSJ9EBfsKfrssGTbzBY+9Ho93nrrLbz//vuQyWTQ6XRYuHAh5syZAwDIy8tDcHAw3N3dsWDBAjzyyCP4+eef8dZbb2HPnj3o37//Hft85513MH/+/DvuZ/ggR1Km1uL7UznYnJKNE1mlhvsVbs4YkaDE6J6hSAhV8JuqEU5nl2HEpwcgCMCWF/uiZ4TPPe2vpLIGo1ccxJUblYgN8sSmF/rCy9U2pkUvqtAgObMEKZklOHa1GGeul0Gra/in391Fhu7h3oZLNd3D26KNA3VWpntntvDx9ddfY+bMmfjggw8QHx+PEydOYMaMGViyZAkmTZqEnJwchISEYPz48Vi/fr3heSNGjICHhwc2bNhwxz7Z8kHWqlanx+ErxfjpTC5SMkugN9PAMEEAMovVqKmtu6wik0rwcEd/jO4ZioFxAVb3zdqWzNp8ChuTs9AlRIHvpt/f6ssjVTU6/Pmzwzh+rRQh3m7Y8mI/m259qtbqcDKrtEHrSPkt684AdZf37ovwwZKxCQ7dgZlazmwdTmfOnInZs2dj3LhxAIAuXbogMzMTixYtwqRJk+Dn5wcnJyd06tSpwfPi4uJw4MCBRvcpl8shl9vOTIpk32pq9fg9vRA/nc7FznP5DWacNLfYIE881TMUI7opEeBpux9s1mTm0Bj8eDoXp6+XYXNKNsb0CjN6H7U6PV7ZkIrj10qhcHPGmqm9bDp4AICrswx92vmiTztfAHXDti8VVODY1WJDGMkuqcLRq8WYsvoYNr/Yj4vfkUkZFT7UajWk0obXBGUyGfT6um9sLi4u6NWrFy5cuNBgm4sXLyIiIuIeSyUyj2qtDr9dvIGfz+RhZ1p+g2+Abd2dMSQ+CI/EBsDTjE3Qfp5ydAjgXA2m5tdGjtcGdcCC7Wl4f8d5DO0SZNSlEkEQkPTdGexKK4DcSYrPJ92H9gH2t+aKVCpBTJAnYoI88f/+VPe3+sqNCoz/72FcKqjA9HWpWD2lF2dXJZMx6q/p8OHDsXDhQoSHhyM+Ph7Hjx/HkiVLMHXqVMM2M2fOxNixY/HQQw8Z+nx8//332Lt3r6lrJ2o1dU0t9l64gR9P52LP+QJU3jJBl7+nHEPiA/FY52D0jvJhJzwb90zfSKw/eg1XblTik18v463H4lr83I92X8KGo1mQSoCPx3fHfZH31m/ElrTzb4PPJ/XCmJWHcOByIZK2ncGiJ7swIJNJGNXno7y8HElJSdi6dSsKCgqgVCoxfvx4zJ07Fy4uf4whX7VqFRYtWoTs7GzExMRg/vz5GDlyZIteg0NtyVzKq7X49XwBfjqdh70XCwxDVwEgWOGKoZ2D8FiXYPQIb2uVK7dS6+25UIApq4/BWSbBjhkPoZ1/m7s+Z/2Ra3hr62kAwIJRnQ0tAo5md1o+nvsyGXoBmD0sFi+YeTI1sl2cXp3opjK1FjvT8vHT6Vzsv1TYYFbIMB83PNY5GEM7ByEh1FvUuRrI/KasPoo9F25gQGwAVk3u1ey2O8/lY9pXdR+4rwxoj78OjrFQldZp9e8ZmP/9OQDAvyf0wGNdzDttPdkms3U4JbIFRRUa/HIuHz+dycPBy4WG1UEBoJ2fB4Z1CcKwzsGIV3qxCdmBJD3eCfsv/YZfzxdgz4UCPBIT0Oh2KZkleGVDKvQCMOa+ULzxaEcLV2p9ptwfhcwiNb44eBWvbzyBIIUreoS3FbsssmEMH2QXClTV2HE2Dz+ezsORjCLckjcQE+hpCBwdA9mp01G182+DKfdH4r/7M/DuD+dwf7QfXJwa9ue5XFCBZ9ccQ7VWj0di/LHwCfZxqJf0eCdkFaux+3wBnluTjG3T70eYD4fgUuvwsgvZNK1Oj09+vYxP91xu0MLROcQLwzoHY1jnoBZd3yfHoKrWYsCHe1FYUYO3E+Pwlwf/WJMlX1WNJ/99ENdLq5AQ5o0Nz/WBuwu/n92qUlOLMSsP4WyOCtH+Hvj2pfs5BJcM2OeDHMKVGxV4fdNJnLw5I2hCmDcSb7Zw8BsZNWXjsWuYteU0POVO2DPzYfi1kUNVrcXYlYeRlqtClJ8HNr/QF75tOP9QY/LKqjHq09+Rp6pGv2hffDGl9x0tSGTdqrU6aGr1Jg+Oxnx+818M2RxBELD2cCYSPz6Ak1ml8HJ1wkfjuuG76ffj+YeiGTyoWU/3DEOXEAXKNbX4cMcFaGp1eOGrFKTlquDXRo41U3ozeDQjSOGKVZN7wcNFhoPpRXh722lY2XdYakZ2iRpPrTiIl9enQqcX77wxfJBNKSivxrNrkvH2tjOo0urQL9oXP894CCO7hYhdGtkIqVSCd0bUzcK8MTkLU1Yfw8H0Ini4yPDFlF4I92V4vZtOSi988ucekEqATcnZ+PfedLFLohb4/XIhhi87gDPXVThzvQyZRXcuOGgpDB9kM345m4ehS/fj1/MFcHGS4u3EOKx9tg+U3qZbLp0cQ88IH4zspoQgAAfTi+AklWDFxJ7oHKIQuzSb8UhsAOaPiAcAfLDjAr4/mSNyRdQUQRCwcl86Jn5+BCVqLbqEKPD9Kw+I2h+OvanI6lVoavHu9+ewMTkLQN0aKB+N646YIPub5posZ/awWOw8lw91jQ4fPN0VD3bwF7skmzOxbyQyCtVY9XsG/vrNSSi9Xe959WAyrUpNLd7cfArbT+cCAJ7qGYoFozrD1VncBSvZ4ZSsWkpmMV7feBLXitWQSIDnH2qHNx7tyJVeySTSclUor65F7yh+YLaWTi9g2lcp2JWWDx8PF2x9qR8ifD3ELosAZBRWYtpXybiYXwFnmQRzh8fj//UJN9vwcY52IZun1enx0a5L+Pfey9ALQIi3G/45JgF/urkKJxFZD3VN3RDcM9dVaOfvga0v3g+Fu/0Owa3U1OLo1WL8KcoXbi7W+UVod1o+Znx9AuWaWgR4yrH8//Uwe6sUwwfZtMsFFXh94wmcvl4GAHiyewjeGRlv1GqkRGRZ+apqPPHp78gpq8af2vngy6l97HII7q2tsUFervjbkBg82T3EapZn0OsFfLT7Ej7afQkAcF9EW/x7Qg8EeLma/bUZPsgmCYKALw9l4h8/phnGoP/jiS5I7Mp1JIhsQVquCk+vOIQKTS1G9wjFh093tZsZYm9vjZVKYJhJOV7phb8nxqFftJ+oNZZVafHGxhPYfb4AADCpbwT+ntjJYiGQ4YNsTr6qGjM3n8JvF28AAB7s4IcPnkpAkML8aZ2ITGffxRuY+sUx6PQC/vpoR7wysIPYJd2zO1pje4TgrcfisDklG5/+ehnlmloAwKC4AMx5LA7RIowiuZBXjmlfJeNqkRpyJykWPtEFT/UMtWgNDB9kU346nYs5W0+jVK2F3EmKOcNi8UzfSKtpxiQi46w7kom/bz0DAPhoXDebnYfn9tZYb/e61thbV/UtqtDgo92XsO7INej0ApykEkzoE47XBnWEj4eLRer84VQO3tx8CuoaHUK83bBSpGHjDB9kE8qrtXjnf+ewJTUbQF3T5dKx3dAhkENoiWzdwu3n8N/9GXCRSbHuuT7oFWlbI4pub419qKM/PniqKwKb6DtxuaAC7/2Uhl1pdZc8PF2d8PIj7TGpX6TZhrXW6vT4YMcFrPztCgDg/va+WDa+h8VCz+0YPsjqHc0oxusbT+B6aRWkEuCF/tGYMaijXXZQI3JEer2AF9elYMfZfLR1d8bWl+5HpJ9tDMG9vTX2rcfi8EzfiBb1Xzl4uRALtqfhXK4KABDa1g2zhsbi8a7BJu3/UlxZg1c2pOL3y0UAgGn922Hm4Bg4ycT7G8rwQVarplaPJTsvYuVv6RAEIMzHDUvGdLO5b0VEdHdVNTqM+88hnMwuQ5SfB759sR/aivStvCVub43tHFLXGts+wLjWWJ1ewLep2fjwlwvIV2kAAN3DvfF2Yif0jGh7z3Wezi7DC2tTcL20Cu4uMnzwVIJVdMxn+CCrdDG/HDO+PmH4RvB0z1DMHd4JnhxCS2S3Csqr8cSnB3G9tAq9o3zw1bO9rXKSwKMZxXhj0wlkl9S1xr74cDReG3hvrbHqmlr897cMrPwtHeoaHQAgsUswZg2NbfUaQptTsvHW1tOoqdUjys8DKyf2REcruVTN8EFW56tDV/Hu9jTU1OrR1t0Zi57sgqGdxU/qRGR+F/LK8dTygyjX1OKJ7iFYMibBaobg1tTq8a9dF7Fi3x+tsf8a0w33mbA1tkBVjX/+chGbUrIgCICLTIpJ/SLw8oAOLV7WvqZWj3d/OIevDmcCAAbGBmDJ2G4tfr4lMHyQVdl+KhfT16cCAB6O8cf7o7taZMIbIrIe+y/dwOTVdUNwZwzqgBmDOopd0h2tsWPuC8Xc4fFoIzfPsmdpuSr848c07L9UCABo6+6M1wZ2wIQ/RcC5mb4aBapqvLQuFcmZJQCAGYM64NUBHaxuRCDDB1mNa0VqJH68H+WaWvzlgSj8PTHOar7xEJFlbTh6DXO+PQ0A+NfYBDzR3bLzUNTT6wV8cfAq3vv5/C2tsV0xtHOQ2V9bEATsvXgD/9iehksFFQCAdn4emD0sFo92Crzj72Py1WK8uC4VN8o18HR1wtKx3TAwLtDsdbYGwwdZhZpaPZ5acRCnsstwX0RbfP38n0TtiU1E4nvvp/NYsS8dzjIJVk3uhQfa+1n0C0leWTX+9s1JHLhc1/rwcIw/3n+qKwI8LdsaW6vTY2NyFv618yIKK2oAAH2ifPB2Yid0CVVAEASsPZyJ+d+fQ61eQMfANlg58T5EWfGIIYYPsgoLfjiHzw5kQOHmjB9fexAh3m5il0REItPrBby8IRU/ns4DAHi5OiEu2AudlF7oFOyFuGAvdAhsY5ZOqd+fzMHb286grEoLV2cp/p7YyayrvLZEebUWK/al47P9GdDU6gHUrWclkUgMo24Suwbj/dFd4WGmy0GmwvBBotudlo9n1yQDAP77zH14tJN1NhMSkeVVa3WY8fUJ7D6fD63uzo8gJ6kE7QPaGAJJfShp7TDdsiot5n13BttO5AAAEkIVWDK2myjToDflemkVPtxxAVuPXzfcJ5UAs4fF4rkH29nE5WqGDxJVblkVhn20H6VqLabcH4l5w+PFLomIrFBNrR6XCypwLleFczkqnMstQ1puOcqqtI1uH6xwrQsjyrow0inYC+E+7s12vDyUXoS/bjqBnLJqSCXAywM64JUB7Zvt4CmmU9mleO+n88gsUuP9p7ri/vbiLlZnDIYPEk2tTo/x/z2MY1dL0CVEgc0v9rXKMf1EZJ0EQUBOWTXO5aiQZgglKlwrVje6vYeLDLE3g0h9KIkJ9IRUCvzzl4v47/4rEAQgwtcd/xrbDT3C732SL2qcMZ/f1n0BiWzOR7sv4djVErSRO+GTP3dn8CAio0gkEoR4uyHE263B5dryai3O55XXhZEcFdLyVDifV47KGh1SMkuQcnMYKlB3ucLLzRml6roWlPG9w/B2Yier7zPhSHgmyGQOXCrEJ3suAwD+8WQXRPhab69sIrItnq7O6BXp02AphlqdHlcKKxu0kJzLUaGosgalai18PVzw3uiu7HNmhRg+yCRulGswY+MJCELdt4wRCUqxSyIiO+ckk6JjoCc6BnpiZLcQAHWXbW6Ua5BRWInYYC+rmgGU/sDwQfdMrxfw+sYTKKzQICbQE3MfZwdTIhKHRCJBgJcrZ1G2ctbZ3ZdsyvJ96ThwuRCuzlJ88ufucHNhPw8iImoawwfdk2NXi7Fk50UAwP+N7IwOVrK6IhERWS+GD2q1ksoavLrhOHR6AU90D8HTPcVZp4GIiGwLwwe1iiAImLn5JHLLqhHl54F3R3W2iRn4iIhIfAwf1Cqrfr+KXWkFcHGq6+dhriWoiYjI/jB8kNHqpv9NAwC8nRiHeKVC5IqIiMiWMHyQUVTVWry8/ji0OgFD44Mw8U8RYpdEREQ2huGDWkwQBMz59jSuFasR4u2GxU91ZT8PIiIyGsMHtdiGo1nYfioXTlIJlv25O2cOJCKiVmH4oBY5n6fC/O/PAgBmDonhypBERNRqDB90V+qaWkxflwpNrR4Px/jjuQfbiV0SERHZMIYPuqt5351F+o1KBHrJ8c+nEyCVsp8HERG1HsMHNevb1Gx8k5INqQT4aFx3+LaRi10SERHZOIYPalL6jQq8ve0MAOC1gR3xp3a+IldERET2wKjwodPpkJSUhKioKLi5uSE6OhrvvvsuBEFodPsXXngBEokES5cuNUWtZEHVWh1eXn8c6hod+rbzxcsD2otdEhER2Qmj5sRevHgxli9fjjVr1iA+Ph7JycmYMmUKFAoFXn311Qbbbt26FYcPH4ZSqTRpwWQZC7enIS1XBV8PFywd1w0y9vMgIiITMSp8HDx4ECNHjkRiYiIAIDIyEhs2bMDRo0cbbHf9+nW88sor2LFjh2Fbsh0/nc7FV4czAQD/HJOAQC9XkSsiIiJ7YlT46NevH/7zn//g4sWL6NixI06ePIkDBw5gyZIlhm30ej0mTpyImTNnIj4+/q771Gg00Gg0hp9VKpUxJTmMczkqfLDjPLzcnBHh444IXw9E+tX919fDxWQzjWYVq/HmllMAgBf6R+PhmACT7JeIiKieUeFj9uzZUKlUiI2NhUwmg06nw8KFCzFhwgTDNosXL4aTk9Mdl2GasmjRIsyfP9+4qh3Ql4euYs+FG40+1kbuhHAfd0MYifR1R7hPXTgJ9HRt8dDYmlo9Xt5wHOXVtegR7o2/Du5oykMgIiICYGT42LRpE9atW4f169cjPj4eJ06cwIwZM6BUKjFp0iSkpKTgo48+Qmpqaou/ic+ZMwdvvPGG4WeVSoWwsDDjjsIBpN+oAACMSFDCQy5DZpEamUVq5JRVoUJTi3O5KpzLvbPVSO4kRUR9GPF1R4Rf3X8jfT0QrHCFk+yPPscf/nIBJ7NK4eXqhI/Hd4ezjIOhiIjI9CRCU0NVGhEWFobZs2dj+vTphvsWLFiAtWvX4vz581i6dCneeOMNSKV/fGjpdDpIpVKEhYXh6tWrd30NlUoFhUKBsrIyeHl5GXc0dqznuztRVFmDH155AJ1D/ljCvlqrQ3ZJXRC5WqRGZlElrhapca2oElklVdDpmz69TlIJwnzcEeHrDr82cmxOyQYArJzYE0Pig8x+TEREZD+M+fw2quVDrVY3CBYAIJPJoNfrAQATJ07EoEGDGjw+ZMgQTJw4EVOmTDHmpegWZWotiiprAABRfh4NHnN1lqF9gCfaB3je8TytTo+c0ipDGGkQTorVqKnVI6OwEhmFlYbnTO4XyeBBRERmZVT4GD58OBYuXIjw8HDEx8fj+PHjWLJkCaZOnQoA8PX1ha9vw4monJ2dERQUhJiYGNNV7WDSC+suuQR5ucJD3vJT5iyTIsLXAxG+HgD8Gzym1wvIU1XjalGl4RKOs0zC+TyIiMjsjAofy5YtQ1JSEl566SUUFBRAqVRi2rRpmDt3rrnqIwBXbtS1TLTz97jLli0nlUqg9HaD0tsN/aJNtlsiIqK7Mip8eHp6YunSpUbNWNqSfh7UvCs3O5uaMnwQERGJhcMZbICh5cOvjciVEBER3TuGDxtwpZAtH0REZD8YPqycTi/gapEaABDtz5YPIiKyfQwfVu56SRVqavVwcZJC6e0mdjlERET3jOHDytUPs43y9eDKskREZBcYPqycOYbZEhERiYnhw8pxmC0REdkbhg8rx2G2RERkbxg+rByH2RIRkb1h+LBiFZpa5Ks0AIB2HGZLRER2guHDimXcvOTi18YFCjdnkashIiIyDYYPK2a45ML+HkREZEcYPqxYOofZEhGRHWL4sGIcZktERPaI4cOKcZgtERHZI4YPK6XXC8go5GUXIiKyPwwfVipPVY0qrQ5OUgnCfNzFLoeIiMhkGD6sVP0ll3BfdzjLeJqIiMh+8FPNSnGYLRER2SuGDytV3/IRzf4eRERkZxg+rFQ6h9kSEZGdYviwUoZhtlzThYiI7AzDhxWq1uqQU1YFAGjnx5YPIiKyLwwfViijsBKCACjcnOHj4SJ2OURERCbF8GGFrtyypotEIhG5GiIiItNi+LBChjVdOMyWiIjsEMOHFbrCadWJiMiOMXxYofqWD87xQURE9ojhw8oIgsBhtkREZNcYPqzMjQoNyjW1kEqACF8uKEdERPaH4cPK1Ld6hLZ1h9xJJnI1REREpsfwYWVuHWZLRERkjxg+rAyH2RIRkb1j+LAyHGZLRET2juHDylzharZERGTnGD6sSE2tHlkldQvKRXOYLRER2SmGDytyrbgSOr0ADxcZAjzlYpdDRERkFgwfViT9lsnFuKAcERHZK4YPK1I/zDbKj/09iIjIfjF8WBF2NiUiIkfA8GFF/hhmy86mRERkvxg+rMgfE4yx5YOIiOwXw4eVKKmsQYlaC4CXXYiIyL4xfFiJK4V1rR7BCle4uziJXA0REZH5GBU+dDodkpKSEBUVBTc3N0RHR+Pdd9+FIAgAAK1Wi1mzZqFLly7w8PCAUqnEM888g5ycHLMUb0+4oBwRETkKo75iL168GMuXL8eaNWsQHx+P5ORkTJkyBQqFAq+++irUajVSU1ORlJSEhIQElJSU4LXXXsOIESOQnJxsrmOwC4bOplxQjoiI7JxR4ePgwYMYOXIkEhMTAQCRkZHYsGEDjh49CgBQKBTYuXNng+d88skn6N27N65du4bw8HATlW1/OMyWiIgchVGXXfr164fdu3fj4sWLAICTJ0/iwIEDGDZsWJPPKSsrg0Qigbe39z0Vau+u3OAwWyIicgxGtXzMnj0bKpUKsbGxkMlk0Ol0WLhwISZMmNDo9tXV1Zg1axbGjx8PLy+vRrfRaDTQaDSGn1UqlTEl2QWdXkBmkRoAh9kSEZH9M6rlY9OmTVi3bh3Wr1+P1NRUrFmzBh9++CHWrFlzx7ZarRZjxoyBIAhYvnx5k/tctGgRFAqF4RYWFmb8Udi47BI1anR6yJ2kCPF2E7scIiIis5II9UNVWiAsLAyzZ8/G9OnTDfctWLAAa9euxfnz5w331QePK1eu4Ndff4Wvr2+T+2ys5SMsLAxlZWVNtpbYmz3nCzDli2OIDfLEzzMeErscIiIio6lUKigUihZ9fht12UWtVkMqbdhYIpPJoNfrDT/XB49Lly5hz549zQYPAJDL5ZDLHXv5+HR2NiUiIgdiVPgYPnw4Fi5ciPDwcMTHx+P48eNYsmQJpk6dCqAueDz11FNITU3FDz/8AJ1Oh7y8PACAj48PXFxcTH8EdoDDbImIyJEYFT6WLVuGpKQkvPTSSygoKIBSqcS0adMwd+5cAMD169fxv//9DwDQrVu3Bs/ds2cPHn74YZMUbW84zJaIiByJUeHD09MTS5cuxdKlSxt9PDIyEkZ0IaGbOMyWiIgcCdd2EVl5tRYF5XUdbtnyQUREjoDhQ2QZN/t7+LWRw8vVWeRqiIiIzI/hQ2RcUI6IiBwNw4fI6jubRjN8EBGRg2D4EFk6h9kSEZGDYfgQGS+7EBGRo2H4EJFeLyCjsH6OD7Z8EBGRY2D4EFGuqhrVWj2cZRKEteWCckRE5BgYPkRU39k03McdTjKeCiIicgz8xBMRZzYlIiJHxPAhIq7pQkREjojhQ0T1q9lGc5gtERE5EIYPEXGYLREROSKGD5FU1ehwvbQKAPt8EBGRY2H4EEn9gnLe7s7w8XARuRoiIiLLYfgQyZX6ycX8eMmFiIgcC8OHSDjMloiIHBXDh0g4zJaIiBwVw4dIrnA1WyIiclAMHyIQBMFw2SWaLR9ERORgGD5EcKNcgwpNLaQSINzXXexyiIiILIrhQwTpN1s9wnzcIXeSiVwNERGRZTF8iIDDbImIyJExfIiAw2yJiMiRMXyIgMNsiYjIkTF8iIDDbImIyJExfFiYplaHrGI1AA6zJSIix8TwYWHXitTQC0AbuRP8PeVil0NERGRxDB8Wlm7obOoBiUQicjVERESWx/BhYRxmS0REjo7hw8I4zJaIiBwdw4eFcZgtERE5OoYPC+MwWyIicnQMHxZUXFmDUrUWABDFPh9EROSgGD4sqP6SS4i3G9xcuKAcERE5JoYPC7pyyzBbIiIiR8XwYUHpHGZLRETE8GFJHGZLRETE8GFR9X0+2NmUiIgcGcOHhdTq9Lh2c0E59vkgIiJHxvBhIVklVdDqBLg6S6FUuIldDhERkWgYPiyk/pJLpK8HpFIuKEdERI6L4cNC6jubRrOzKREROTiGDwsxrGbL/h5EROTgGD4sJJ0TjBEREQEwMnzodDokJSUhKioKbm5uiI6OxrvvvgtBEAzbCIKAuXPnIjg4GG5ubhg0aBAuXbpk8sJtjWGODy4oR0REDs6o8LF48WIsX74cn3zyCdLS0rB48WK8//77WLZsmWGb999/Hx9//DFWrFiBI0eOwMPDA0OGDEF1dbXJi7cVqmotCis0ANjyQURE5GTMxgcPHsTIkSORmJgIAIiMjMSGDRtw9OhRAHWtHkuXLsXbb7+NkSNHAgC+/PJLBAYGYtu2bRg3bpyJy7cN9a0e/p5yeLo6i1wNERGRuIxq+ejXrx92796NixcvAgBOnjyJAwcOYNiwYQCAjIwM5OXlYdCgQYbnKBQK9OnTB4cOHWp0nxqNBiqVqsHN3tQPs+WaLkREREa2fMyePRsqlQqxsbGQyWTQ6XRYuHAhJkyYAADIy8sDAAQGBjZ4XmBgoOGx2y1atAjz589vTe02g2u6EBER/cGolo9NmzZh3bp1WL9+PVJTU7FmzRp8+OGHWLNmTasLmDNnDsrKygy3rKysVu/LWtUPs41mfw8iIiLjWj5mzpyJ2bNnG/pudOnSBZmZmVi0aBEmTZqEoKAgAEB+fj6Cg4MNz8vPz0e3bt0a3adcLodcLm9l+bbhCofZEhERGRjV8qFWqyGVNnyKTCaDXq8HAERFRSEoKAi7d+82PK5SqXDkyBH07dvXBOXaHr1eQEYhh9kSERHVM6rlY/jw4Vi4cCHCw8MRHx+P48ePY8mSJZg6dSoAQCKRYMaMGViwYAE6dOiAqKgoJCUlQalUYtSoUeao3+pdL62CplYPZ5kEoW25oBwREZFR4WPZsmVISkrCSy+9hIKCAiiVSkybNg1z5841bPPmm2+isrISzz//PEpLS/HAAw/g559/hqurq8mLtwVXbrZ6RPh6wEnGCWWJiIgkwq3Tk1oBlUoFhUKBsrIyeHl5iV3OPVv9ewbmf38OgzsF4j/P3Cd2OURERGZhzOc3v4qbGYfZEhERNcTwYWZczZaIiKghhg8zq2/54BwfREREdRg+zEhdU4vcsroF9TjMloiIqA7DhxnVz+/R1t0ZbT1cRK6GiIjIOjB8mBE7mxIREd2J4cOMDOGDq9kSEREZMHyY0R8jXdjyQUREVI/hw4y4oBwREdGdGD7MRBAEXLlR1/LBYbZERER/YPgwk4JyDSprdJBJJQj3YfggIiKqx/BhJuk3Wz3C2rrBxYm/ZiIionr8VDQTDrMlIiJqHMOHmXCYLRERUeMYPsyEw2yJiIgax/BhJhxmS0RE1DiGDzPQ1OqQXaIGwPBBRER0O4YPM8gsUkMvAJ5yJ/i3kYtdDhERkVVh+DCD+snF2vl7QCKRiFwNERGRdWH4MIN0DrMlIiJqEsOHGXCYLRERUdMYPsyAw2yJiIiaxvBhYnULynGYLRERUVMYPkysuLIGZVVaSCRAFC+7EBER3YHhw8SuFNa1eigVbnB1lolcDRERkfVh+DCxW4fZEhER0Z0YPkysvr9HNDubEhERNYrhw8TS2dmUiIioWQwfJmYYZuvHlg8iIqLGMHyYkFanx7UiLihHRETUHIYPE8oqVqNWL8DNWYYgL1exyyEiIrJKDB8mVN/ZNMrPA1IpF5QjIiJqDMOHCf0xrTovuRARETWF4cOErnA1WyIiorti+DChP+b4YMsHERFRUxg+TIjDbImIiO6O4cNEyqq0KKyoAQBEseWDiIioSQwfJlK/pkuApxxt5E4iV0NERGS9GD5M5PT1MgBATJCnyJUQERFZN4YPEzmSUQwA6B3pI3IlRERE1o3hwwQEQcDR+vARxfBBRETUHIYPE8gsUuNGuQYuMikSwrzFLoeIiMiqMXyYQH2rR0KYAq7OMpGrISIism4MHyZwhJdciIiIWsyo8BEZGQmJRHLHbfr06QCAvLw8TJw4EUFBQfDw8ECPHj2wZcsWsxRuTY5eLQIA9I7yFbkSIiIi62fUhBTHjh2DTqcz/HzmzBk8+uijePrppwEAzzzzDEpLS/G///0Pfn5+WL9+PcaMGYPk5GR0797dtJVbidyyKmQVV0EqAXpGtBW7HCIiIqtnVMuHv78/goKCDLcffvgB0dHR6N+/PwDg4MGDeOWVV9C7d2+0a9cOb7/9Nry9vZGSkmKW4q1BfX+PeKWCk4sRERG1QKv7fNTU1GDt2rWYOnUqJBIJAKBfv37YuHEjiouLodfr8fXXX6O6uhoPP/xwk/vRaDRQqVQNbraEQ2yJiIiM0+rwsW3bNpSWlmLy5MmG+zZt2gStVgtfX1/I5XJMmzYNW7duRfv27Zvcz6JFi6BQKAy3sLCw1pYkCoYPIiIi47Q6fHz++ecYNmwYlEql4b6kpCSUlpZi165dSE5OxhtvvIExY8bg9OnTTe5nzpw5KCsrM9yysrJaW5LFFVfW4FJB3ZouvTizKRERUYu0qpNCZmYmdu3ahW+//dZwX3p6Oj755BOcOXMG8fHxAICEhATs378fn376KVasWNHovuRyOeRyeWvKEN2xq3WtHh0C2sDHw0XkaoiIiGxDq1o+Vq9ejYCAACQmJhruU6vVdTuUNtylTCaDXq+/hxKtFy+5EBERGc/o8KHX67F69WpMmjQJTk5/NJzExsaiffv2mDZtGo4ePYr09HT885//xM6dOzFq1ChT1mw1GD6IiIiMZ3T42LVrF65du4apU6c2uN/Z2Rk//vgj/P39MXz4cHTt2hVffvkl1qxZg8cee8xkBVuLCk0tzuaUAWD4ICIiMobRfT4GDx4MQRAafaxDhw4OMaMpAKRklkAvAGE+bghWuIldDhERkc3g2i6tdDTj5pTqkZxSnYiIyBgMH61U39+jDy+5EBERGYXhoxWqtTqczGJ/DyIiotZg+GiFk1mlqNHp4e8pR4Svu9jlEBER2RSGj1a4dYht/bo2RERE1DIMH61w9Cr7exAREbUWw4eRanV6pGSWAGB/DyIiotZg+DDS2RwV1DU6KNyc0THAU+xyiIiIbA7Dh5Hq+3v0imwLqZT9PYiIiIzF8GGkI1zPhYiI6J4wfBhBrxdw7Gp9+ODMpkRERK3B8GGESwUVKKvSwt1Fhnill9jlEBER2SSGDyPUr+fSI7wtnGX81REREbUGP0GNwP4eRERE947ho4UEQWgwsykRERG1DsNHC10rVqOgXAMXmRTdwrzFLoeIiMhmMXy0UP0ll66hCrg6y0SuhoiIyHYxfLQQL7kQERGZBsNHCzF8EBERmQbDRwvklVXjWrEaUgnQM6Kt2OUQERHZNIaPFjh6c1bTTkoveLo6i1wNERGRbWP4aIH6ycV6R3JKdSIionvF8NEC7O9BRERkOgwfd1FSWYOL+RUAgF6R7O9BRER0rxg+7qJ+FdsOAW3g20YucjVERES2j+HjLuovufTiJRciIiKTYPi4i/qRLn0YPoiIiEyC4aMZFZpanM1RAQB6RTJ8EBERmQLDRzNSM0ug0wsI83GD0ttN7HKIiIjsAsNHMwz9PdjqQUREZDIMH82oDx/s70FERGQ6DB9NqNbqcCKrFADQO4ozmxIREZkKw0cTTmWXoUanh7+nHJG+7mKXQ0REZDcYPprwx3ouPpBIJCJXQ0REZD8YPppwhOu5EBERmQXDRyNqdXqkZpYAYPggIiIyNYaPRpzLVaGyRgcvVyfEBHqKXQ4REZFdYfhoxK3ze0il7O9BRERkSgwfjWB/DyIiIvNh+LiNXi/g2FWGDyIiInNh+LjN5RsVKFVr4eYsQ+cQhdjlEBER2R2Gj9vUX3LpGdEWzjL+eoiIiEyNn6634WJyRERE5sXwcQtBEP6Y2ZT9PYiIiMzCqPARGRkJiURyx2369OmGbQ4dOoQBAwbAw8MDXl5eeOihh1BVVWXyws0hq7gK+SoNnGUSdA/3FrscIiIiu+RkzMbHjh2DTqcz/HzmzBk8+uijePrppwHUBY+hQ4dizpw5WLZsGZycnHDy5ElIpbbRwHLkZqtHQqg3XJ1lIldDRERkn4wKH/7+/g1+fu+99xAdHY3+/fsDAF5//XW8+uqrmD17tmGbmJgYE5RpGYb+HrzkQkREZDatbpKoqanB2rVrMXXqVEgkEhQUFODIkSMICAhAv379EBgYiP79++PAgQPN7kej0UClUjW4ieUo5/cgIiIyu1aHj23btqG0tBSTJ08GAFy5cgUA8M477+C5557Dzz//jB49emDgwIG4dOlSk/tZtGgRFAqF4RYWFtbaku5JvqoamUVqSCV1w2yJiIjIPFodPj7//HMMGzYMSqUSAKDX6wEA06ZNw5QpU9C9e3f861//QkxMDFatWtXkfubMmYOysjLDLSsrq7Ul3ZP6Sy6dlF7wcnUWpQYiIiJHYFSfj3qZmZnYtWsXvv32W8N9wcHBAIBOnTo12DYuLg7Xrl1rcl9yuRxyubw1ZZgU5/cgIiKyjFa1fKxevRoBAQFITEw03BcZGQmlUokLFy402PbixYuIiIi4tyotoD589GF/DyIiIrMyuuVDr9dj9erVmDRpEpyc/ni6RCLBzJkzMW/ePCQkJKBbt25Ys2YNzp8/j82bN5u0aFMrVdfgQn45ALZ8EBERmZvR4WPXrl24du0apk6desdjM2bMQHV1NV5//XUUFxcjISEBO3fuRHR0tEmKNZdjV0sAAO0D2sC3jfiXgIiIiOyZ0eFj8ODBEAShycdnz57dYJ4PW1A/pTpbPYiIiMzPNqYeNTP29yAiIrIchw8flZpanMmpm9iMk4sRERGZn8OHj9RrJdDpBYS2dYPS203scoiIiOyew4eP+ksubPUgIiKyDIcPH0fqwwc7mxIREVmEQ4cPTa0OJ7JKAbDlg4iIyFIcOnycyi5DTa0efm3kiPLzELscIiIih+DQ4ePWIbYSiUTkaoiIiByDQ4ePI4bF5NqKXAkREZHjcNjwUavTI+Vq/UgXX5GrISIichwOGz7ScstRWaODl6sTYoI8xS6HiIjIYThs+Dhyy3ouMin7exAREVmKw4aP+s6mvTjEloiIyKIcMnzo9QKOXeXMpkRERGJwyPCRfqMCJWot3Jxl6KxUiF0OERGRQ3HI8FE/xLZHhDdcnBzyV0BERCQah/zkNfT34HouREREFudw4UMQBK5kS0REJCKHCx/ZJVXIU1XDWSZB9zDObEpERGRpDhc+6vt7dA31hpuLTORqiIiIHI/DhY+jNycX4yUXIiIicThg+LjZ34OdTYmIiEThUOGjQFWNq0VqSCRAT65kS0REJAqHCh9Hb85q2inYC16uziJXQ0RE5JgcK3xwiC0REZHoHDN8sL8HERGRaBwmfJSqa3A+rxwAV7IlIiISk5PYBViKVCrB/BHxyCishF8budjlEBEROSyHCR9ers6Y1C9S7DKIiIgcnsNcdiEiIiLrwPBBREREFsXwQURERBbF8EFEREQWxfBBREREFsXwQURERBbF8EFEREQWxfBBREREFsXwQURERBbF8EFEREQWxfBBREREFsXwQURERBbF8EFEREQWZXWr2gqCAABQqVQiV0JEREQtVf+5Xf853hyrCx/l5eUAgLCwMJErISIiImOVl5dDoVA0u41EaElEsSC9Xo+cnBx4enpCIpGYdN8qlQphYWHIysqCl5eXSfdtbRzpWAHHOl4eq/1ypOPlsdofQRBQXl4OpVIJqbT5Xh1W1/IhlUoRGhpq1tfw8vKy638At3KkYwUc63h5rPbLkY6Xx2pf7tbiUY8dTomIiMiiGD6IiIjIohwqfMjlcsybNw9yuVzsUszOkY4VcKzj5bHaL0c6Xh6rY7O6DqdERERk3xyq5YOIiIjEx/BBREREFsXwQURERBbF8EFEREQWZXfh49NPP0VkZCRcXV3Rp08fHD16tNntv/nmG8TGxsLV1RVdunTBjz/+aKFKW2/RokXo1asXPD09ERAQgFGjRuHChQvNPueLL76ARCJpcHN1dbVQxffmnXfeuaP22NjYZp9ji+cVACIjI+84VolEgunTpze6va2d199++w3Dhw+HUqmERCLBtm3bGjwuCALmzp2L4OBguLm5YdCgQbh06dJd92vs+94SmjtWrVaLWbNmoUuXLvDw8IBSqcQzzzyDnJycZvfZmveCJdztvE6ePPmOuocOHXrX/VrjeQXufryNvYclEgk++OCDJvdprefWXOwqfGzcuBFvvPEG5s2bh9TUVCQkJGDIkCEoKChodPuDBw9i/PjxePbZZ3H8+HGMGjUKo0aNwpkzZyxcuXH27duH6dOn4/Dhw9i5cye0Wi0GDx6MysrKZp/n5eWF3Nxcwy0zM9NCFd+7+Pj4BrUfOHCgyW1t9bwCwLFjxxoc586dOwEATz/9dJPPsaXzWllZiYSEBHz66aeNPv7+++/j448/xooVK3DkyBF4eHhgyJAhqK6ubnKfxr7vLaW5Y1Wr1UhNTUVSUhJSU1Px7bff4sKFCxgxYsRd92vMe8FS7nZeAWDo0KEN6t6wYUOz+7TW8wrc/XhvPc7c3FysWrUKEokEo0ePbna/1nhuzUawI7179xamT59u+Fmn0wlKpVJYtGhRo9uPGTNGSExMbHBfnz59hGnTppm1TlMrKCgQAAj79u1rcpvVq1cLCoXCckWZ0Lx584SEhIQWb28v51UQBOG1114ToqOjBb1e3+jjtnxeAQhbt241/KzX64WgoCDhgw8+MNxXWloqyOVyYcOGDU3ux9j3vRhuP9bGHD16VAAgZGZmNrmNse8FMTR2rJMmTRJGjhxp1H5s4bwKQsvO7ciRI4UBAwY0u40tnFtTspuWj5qaGqSkpGDQoEGG+6RSKQYNGoRDhw41+pxDhw412B4AhgwZ0uT21qqsrAwA4OPj0+x2FRUViIiIQFhYGEaOHImzZ89aojyTuHTpEpRKJdq1a4cJEybg2rVrTW5rL+e1pqYGa9euxdSpU5tdZNGWz+utMjIykJeX1+DcKRQK9OnTp8lz15r3vbUqKyuDRCKBt7d3s9sZ816wJnv37kVAQABiYmLw4osvoqioqMlt7em85ufnY/v27Xj22Wfvuq2tntvWsJvwUVhYCJ1Oh8DAwAb3BwYGIi8vr9Hn5OXlGbW9NdLr9ZgxYwbuv/9+dO7cucntYmJisGrVKnz33XdYu3Yt9Ho9+vXrh+zsbAtW2zp9+vTBF198gZ9//hnLly9HRkYGHnzwQZSXlze6vT2cVwDYtm0bSktLMXny5Ca3seXzerv682PMuWvN+94aVVdXY9asWRg/fnyzC48Z+16wFkOHDsWXX36J3bt3Y/Hixdi3bx+GDRsGnU7X6Pb2cl4BYM2aNfD09MSTTz7Z7Ha2em5by+pWtSXjTJ8+HWfOnLnrtcG+ffuib9++hp/79euHuLg4rFy5Eu+++665y7wnw4YNM/x/165d0adPH0RERGDTpk0t+jZhqz7//HMMGzYMSqWyyW1s+bxSHa1WizFjxkAQBCxfvrzZbW31vTBu3DjD/3fp0gVdu3ZFdHQ09u7di4EDB4pYmfmtWrUKEyZMuGtHcFs9t61lNy0ffn5+kMlkyM/Pb3B/fn4+goKCGn1OUFCQUdtbm5dffhk//PAD9uzZg9DQUKOe6+zsjO7du+Py5ctmqs58vL290bFjxyZrt/XzCgCZmZnYtWsX/vKXvxj1PFs+r/Xnx5hz15r3vTWpDx6ZmZnYuXOn0cut3+29YK3atWsHPz+/Juu29fNab//+/bhw4YLR72PAds9tS9lN+HBxcUHPnj2xe/duw316vR67d+9u8M3wVn379m2wPQDs3Lmzye2thSAIePnll7F161b8+uuviIqKMnofOp0Op0+fRnBwsBkqNK+Kigqkp6c3WbutntdbrV69GgEBAUhMTDTqebZ8XqOiohAUFNTg3KlUKhw5cqTJc9ea9721qA8ely5dwq5du+Dr62v0Pu72XrBW2dnZKCoqarJuWz6vt/r888/Rs2dPJCQkGP1cWz23LSZ2j1dT+vrrrwW5XC588cUXwrlz54Tnn39e8Pb2FvLy8gRBEISJEycKs2fPNmz/+++/C05OTsKHH34opKWlCfPmzROcnZ2F06dPi3UILfLiiy8KCoVC2Lt3r5Cbm2u4qdVqwza3H+v8+fOFHTt2COnp6UJKSoowbtw4wdXVVTh79qwYh2CUv/71r8LevXuFjIwM4ffffxcGDRok+Pn5CQUFBYIg2M95rafT6YTw8HBh1qxZdzxm6+e1vLxcOH78uHD8+HEBgLBkyRLh+PHjhhEe7733nuDt7S189913wqlTp4SRI0cKUVFRQlVVlWEfAwYMEJYtW2b4+W7ve7E0d6w1NTXCiBEjhNDQUOHEiRMN3scajcawj9uP9W7vBbE0d6zl5eXC3/72N+HQoUNCRkaGsGvXLqFHjx5Chw4dhOrqasM+bOW8CsLd/x0LgiCUlZUJ7u7uwvLlyxvdh62cW3Oxq/AhCIKwbNkyITw8XHBxcRF69+4tHD582PBY//79hUmTJjXYftOmTULHjh0FFxcXIT4+Xti+fbuFKzYegEZvq1evNmxz+7HOmDHD8HsJDAwUHnvsMSE1NdXyxbfC2LFjheDgYMHFxUUICQkRxo4dK1y+fNnwuL2c13o7duwQAAgXLly44zFbP6979uxp9N9u/THp9XohKSlJCAwMFORyuTBw4MA7fg8RERHCvHnzGtzX3PteLM0da0ZGRpPv4z179hj2cfux3u29IJbmjlWtVguDBw8W/P39BWdnZyEiIkJ47rnn7ggRtnJeBeHu/44FQRBWrlwpuLm5CaWlpY3uw1bOrblIBEEQzNq0QkRERHQLu+nzQURERLaB4YOIiIgsiuGDiIiILIrhg4iIiCyK4YOIiIgsiuGDiIiILIrhg4iIiCyK4YOIiIgsiuGDiIiILIrhg4iIiCyK4YOIiIgsiuGDiIiILOr/A/mQhMaogtUSAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy: 85.56, best accuracy: 86.96\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import InputLayer\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn import model_selection\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "device=torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "\n",
        "data=pd.read_csv(\"xab\",encoding=\"utf-8\")\n",
        "\n",
        "word2vec_model = KeyedVectors.load_word2vec_format(\"drive/MyDrive/Colab Notebooks/GoogleNews-vectors-negative300.bin.gz\", binary=True, limit=20000)\n",
        "#print(word2vec_model.get_index(\"the\"))\n",
        "vect  = CountVectorizer(stop_words=\"english\",max_df=0.7)\n",
        "#corpus = vect.fit_transform(data[\"text\"])\n",
        "#train_corpus, test_corpus, train_label, test_label = model_selection.train_test_split(data[\"text\"],data[\"label\"],test_size=0.4)\n",
        "#Encoder = LabelEncoder()\n",
        "#train_label = Encoder.fit_transform(train_label)\n",
        "#test_label = Encoder.fit_transform(test_label)\n",
        "#train_corpus_vect=vect.transform(train_corpus)\n",
        "#test_corpus_vect=vect.transform(test_corpus)\n",
        "\n",
        "# Initalise vect.vocabulary_\n",
        "vect.fit_transform(data[\"text\"])\n",
        "\n",
        "maxlen=0\n",
        "\n",
        "def transform(text,vect):\n",
        "    global maxlen\n",
        "    global word2vec_model\n",
        "    #d=vect.vocabulary_\n",
        "    d=word2vec_model\n",
        "    p=vect.build_preprocessor()\n",
        "    t=vect.build_tokenizer()\n",
        "    vec_list=[]\n",
        "    for doc in text:\n",
        "        tokens=t(p(doc))\n",
        "        doc_vec=np.array([d.get_index(token) for token in tokens if token in d])\n",
        "        s=len(doc_vec)\n",
        "        if s>maxlen:\n",
        "            maxlen=s\n",
        "        #doc_vec=sequence.pad_sequences(doc_vec,maxlen=maxlen)\n",
        "        vec_list.append(doc_vec)\n",
        "    vec_list=sequence.pad_sequences(vec_list,maxlen=maxlen,padding=\"post\")\n",
        "    corpus_vec=np.vstack(vec_list)\n",
        "    #return nn.functional.normalize(torch.tensor(corpus_vec).float())\n",
        "    return torch.tensor(corpus_vec)\n",
        "    #return torch.tensor(corpus_vec).float()\n",
        "\n",
        "# print(corpus_vec)\n",
        "\n",
        "bsize=50\n",
        "epochs=20\n",
        "lr=5e-4\n",
        "embed_dim=300\n",
        "\n",
        "class corpus(Dataset):\n",
        "    def __init__(self,corpus,label,seq):\n",
        "        self.corpus=corpus\n",
        "        self.label=label\n",
        "        self.seq=seq\n",
        "    def __len__(self):\n",
        "        return len(self.corpus)\n",
        "    def __getitem__(self,idx):\n",
        "        return self.corpus[idx],self.label[idx]\n",
        "\n",
        "class lstm(nn.Module):\n",
        "    def __init__(self,input_size,hidden_size,seq):\n",
        "        super(lstm,self).__init__()\n",
        "        self.input_size=input_size\n",
        "        self.hidden_size=hidden_size\n",
        "        self.seq=seq\n",
        "        self.rnn=True\n",
        "        self.lstm=nn.LSTM(input_size,hidden_size,batch_first=True,num_layers=3)\n",
        "        self.fc=nn.Linear(self.hidden_size*seq,1)\n",
        "        #self.fc=nn.Linear(self.hidden_size,1)\n",
        "        #self.embed=nn.Embedding(len(vect.vocabulary_),input_size)\n",
        "        self.embed=nn.Embedding.from_pretrained(torch.from_numpy(word2vec_model.vectors),freeze=True)\n",
        "\n",
        "    def forward(self,x,h0=None,c0=None):\n",
        "        x=self.embed(x)\n",
        "        if h0==None and c0==None:\n",
        "            x, (hn,cn) = self.lstm(x)\n",
        "        else:\n",
        "            x, (hn,cn) = self.lstm(x,(h0,c0))\n",
        "        #print(x[:,-1,:].shape)\n",
        "        #x = torch.flatten(x[:,-1,:],1)\n",
        "        # Flatten like this so that all information from previous time steps is fed into fully connected layer\n",
        "        x=torch.flatten(x,1)\n",
        "        x = self.fc(x)\n",
        "        return nn.Sigmoid()(x), hn,cn\n",
        "        #return nn.Softmax()(x), hn,cn\n",
        "\n",
        "class dense(nn.Module):\n",
        "    def __init__(self,seq,vocab,embed_dim):\n",
        "        super(dense,self).__init__()\n",
        "        self.seq=seq\n",
        "        self.rnn=False\n",
        "        self.network=nn.Sequential(\n",
        "            nn.Linear(embed_dim*seq,360),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(360,180),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(180,1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.embed=nn.Embedding(vocab,embed_dim)\n",
        "\n",
        "    def forward(self,x):\n",
        "        #print(x.shape)\n",
        "        x=self.embed(x)\n",
        "        x=torch.flatten(x,1)\n",
        "        #x=torch.transpose(x,1,2)\n",
        "        #x=torch.flatten(x,1)\n",
        "        return self.network(x)\n",
        "\n",
        "vocab=len(vect.vocabulary_)\n",
        "Encoder = LabelEncoder()\n",
        "corpus_vec = transform(data[\"text\"],vect)\n",
        "train_corpus_vec, test_corpus_vec, train_label, test_label = model_selection.train_test_split(corpus_vec,data[\"label\"],test_size=0.1)\n",
        "train_label = torch.from_numpy(Encoder.fit_transform(train_label)).float()\n",
        "test_label = torch.from_numpy(Encoder.fit_transform(test_label)).float()\n",
        "#train_corpus_vec = transform(train_corpus,vect)\n",
        "#test_corpus_vec = transform(test_corpus,vect)\n",
        "lstm_classifier=lstm(embed_dim,200,maxlen)\n",
        "loss_fn=nn.BCELoss()\n",
        "#loss_fn=nn.BCEWithLogitsLoss()\n",
        "#loss_fn=nn.MSELoss()\n",
        "optimizer=torch.optim.Adam(lstm_classifier.parameters(),lr=lr)\n",
        "#optimizer=torch.optim.SGD(lstm_classifier.parameters(),lr=lr)\n",
        "#print(len(lstm_classifier(torch.reshape(train_corpus_vec[0],(bsize,maxlen,1)))))\n",
        "\n",
        "dense_classifier=dense(maxlen,vocab,16)\n",
        "\n",
        "c=lstm_classifier\n",
        "\n",
        "c=c.to(device)\n",
        "\n",
        "train_dataloader=DataLoader(corpus(train_corpus_vec,train_label,maxlen),batch_size=bsize,shuffle=True)\n",
        "test_dataloader=DataLoader(corpus(test_corpus_vec,test_label,maxlen),batch_size=bsize,shuffle=True)\n",
        "\n",
        "def train(dataloader,model,loss_fn,optimizer):\n",
        "    hn,cn=None,None\n",
        "    size=len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch,(x,y) in enumerate(dataloader):\n",
        "        x,y=x.to(device),y.to(device)\n",
        "        #print(torch.sum(x[0]!=0))\n",
        "        if model.rnn==True:\n",
        "            #pred,hn,cn=model(x.reshape(bsize,dataloader.dataset.seq,1).to(device),hn,cn)\n",
        "            pred,hn,cn=model(x,hn,cn)\n",
        "        else:\n",
        "            pred=model(x)\n",
        "        #pred=model(x)\n",
        "        cost=loss_fn(pred.flatten(),y)\n",
        "        cost.backward()\n",
        "        #if model.rnn==True:\n",
        "        #    print(model.lstm.weight_ih_l0.grad[0][0])\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if model.rnn==True:\n",
        "            hn=hn.detach()\n",
        "            cn=cn.detach()\n",
        "        if batch % 10 == 0:\n",
        "            cost_val, current = cost.item(), batch * bsize + len(x)\n",
        "            print(f\"cost: {cost_val:>7f}, accuracy: {(torch.round(pred.flatten())==y).sum().item()/bsize:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x,y=x.to(device),y.to(device)\n",
        "            if model.rnn==True:\n",
        "                #pred,_,_=model(x.reshape(bsize,dataloader.dataset.seq,1).to(device))\n",
        "                pred,_,_=model(x)\n",
        "            else:\n",
        "                pred=model(x)\n",
        "            #pred=model(x)\n",
        "            #print(torch.round(pred.flatten()),y)\n",
        "            test_loss += loss_fn(pred.flatten(), y).item()\n",
        "            ncorrect = (torch.round(pred.flatten()) == y).sum().item()\n",
        "            #print(ncorrect)\n",
        "            correct += ncorrect\n",
        "\n",
        "    #print(correct,size)\n",
        "    #print(f\"Test Error: \\n Accuracy: {(100*correct/size):>0.1f}%, Avg loss: {100*test_loss/size:>8f} \\n\")\n",
        "    return 100*correct/size\n",
        "\n",
        "#keras_model=Sequential([InputLayer(input_shape=(maxlen,),batch_size=bsize),\n",
        "#                        Embedding(len(vect.vocabulary_),16),\n",
        "#                  Flatten(),\n",
        "#                  Dense(1,activation=\"sigmoid\")])\n",
        "keras_model=Sequential([InputLayer(shape=(maxlen,),batch_size=bsize),\n",
        "                        Embedding(len(word2vec_model),embed_dim),\n",
        "                        LSTM(20,return_sequences=True),\n",
        "                  Flatten(),\n",
        "                  Dense(1,activation=\"sigmoid\")])\n",
        "keras_model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "keras_model.summary()\n",
        "\n",
        "use_torch=True\n",
        "\n",
        "x=np.arange(epochs)\n",
        "y=np.zeros(epochs)\n",
        "#print(corpus_vec[0])\n",
        "if use_torch==True:\n",
        "    for epoch in range(epochs):\n",
        "        train(train_dataloader,c,loss_fn,optimizer)\n",
        "        y[epoch] = test_loop(test_dataloader,c,loss_fn)\n",
        "    plt.plot(x,y)\n",
        "    plt.show()\n",
        "    print(f\"Final accuracy: {y[-1]:.2f}, best accuracy: {y[np.argmax(y)]:.2f}\")\n",
        "else:\n",
        "    keras_model.fit(train_corpus_vec,train_label,batch_size=bsize,epochs=epochs,validation_data=(test_corpus_vec,test_label))\n",
        "    keras_model.evaluate(test_corpus_vec,test_label,batch_size=bsize)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "cy5ekCL0mHOK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "outputId": "6e7936cf-ae69-44cc-83d3-b362ec70f1d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              },
              "id": "caaec4ead7d7420cabe39cb563415b7e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vx6v266o_lK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(word2vec_model))\n",
        "word2vec_model[\"horse\"]"
      ],
      "metadata": {
        "id": "0EdHfJkrFBpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a61279-c917-4845-f223-6b7729de06f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.34057617e-04,  3.11279297e-02,  5.03540039e-03, -9.17968750e-02,\n",
              "       -8.36181641e-03, -1.66015625e-01,  3.93066406e-02,  2.97851562e-02,\n",
              "        1.69921875e-01, -2.04101562e-01,  2.41210938e-01, -3.04687500e-01,\n",
              "       -2.24609375e-02, -3.71093750e-01, -5.61523438e-02,  1.51367188e-01,\n",
              "       -1.21582031e-01,  3.41796875e-01,  3.05175781e-02, -2.94921875e-01,\n",
              "        6.54296875e-02, -9.27734375e-02,  1.49414062e-01,  8.15429688e-02,\n",
              "       -6.93359375e-02,  1.98242188e-01, -1.66015625e-01,  2.00195312e-01,\n",
              "        1.16699219e-01, -3.69140625e-01, -2.48046875e-01,  1.25976562e-01,\n",
              "        3.59375000e-01,  1.51367188e-01, -7.76367188e-02,  2.91015625e-01,\n",
              "       -1.74560547e-02, -1.21093750e-01, -1.00097656e-01,  1.43554688e-01,\n",
              "        5.92041016e-03,  2.35595703e-02,  3.20312500e-01,  1.82617188e-01,\n",
              "        9.52148438e-02,  9.22851562e-02,  8.30078125e-02, -1.33789062e-01,\n",
              "        9.57031250e-02,  1.66992188e-01,  1.87988281e-02, -2.79541016e-02,\n",
              "       -1.03149414e-02,  1.11816406e-01, -8.10546875e-02,  1.79687500e-01,\n",
              "        8.34960938e-02, -5.90820312e-02,  1.70898438e-01,  1.68457031e-02,\n",
              "        8.74023438e-02,  9.03320312e-02,  9.22851562e-02, -9.76562500e-02,\n",
              "       -2.39257812e-02, -2.07031250e-01, -1.21459961e-02,  1.44531250e-01,\n",
              "        6.20117188e-02, -1.44042969e-02,  2.81250000e-01,  6.83593750e-02,\n",
              "       -2.12890625e-01,  4.68750000e-02, -1.00097656e-01, -1.35742188e-01,\n",
              "        7.47070312e-02, -2.69531250e-01,  7.56835938e-02, -5.51757812e-02,\n",
              "       -2.01416016e-02, -3.80859375e-01,  1.67968750e-01, -3.90625000e-01,\n",
              "        5.54199219e-02,  2.23632812e-01, -6.28662109e-03,  7.76367188e-02,\n",
              "        2.03125000e-01, -1.04980469e-01, -3.12500000e-02,  3.53515625e-01,\n",
              "        1.54296875e-01, -1.25976562e-01, -2.24609375e-02, -3.80859375e-01,\n",
              "        3.12500000e-01,  2.12890625e-01,  1.97265625e-01, -4.49218750e-01,\n",
              "       -9.22851562e-02, -2.94921875e-01,  2.21679688e-01, -2.58789062e-02,\n",
              "        1.38671875e-01,  7.37304688e-02, -1.10839844e-01, -3.00781250e-01,\n",
              "        1.29882812e-01, -1.74804688e-01,  1.37939453e-02,  7.51953125e-02,\n",
              "        2.98828125e-01, -7.61718750e-02,  9.76562500e-02, -2.53906250e-01,\n",
              "       -8.69140625e-02, -9.86328125e-02, -4.49218750e-02,  1.00585938e-01,\n",
              "       -1.68945312e-01,  1.06933594e-01, -1.07910156e-01, -3.57421875e-01,\n",
              "       -3.58886719e-02, -3.24707031e-02,  1.62109375e-01, -1.17187500e-01,\n",
              "       -1.49414062e-01,  2.31933594e-02, -4.14062500e-01,  2.85644531e-02,\n",
              "       -2.57812500e-01, -6.59179688e-02, -4.80957031e-02, -1.87500000e-01,\n",
              "        5.10253906e-02,  7.86132812e-02, -7.56835938e-02,  3.20312500e-01,\n",
              "        7.08007812e-02, -1.08886719e-01, -3.03955078e-02,  1.53320312e-01,\n",
              "        8.93554688e-02,  8.83789062e-02, -2.01416016e-02, -1.66992188e-01,\n",
              "       -8.88671875e-02,  7.20214844e-03,  4.88281250e-01,  7.66601562e-02,\n",
              "        6.68945312e-02, -4.34570312e-02, -2.41210938e-01, -9.71679688e-02,\n",
              "        7.47070312e-02, -3.24218750e-01, -3.14453125e-01, -8.74023438e-02,\n",
              "       -8.20312500e-02,  2.33154297e-02,  2.55859375e-01, -1.06445312e-01,\n",
              "        1.13769531e-01, -4.71191406e-02, -4.83398438e-02, -4.31640625e-01,\n",
              "        3.41796875e-02,  1.66015625e-02, -6.00585938e-02, -1.82617188e-01,\n",
              "       -3.56445312e-02, -8.59375000e-02, -5.88378906e-02,  1.19628906e-01,\n",
              "        1.33789062e-01, -3.73535156e-02, -1.79687500e-01,  8.59375000e-02,\n",
              "       -2.63671875e-01, -3.36914062e-02, -2.22167969e-02,  9.52148438e-02,\n",
              "        1.05468750e-01, -1.63085938e-01,  2.65625000e-01,  1.77734375e-01,\n",
              "       -2.37304688e-01,  1.58203125e-01, -4.00390625e-02, -5.71289062e-02,\n",
              "        1.51367188e-01,  1.52343750e-01,  2.71484375e-01, -2.13867188e-01,\n",
              "        1.81884766e-02, -4.98046875e-02, -2.65625000e-01, -1.05468750e-01,\n",
              "        4.98046875e-02, -5.54687500e-01, -2.91015625e-01, -9.61914062e-02,\n",
              "       -9.52148438e-02, -4.17480469e-02, -2.57812500e-01, -6.25000000e-02,\n",
              "        9.37500000e-02, -2.09960938e-02, -2.48046875e-01,  4.51660156e-02,\n",
              "        1.56250000e-01, -1.74804688e-01, -1.37695312e-01,  1.54296875e-01,\n",
              "       -3.94531250e-01, -1.66992188e-01,  2.07031250e-01,  1.55273438e-01,\n",
              "        2.08984375e-01,  2.69531250e-01,  3.26171875e-01, -1.24023438e-01,\n",
              "        1.64794922e-02, -5.05371094e-02,  3.10546875e-01, -3.24707031e-02,\n",
              "        3.41796875e-01, -9.96093750e-02,  4.15039062e-02, -3.06640625e-01,\n",
              "        4.83398438e-02,  2.08007812e-01, -4.10156250e-01, -7.22656250e-02,\n",
              "        1.09863281e-01, -2.67578125e-01,  2.28515625e-01, -1.02050781e-01,\n",
              "        1.83593750e-01, -2.44140625e-01,  2.21679688e-01,  2.01171875e-01,\n",
              "        3.10546875e-01, -2.14843750e-01, -3.41796875e-02,  2.57812500e-01,\n",
              "        2.53906250e-02,  7.66601562e-02, -1.18164062e-01,  2.41210938e-01,\n",
              "       -9.61914062e-02, -1.16699219e-01, -8.34960938e-02,  2.37304688e-01,\n",
              "       -1.10839844e-01,  6.73828125e-02, -4.35546875e-01, -3.32641602e-03,\n",
              "       -1.27929688e-01, -6.53076172e-03,  2.72216797e-02,  2.83203125e-01,\n",
              "       -4.19921875e-02,  8.00781250e-02,  1.12792969e-01, -2.73437500e-01,\n",
              "       -2.63671875e-01,  2.04101562e-01, -8.54492188e-02,  1.91497803e-03,\n",
              "       -2.04101562e-01,  6.83593750e-02, -6.54296875e-02, -1.35742188e-01,\n",
              "       -2.57568359e-02, -3.96484375e-01, -2.94189453e-02,  4.33593750e-01,\n",
              "        6.03027344e-02,  3.41796875e-03,  1.74804688e-01,  6.44531250e-02,\n",
              "       -3.97949219e-02, -7.32421875e-02, -1.50390625e-01,  2.56347656e-02,\n",
              "        2.91015625e-01,  2.61718750e-01, -2.32421875e-01,  1.13769531e-01,\n",
              "       -2.53906250e-01,  1.75781250e-01,  1.89453125e-01,  2.65625000e-01,\n",
              "        1.66015625e-01,  2.85156250e-01, -1.63085938e-01,  6.07910156e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Md7zxWTk9AhSbKVVPH3m-w-W4QP5_WDX",
      "authorship_tag": "ABX9TyONhoAJyyEC1eWSlIgSktI3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}