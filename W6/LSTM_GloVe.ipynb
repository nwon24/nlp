{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nwon24/nlp/blob/main/LSTM_GloVe_50000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNJn2LK1JFjP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dWAcH6mWYxkE",
        "outputId": "b59e54df-089c-488f-b159-2b317cb6b077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2-2806439594.py:31: ConversionWarning: Some errors were detected !\n",
            "    Line #248458 (got 1 columns instead of 101)\n",
            "    Line #254064 (got 1 columns instead of 101)\n",
            "    Line #333494 (got 1 columns instead of 101)\n",
            "    Line #377299 (got 1 columns instead of 101)\n",
            "  glove_data_f=np.genfromtxt(glove_file,dtype=float,invalid_raise=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(399966, 100)\n",
            "190\n",
            "torch.Size([50000, 190])\n",
            "(50000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m190\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │    \u001b[38;5;34m39,996,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m190\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │         \u001b[38;5;34m9,680\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m3800\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │         \u001b[38;5;34m3,801\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">190</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">39,996,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">190</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,680</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3800</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,801</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,010,081\u001b[0m (152.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,010,081</span> (152.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,010,081\u001b[0m (152.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,010,081</span> (152.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost: 0.692866, accuracy: 0.540000  [   50/45000]\n",
            "cost: 0.706505, accuracy: 0.520000  [  550/45000]\n",
            "cost: 0.690300, accuracy: 0.480000  [ 1050/45000]\n",
            "cost: 0.739295, accuracy: 0.420000  [ 1550/45000]\n",
            "cost: 0.686552, accuracy: 0.460000  [ 2050/45000]\n",
            "cost: 0.677665, accuracy: 0.600000  [ 2550/45000]\n",
            "cost: 0.636312, accuracy: 0.640000  [ 3050/45000]\n",
            "cost: 0.540055, accuracy: 0.740000  [ 3550/45000]\n",
            "cost: 0.576323, accuracy: 0.720000  [ 4050/45000]\n",
            "cost: 0.559700, accuracy: 0.800000  [ 4550/45000]\n",
            "cost: 0.607503, accuracy: 0.660000  [ 5050/45000]\n",
            "cost: 0.494792, accuracy: 0.740000  [ 5550/45000]\n",
            "cost: 0.528491, accuracy: 0.740000  [ 6050/45000]\n",
            "cost: 0.674519, accuracy: 0.680000  [ 6550/45000]\n",
            "cost: 0.402766, accuracy: 0.880000  [ 7050/45000]\n",
            "cost: 0.825584, accuracy: 0.620000  [ 7550/45000]\n",
            "cost: 0.475834, accuracy: 0.780000  [ 8050/45000]\n",
            "cost: 0.505280, accuracy: 0.700000  [ 8550/45000]\n",
            "cost: 0.565117, accuracy: 0.600000  [ 9050/45000]\n",
            "cost: 0.340383, accuracy: 0.860000  [ 9550/45000]\n",
            "cost: 0.442216, accuracy: 0.780000  [10050/45000]\n",
            "cost: 0.456475, accuracy: 0.800000  [10550/45000]\n",
            "cost: 0.436344, accuracy: 0.740000  [11050/45000]\n",
            "cost: 0.406150, accuracy: 0.800000  [11550/45000]\n",
            "cost: 0.438518, accuracy: 0.840000  [12050/45000]\n",
            "cost: 0.457145, accuracy: 0.760000  [12550/45000]\n",
            "cost: 0.680122, accuracy: 0.640000  [13050/45000]\n",
            "cost: 0.410711, accuracy: 0.820000  [13550/45000]\n",
            "cost: 0.434760, accuracy: 0.800000  [14050/45000]\n",
            "cost: 0.594665, accuracy: 0.740000  [14550/45000]\n",
            "cost: 0.453378, accuracy: 0.820000  [15050/45000]\n",
            "cost: 0.342791, accuracy: 0.860000  [15550/45000]\n",
            "cost: 0.393897, accuracy: 0.800000  [16050/45000]\n",
            "cost: 0.340494, accuracy: 0.840000  [16550/45000]\n",
            "cost: 0.436615, accuracy: 0.800000  [17050/45000]\n",
            "cost: 0.466998, accuracy: 0.720000  [17550/45000]\n",
            "cost: 0.432570, accuracy: 0.820000  [18050/45000]\n",
            "cost: 0.455866, accuracy: 0.680000  [18550/45000]\n",
            "cost: 0.504962, accuracy: 0.780000  [19050/45000]\n",
            "cost: 0.391898, accuracy: 0.860000  [19550/45000]\n",
            "cost: 0.330164, accuracy: 0.860000  [20050/45000]\n",
            "cost: 0.620932, accuracy: 0.700000  [20550/45000]\n",
            "cost: 0.424021, accuracy: 0.820000  [21050/45000]\n",
            "cost: 0.357224, accuracy: 0.900000  [21550/45000]\n",
            "cost: 0.461267, accuracy: 0.760000  [22050/45000]\n",
            "cost: 0.318793, accuracy: 0.860000  [22550/45000]\n",
            "cost: 0.238495, accuracy: 0.940000  [23050/45000]\n",
            "cost: 0.231823, accuracy: 0.900000  [23550/45000]\n",
            "cost: 0.475190, accuracy: 0.800000  [24050/45000]\n",
            "cost: 0.382316, accuracy: 0.800000  [24550/45000]\n",
            "cost: 0.248383, accuracy: 0.900000  [25050/45000]\n",
            "cost: 0.336872, accuracy: 0.860000  [25550/45000]\n",
            "cost: 0.486657, accuracy: 0.780000  [26050/45000]\n",
            "cost: 0.555421, accuracy: 0.760000  [26550/45000]\n",
            "cost: 0.251570, accuracy: 0.900000  [27050/45000]\n",
            "cost: 0.341570, accuracy: 0.880000  [27550/45000]\n",
            "cost: 0.298420, accuracy: 0.880000  [28050/45000]\n",
            "cost: 0.387938, accuracy: 0.760000  [28550/45000]\n",
            "cost: 0.376205, accuracy: 0.900000  [29050/45000]\n",
            "cost: 0.315350, accuracy: 0.840000  [29550/45000]\n",
            "cost: 0.348222, accuracy: 0.880000  [30050/45000]\n",
            "cost: 0.295324, accuracy: 0.880000  [30550/45000]\n",
            "cost: 0.328539, accuracy: 0.860000  [31050/45000]\n",
            "cost: 0.301026, accuracy: 0.880000  [31550/45000]\n",
            "cost: 0.397200, accuracy: 0.840000  [32050/45000]\n",
            "cost: 0.508908, accuracy: 0.780000  [32550/45000]\n",
            "cost: 0.417682, accuracy: 0.740000  [33050/45000]\n",
            "cost: 0.384114, accuracy: 0.760000  [33550/45000]\n",
            "cost: 0.303914, accuracy: 0.840000  [34050/45000]\n",
            "cost: 0.517192, accuracy: 0.780000  [34550/45000]\n",
            "cost: 0.314937, accuracy: 0.860000  [35050/45000]\n",
            "cost: 0.343987, accuracy: 0.860000  [35550/45000]\n",
            "cost: 0.409617, accuracy: 0.820000  [36050/45000]\n",
            "cost: 0.363724, accuracy: 0.800000  [36550/45000]\n",
            "cost: 0.298770, accuracy: 0.900000  [37050/45000]\n",
            "cost: 0.376521, accuracy: 0.840000  [37550/45000]\n",
            "cost: 0.272319, accuracy: 0.840000  [38050/45000]\n",
            "cost: 0.149851, accuracy: 0.980000  [38550/45000]\n",
            "cost: 0.317340, accuracy: 0.860000  [39050/45000]\n",
            "cost: 0.243058, accuracy: 0.920000  [39550/45000]\n",
            "cost: 0.426034, accuracy: 0.800000  [40050/45000]\n",
            "cost: 0.317767, accuracy: 0.840000  [40550/45000]\n",
            "cost: 0.286759, accuracy: 0.860000  [41050/45000]\n",
            "cost: 0.208950, accuracy: 0.920000  [41550/45000]\n",
            "cost: 0.532423, accuracy: 0.780000  [42050/45000]\n",
            "cost: 0.351021, accuracy: 0.840000  [42550/45000]\n",
            "cost: 0.383681, accuracy: 0.860000  [43050/45000]\n",
            "cost: 0.261279, accuracy: 0.900000  [43550/45000]\n",
            "cost: 0.490712, accuracy: 0.840000  [44050/45000]\n",
            "cost: 0.216761, accuracy: 0.880000  [44550/45000]\n",
            "cost: 0.144894, accuracy: 0.940000  [   50/45000]\n",
            "cost: 0.344157, accuracy: 0.880000  [  550/45000]\n",
            "cost: 0.294202, accuracy: 0.880000  [ 1050/45000]\n",
            "cost: 0.200303, accuracy: 0.960000  [ 1550/45000]\n",
            "cost: 0.198543, accuracy: 0.960000  [ 2050/45000]\n",
            "cost: 0.420085, accuracy: 0.840000  [ 2550/45000]\n",
            "cost: 0.117008, accuracy: 0.960000  [ 3050/45000]\n",
            "cost: 0.256485, accuracy: 0.900000  [ 3550/45000]\n",
            "cost: 0.298712, accuracy: 0.880000  [ 4050/45000]\n",
            "cost: 0.254059, accuracy: 0.920000  [ 4550/45000]\n",
            "cost: 0.219126, accuracy: 0.920000  [ 5050/45000]\n",
            "cost: 0.354999, accuracy: 0.860000  [ 5550/45000]\n",
            "cost: 0.216115, accuracy: 0.940000  [ 6050/45000]\n",
            "cost: 0.354135, accuracy: 0.860000  [ 6550/45000]\n",
            "cost: 0.186423, accuracy: 0.940000  [ 7050/45000]\n",
            "cost: 0.363806, accuracy: 0.820000  [ 7550/45000]\n",
            "cost: 0.236455, accuracy: 0.900000  [ 8050/45000]\n",
            "cost: 0.284257, accuracy: 0.940000  [ 8550/45000]\n",
            "cost: 0.246355, accuracy: 0.900000  [ 9050/45000]\n",
            "cost: 0.189142, accuracy: 0.920000  [ 9550/45000]\n",
            "cost: 0.291936, accuracy: 0.860000  [10050/45000]\n",
            "cost: 0.193176, accuracy: 0.900000  [10550/45000]\n",
            "cost: 0.289789, accuracy: 0.880000  [11050/45000]\n",
            "cost: 0.336366, accuracy: 0.860000  [11550/45000]\n",
            "cost: 0.491477, accuracy: 0.860000  [12050/45000]\n",
            "cost: 0.280723, accuracy: 0.880000  [12550/45000]\n",
            "cost: 0.186815, accuracy: 0.940000  [13050/45000]\n",
            "cost: 0.335737, accuracy: 0.820000  [13550/45000]\n",
            "cost: 0.348553, accuracy: 0.860000  [14050/45000]\n",
            "cost: 0.378005, accuracy: 0.780000  [14550/45000]\n",
            "cost: 0.159711, accuracy: 0.940000  [15050/45000]\n",
            "cost: 0.272368, accuracy: 0.860000  [15550/45000]\n",
            "cost: 0.271587, accuracy: 0.860000  [16050/45000]\n",
            "cost: 0.281098, accuracy: 0.860000  [16550/45000]\n",
            "cost: 0.209559, accuracy: 0.920000  [17050/45000]\n",
            "cost: 0.221012, accuracy: 0.940000  [17550/45000]\n",
            "cost: 0.259951, accuracy: 0.880000  [18050/45000]\n",
            "cost: 0.333425, accuracy: 0.860000  [18550/45000]\n",
            "cost: 0.310179, accuracy: 0.900000  [19050/45000]\n",
            "cost: 0.182071, accuracy: 0.940000  [19550/45000]\n",
            "cost: 0.240391, accuracy: 0.900000  [20050/45000]\n",
            "cost: 0.257116, accuracy: 0.920000  [20550/45000]\n",
            "cost: 0.219454, accuracy: 0.920000  [21050/45000]\n",
            "cost: 0.247670, accuracy: 0.900000  [21550/45000]\n",
            "cost: 0.109807, accuracy: 0.980000  [22050/45000]\n",
            "cost: 0.211156, accuracy: 0.940000  [22550/45000]\n",
            "cost: 0.207187, accuracy: 0.920000  [23050/45000]\n",
            "cost: 0.149397, accuracy: 0.920000  [23550/45000]\n",
            "cost: 0.224202, accuracy: 0.880000  [24050/45000]\n",
            "cost: 0.113222, accuracy: 0.980000  [24550/45000]\n",
            "cost: 0.287463, accuracy: 0.860000  [25050/45000]\n",
            "cost: 0.363361, accuracy: 0.900000  [25550/45000]\n",
            "cost: 0.281148, accuracy: 0.880000  [26050/45000]\n",
            "cost: 0.262454, accuracy: 0.880000  [26550/45000]\n",
            "cost: 0.440200, accuracy: 0.840000  [27050/45000]\n",
            "cost: 0.238490, accuracy: 0.900000  [27550/45000]\n",
            "cost: 0.184892, accuracy: 0.940000  [28050/45000]\n",
            "cost: 0.516677, accuracy: 0.800000  [28550/45000]\n",
            "cost: 0.213205, accuracy: 0.860000  [29050/45000]\n",
            "cost: 0.399851, accuracy: 0.860000  [29550/45000]\n",
            "cost: 0.282897, accuracy: 0.920000  [30050/45000]\n",
            "cost: 0.351722, accuracy: 0.840000  [30550/45000]\n",
            "cost: 0.205075, accuracy: 0.920000  [31050/45000]\n",
            "cost: 0.169446, accuracy: 0.960000  [31550/45000]\n",
            "cost: 0.245798, accuracy: 0.900000  [32050/45000]\n",
            "cost: 0.258159, accuracy: 0.900000  [32550/45000]\n",
            "cost: 0.277195, accuracy: 0.860000  [33050/45000]\n",
            "cost: 0.237482, accuracy: 0.900000  [33550/45000]\n",
            "cost: 0.252352, accuracy: 0.860000  [34050/45000]\n",
            "cost: 0.192921, accuracy: 0.920000  [34550/45000]\n",
            "cost: 0.357378, accuracy: 0.820000  [35050/45000]\n",
            "cost: 0.298590, accuracy: 0.860000  [35550/45000]\n",
            "cost: 0.297773, accuracy: 0.880000  [36050/45000]\n",
            "cost: 0.238704, accuracy: 0.900000  [36550/45000]\n",
            "cost: 0.262376, accuracy: 0.900000  [37050/45000]\n",
            "cost: 0.477194, accuracy: 0.800000  [37550/45000]\n",
            "cost: 0.339698, accuracy: 0.840000  [38050/45000]\n",
            "cost: 0.217957, accuracy: 0.920000  [38550/45000]\n",
            "cost: 0.224802, accuracy: 0.900000  [39050/45000]\n",
            "cost: 0.166095, accuracy: 0.960000  [39550/45000]\n",
            "cost: 0.233679, accuracy: 0.840000  [40050/45000]\n",
            "cost: 0.267332, accuracy: 0.840000  [40550/45000]\n",
            "cost: 0.243300, accuracy: 0.960000  [41050/45000]\n",
            "cost: 0.278070, accuracy: 0.920000  [41550/45000]\n",
            "cost: 0.318080, accuracy: 0.880000  [42050/45000]\n",
            "cost: 0.257118, accuracy: 0.920000  [42550/45000]\n",
            "cost: 0.168731, accuracy: 0.940000  [43050/45000]\n",
            "cost: 0.451157, accuracy: 0.800000  [43550/45000]\n",
            "cost: 0.297420, accuracy: 0.860000  [44050/45000]\n",
            "cost: 0.169611, accuracy: 0.940000  [44550/45000]\n",
            "cost: 0.160839, accuracy: 0.960000  [   50/45000]\n",
            "cost: 0.265804, accuracy: 0.860000  [  550/45000]\n",
            "cost: 0.355210, accuracy: 0.900000  [ 1050/45000]\n",
            "cost: 0.171494, accuracy: 0.900000  [ 1550/45000]\n",
            "cost: 0.264563, accuracy: 0.900000  [ 2050/45000]\n",
            "cost: 0.213267, accuracy: 0.920000  [ 2550/45000]\n",
            "cost: 0.237330, accuracy: 0.880000  [ 3050/45000]\n",
            "cost: 0.370874, accuracy: 0.940000  [ 3550/45000]\n",
            "cost: 0.130508, accuracy: 0.960000  [ 4050/45000]\n",
            "cost: 0.144278, accuracy: 0.960000  [ 4550/45000]\n",
            "cost: 0.335157, accuracy: 0.840000  [ 5050/45000]\n",
            "cost: 0.155835, accuracy: 0.940000  [ 5550/45000]\n",
            "cost: 0.234402, accuracy: 0.920000  [ 6050/45000]\n",
            "cost: 0.286175, accuracy: 0.860000  [ 6550/45000]\n",
            "cost: 0.194007, accuracy: 0.940000  [ 7050/45000]\n",
            "cost: 0.644766, accuracy: 0.780000  [ 7550/45000]\n",
            "cost: 0.151215, accuracy: 0.960000  [ 8050/45000]\n",
            "cost: 0.303350, accuracy: 0.880000  [ 8550/45000]\n",
            "cost: 0.236336, accuracy: 0.920000  [ 9050/45000]\n",
            "cost: 0.164900, accuracy: 0.920000  [ 9550/45000]\n",
            "cost: 0.260546, accuracy: 0.880000  [10050/45000]\n",
            "cost: 0.250466, accuracy: 0.940000  [10550/45000]\n",
            "cost: 0.179906, accuracy: 0.940000  [11050/45000]\n",
            "cost: 0.195708, accuracy: 0.920000  [11550/45000]\n",
            "cost: 0.084198, accuracy: 0.980000  [12050/45000]\n",
            "cost: 0.280131, accuracy: 0.920000  [12550/45000]\n",
            "cost: 0.223910, accuracy: 0.880000  [13050/45000]\n",
            "cost: 0.143391, accuracy: 0.960000  [13550/45000]\n",
            "cost: 0.151966, accuracy: 0.960000  [14050/45000]\n",
            "cost: 0.305595, accuracy: 0.920000  [14550/45000]\n",
            "cost: 0.188045, accuracy: 0.900000  [15050/45000]\n",
            "cost: 0.165126, accuracy: 0.940000  [15550/45000]\n",
            "cost: 0.174436, accuracy: 0.940000  [16050/45000]\n",
            "cost: 0.085982, accuracy: 0.980000  [16550/45000]\n",
            "cost: 0.281752, accuracy: 0.920000  [17050/45000]\n",
            "cost: 0.168848, accuracy: 0.940000  [17550/45000]\n",
            "cost: 0.093747, accuracy: 0.980000  [18050/45000]\n",
            "cost: 0.252888, accuracy: 0.940000  [18550/45000]\n",
            "cost: 0.171788, accuracy: 0.900000  [19050/45000]\n",
            "cost: 0.133583, accuracy: 0.960000  [19550/45000]\n",
            "cost: 0.262253, accuracy: 0.900000  [20050/45000]\n",
            "cost: 0.093861, accuracy: 0.980000  [20550/45000]\n",
            "cost: 0.138695, accuracy: 0.960000  [21050/45000]\n",
            "cost: 0.193237, accuracy: 0.920000  [21550/45000]\n",
            "cost: 0.171905, accuracy: 0.940000  [22050/45000]\n",
            "cost: 0.201660, accuracy: 0.920000  [22550/45000]\n",
            "cost: 0.206142, accuracy: 0.940000  [23050/45000]\n",
            "cost: 0.151013, accuracy: 0.920000  [23550/45000]\n",
            "cost: 0.238275, accuracy: 0.880000  [24050/45000]\n",
            "cost: 0.209330, accuracy: 0.900000  [24550/45000]\n",
            "cost: 0.270135, accuracy: 0.860000  [25050/45000]\n",
            "cost: 0.237456, accuracy: 0.880000  [25550/45000]\n",
            "cost: 0.177444, accuracy: 0.940000  [26050/45000]\n",
            "cost: 0.088456, accuracy: 0.980000  [26550/45000]\n",
            "cost: 0.188357, accuracy: 0.920000  [27050/45000]\n",
            "cost: 0.193433, accuracy: 0.960000  [27550/45000]\n",
            "cost: 0.230854, accuracy: 0.880000  [28050/45000]\n",
            "cost: 0.201602, accuracy: 0.940000  [28550/45000]\n",
            "cost: 0.213579, accuracy: 0.900000  [29050/45000]\n",
            "cost: 0.156740, accuracy: 0.920000  [29550/45000]\n",
            "cost: 0.376068, accuracy: 0.900000  [30050/45000]\n",
            "cost: 0.262686, accuracy: 0.880000  [30550/45000]\n",
            "cost: 0.323435, accuracy: 0.880000  [31050/45000]\n",
            "cost: 0.154307, accuracy: 0.940000  [31550/45000]\n",
            "cost: 0.385445, accuracy: 0.900000  [32050/45000]\n",
            "cost: 0.200452, accuracy: 0.880000  [32550/45000]\n",
            "cost: 0.226472, accuracy: 0.900000  [33050/45000]\n",
            "cost: 0.096853, accuracy: 0.960000  [33550/45000]\n",
            "cost: 0.086931, accuracy: 0.980000  [34050/45000]\n",
            "cost: 0.306753, accuracy: 0.860000  [34550/45000]\n",
            "cost: 0.265002, accuracy: 0.940000  [35050/45000]\n",
            "cost: 0.239972, accuracy: 0.920000  [35550/45000]\n",
            "cost: 0.121649, accuracy: 0.900000  [36050/45000]\n",
            "cost: 0.280486, accuracy: 0.900000  [36550/45000]\n",
            "cost: 0.340967, accuracy: 0.820000  [37050/45000]\n",
            "cost: 0.130411, accuracy: 0.960000  [37550/45000]\n",
            "cost: 0.271675, accuracy: 0.900000  [38050/45000]\n",
            "cost: 0.139311, accuracy: 0.940000  [38550/45000]\n",
            "cost: 0.250045, accuracy: 0.900000  [39050/45000]\n",
            "cost: 0.275970, accuracy: 0.900000  [39550/45000]\n",
            "cost: 0.166518, accuracy: 0.960000  [40050/45000]\n",
            "cost: 0.263693, accuracy: 0.900000  [40550/45000]\n",
            "cost: 0.195661, accuracy: 0.920000  [41050/45000]\n",
            "cost: 0.160338, accuracy: 0.920000  [41550/45000]\n",
            "cost: 0.285879, accuracy: 0.880000  [42050/45000]\n",
            "cost: 0.268202, accuracy: 0.820000  [42550/45000]\n",
            "cost: 0.297713, accuracy: 0.860000  [43050/45000]\n",
            "cost: 0.172798, accuracy: 0.920000  [43550/45000]\n",
            "cost: 0.195949, accuracy: 0.940000  [44050/45000]\n",
            "cost: 0.223562, accuracy: 0.880000  [44550/45000]\n",
            "cost: 0.107249, accuracy: 0.920000  [   50/45000]\n",
            "cost: 0.107008, accuracy: 0.960000  [  550/45000]\n",
            "cost: 0.091284, accuracy: 0.980000  [ 1050/45000]\n",
            "cost: 0.265334, accuracy: 0.920000  [ 1550/45000]\n",
            "cost: 0.112267, accuracy: 0.920000  [ 2050/45000]\n",
            "cost: 0.123744, accuracy: 0.980000  [ 2550/45000]\n",
            "cost: 0.193349, accuracy: 0.940000  [ 3050/45000]\n",
            "cost: 0.080841, accuracy: 0.980000  [ 3550/45000]\n",
            "cost: 0.123091, accuracy: 0.940000  [ 4050/45000]\n",
            "cost: 0.125246, accuracy: 0.940000  [ 4550/45000]\n",
            "cost: 0.175182, accuracy: 0.940000  [ 5050/45000]\n",
            "cost: 0.105356, accuracy: 0.980000  [ 5550/45000]\n",
            "cost: 0.113901, accuracy: 0.980000  [ 6050/45000]\n",
            "cost: 0.136774, accuracy: 0.980000  [ 6550/45000]\n",
            "cost: 0.101431, accuracy: 0.960000  [ 7050/45000]\n",
            "cost: 0.100904, accuracy: 0.940000  [ 7550/45000]\n",
            "cost: 0.111872, accuracy: 0.960000  [ 8050/45000]\n",
            "cost: 0.168662, accuracy: 0.920000  [ 8550/45000]\n",
            "cost: 0.177201, accuracy: 0.940000  [ 9050/45000]\n",
            "cost: 0.064480, accuracy: 0.980000  [ 9550/45000]\n",
            "cost: 0.117614, accuracy: 0.940000  [10050/45000]\n",
            "cost: 0.263993, accuracy: 0.860000  [10550/45000]\n",
            "cost: 0.183118, accuracy: 0.920000  [11050/45000]\n",
            "cost: 0.183894, accuracy: 0.940000  [11550/45000]\n",
            "cost: 0.142345, accuracy: 0.960000  [12050/45000]\n",
            "cost: 0.148390, accuracy: 0.940000  [12550/45000]\n",
            "cost: 0.159497, accuracy: 0.940000  [13050/45000]\n",
            "cost: 0.313378, accuracy: 0.920000  [13550/45000]\n",
            "cost: 0.074467, accuracy: 0.980000  [14050/45000]\n",
            "cost: 0.081890, accuracy: 0.980000  [14550/45000]\n",
            "cost: 0.047175, accuracy: 0.980000  [15050/45000]\n",
            "cost: 0.161963, accuracy: 0.920000  [15550/45000]\n",
            "cost: 0.113731, accuracy: 0.940000  [16050/45000]\n",
            "cost: 0.221843, accuracy: 0.940000  [16550/45000]\n",
            "cost: 0.062362, accuracy: 0.980000  [17050/45000]\n",
            "cost: 0.115664, accuracy: 0.940000  [17550/45000]\n",
            "cost: 0.133173, accuracy: 0.960000  [18050/45000]\n",
            "cost: 0.102845, accuracy: 0.940000  [18550/45000]\n",
            "cost: 0.134959, accuracy: 0.940000  [19050/45000]\n",
            "cost: 0.136617, accuracy: 0.940000  [19550/45000]\n",
            "cost: 0.128579, accuracy: 0.920000  [20050/45000]\n",
            "cost: 0.095938, accuracy: 0.960000  [20550/45000]\n",
            "cost: 0.122553, accuracy: 0.980000  [21050/45000]\n",
            "cost: 0.115380, accuracy: 0.980000  [21550/45000]\n",
            "cost: 0.070931, accuracy: 0.980000  [22050/45000]\n",
            "cost: 0.075476, accuracy: 0.980000  [22550/45000]\n",
            "cost: 0.216386, accuracy: 0.940000  [23050/45000]\n",
            "cost: 0.148018, accuracy: 0.960000  [23550/45000]\n",
            "cost: 0.180730, accuracy: 0.900000  [24050/45000]\n",
            "cost: 0.260996, accuracy: 0.940000  [24550/45000]\n",
            "cost: 0.256016, accuracy: 0.940000  [25050/45000]\n",
            "cost: 0.124665, accuracy: 0.960000  [25550/45000]\n",
            "cost: 0.340790, accuracy: 0.880000  [26050/45000]\n",
            "cost: 0.116549, accuracy: 0.940000  [26550/45000]\n",
            "cost: 0.132477, accuracy: 0.940000  [27050/45000]\n",
            "cost: 0.073517, accuracy: 1.000000  [27550/45000]\n",
            "cost: 0.141998, accuracy: 0.920000  [28050/45000]\n",
            "cost: 0.128929, accuracy: 0.960000  [28550/45000]\n",
            "cost: 0.145452, accuracy: 0.940000  [29050/45000]\n",
            "cost: 0.104458, accuracy: 0.940000  [29550/45000]\n",
            "cost: 0.091226, accuracy: 0.980000  [30050/45000]\n",
            "cost: 0.169653, accuracy: 0.940000  [30550/45000]\n",
            "cost: 0.104949, accuracy: 0.980000  [31050/45000]\n",
            "cost: 0.058041, accuracy: 1.000000  [31550/45000]\n",
            "cost: 0.138505, accuracy: 0.940000  [32050/45000]\n",
            "cost: 0.241212, accuracy: 0.920000  [32550/45000]\n",
            "cost: 0.089404, accuracy: 0.980000  [33050/45000]\n",
            "cost: 0.236020, accuracy: 0.920000  [33550/45000]\n",
            "cost: 0.054791, accuracy: 1.000000  [34050/45000]\n",
            "cost: 0.207788, accuracy: 0.920000  [34550/45000]\n",
            "cost: 0.048257, accuracy: 1.000000  [35050/45000]\n",
            "cost: 0.212004, accuracy: 0.920000  [35550/45000]\n",
            "cost: 0.078096, accuracy: 0.960000  [36050/45000]\n",
            "cost: 0.100534, accuracy: 0.980000  [36550/45000]\n",
            "cost: 0.090863, accuracy: 0.980000  [37050/45000]\n",
            "cost: 0.098609, accuracy: 0.940000  [37550/45000]\n",
            "cost: 0.107602, accuracy: 0.960000  [38050/45000]\n",
            "cost: 0.171227, accuracy: 0.900000  [38550/45000]\n",
            "cost: 0.316870, accuracy: 0.860000  [39050/45000]\n",
            "cost: 0.087138, accuracy: 0.980000  [39550/45000]\n",
            "cost: 0.270506, accuracy: 0.860000  [40050/45000]\n",
            "cost: 0.073491, accuracy: 0.960000  [40550/45000]\n",
            "cost: 0.126442, accuracy: 0.940000  [41050/45000]\n",
            "cost: 0.088541, accuracy: 0.980000  [41550/45000]\n",
            "cost: 0.191439, accuracy: 0.920000  [42050/45000]\n",
            "cost: 0.109126, accuracy: 0.980000  [42550/45000]\n",
            "cost: 0.130459, accuracy: 0.960000  [43050/45000]\n",
            "cost: 0.074926, accuracy: 0.980000  [43550/45000]\n",
            "cost: 0.066871, accuracy: 0.980000  [44050/45000]\n",
            "cost: 0.076072, accuracy: 0.980000  [44550/45000]\n",
            "cost: 0.037198, accuracy: 0.980000  [   50/45000]\n",
            "cost: 0.127483, accuracy: 0.940000  [  550/45000]\n",
            "cost: 0.134141, accuracy: 0.960000  [ 1050/45000]\n",
            "cost: 0.016964, accuracy: 1.000000  [ 1550/45000]\n",
            "cost: 0.323126, accuracy: 0.920000  [ 2050/45000]\n",
            "cost: 0.099633, accuracy: 0.980000  [ 2550/45000]\n",
            "cost: 0.122086, accuracy: 0.960000  [ 3050/45000]\n",
            "cost: 0.193051, accuracy: 0.940000  [ 3550/45000]\n",
            "cost: 0.045232, accuracy: 1.000000  [ 4050/45000]\n",
            "cost: 0.056811, accuracy: 0.980000  [ 4550/45000]\n",
            "cost: 0.070915, accuracy: 0.960000  [ 5050/45000]\n",
            "cost: 0.034589, accuracy: 1.000000  [ 5550/45000]\n",
            "cost: 0.128987, accuracy: 0.920000  [ 6050/45000]\n",
            "cost: 0.071013, accuracy: 0.960000  [ 6550/45000]\n",
            "cost: 0.144871, accuracy: 0.940000  [ 7050/45000]\n",
            "cost: 0.080501, accuracy: 0.960000  [ 7550/45000]\n",
            "cost: 0.062661, accuracy: 0.960000  [ 8050/45000]\n",
            "cost: 0.161005, accuracy: 0.940000  [ 8550/45000]\n",
            "cost: 0.059125, accuracy: 0.980000  [ 9050/45000]\n",
            "cost: 0.069818, accuracy: 0.980000  [ 9550/45000]\n",
            "cost: 0.019547, accuracy: 1.000000  [10050/45000]\n",
            "cost: 0.169583, accuracy: 0.960000  [10550/45000]\n",
            "cost: 0.044777, accuracy: 1.000000  [11050/45000]\n",
            "cost: 0.029033, accuracy: 1.000000  [11550/45000]\n",
            "cost: 0.040613, accuracy: 0.980000  [12050/45000]\n",
            "cost: 0.082410, accuracy: 0.980000  [12550/45000]\n",
            "cost: 0.168137, accuracy: 0.940000  [13050/45000]\n",
            "cost: 0.076925, accuracy: 0.980000  [13550/45000]\n",
            "cost: 0.069240, accuracy: 0.960000  [14050/45000]\n",
            "cost: 0.090655, accuracy: 0.960000  [14550/45000]\n",
            "cost: 0.018775, accuracy: 1.000000  [15050/45000]\n",
            "cost: 0.035777, accuracy: 1.000000  [15550/45000]\n",
            "cost: 0.181491, accuracy: 0.920000  [16050/45000]\n",
            "cost: 0.066331, accuracy: 0.980000  [16550/45000]\n",
            "cost: 0.021481, accuracy: 1.000000  [17050/45000]\n",
            "cost: 0.075531, accuracy: 0.980000  [17550/45000]\n",
            "cost: 0.079900, accuracy: 0.960000  [18050/45000]\n",
            "cost: 0.066487, accuracy: 0.980000  [18550/45000]\n",
            "cost: 0.052385, accuracy: 0.980000  [19050/45000]\n",
            "cost: 0.089322, accuracy: 0.960000  [19550/45000]\n",
            "cost: 0.135616, accuracy: 0.960000  [20050/45000]\n",
            "cost: 0.105532, accuracy: 0.960000  [20550/45000]\n",
            "cost: 0.063130, accuracy: 0.980000  [21050/45000]\n",
            "cost: 0.227044, accuracy: 0.940000  [21550/45000]\n",
            "cost: 0.224085, accuracy: 0.920000  [22050/45000]\n",
            "cost: 0.217142, accuracy: 0.940000  [22550/45000]\n",
            "cost: 0.138188, accuracy: 0.920000  [23050/45000]\n",
            "cost: 0.042108, accuracy: 1.000000  [23550/45000]\n",
            "cost: 0.088721, accuracy: 0.960000  [24050/45000]\n",
            "cost: 0.111101, accuracy: 0.960000  [24550/45000]\n",
            "cost: 0.153159, accuracy: 0.940000  [25050/45000]\n",
            "cost: 0.061216, accuracy: 0.980000  [25550/45000]\n",
            "cost: 0.085090, accuracy: 0.960000  [26050/45000]\n",
            "cost: 0.189991, accuracy: 0.960000  [26550/45000]\n",
            "cost: 0.046540, accuracy: 1.000000  [27050/45000]\n",
            "cost: 0.036248, accuracy: 0.980000  [27550/45000]\n",
            "cost: 0.046458, accuracy: 0.980000  [28050/45000]\n",
            "cost: 0.048015, accuracy: 1.000000  [28550/45000]\n",
            "cost: 0.065264, accuracy: 0.960000  [29050/45000]\n",
            "cost: 0.029366, accuracy: 1.000000  [29550/45000]\n",
            "cost: 0.347624, accuracy: 0.920000  [30050/45000]\n",
            "cost: 0.140137, accuracy: 0.960000  [30550/45000]\n",
            "cost: 0.068273, accuracy: 0.980000  [31050/45000]\n",
            "cost: 0.039589, accuracy: 0.980000  [31550/45000]\n",
            "cost: 0.039110, accuracy: 1.000000  [32050/45000]\n",
            "cost: 0.186362, accuracy: 0.900000  [32550/45000]\n",
            "cost: 0.058667, accuracy: 0.980000  [33050/45000]\n",
            "cost: 0.077808, accuracy: 0.980000  [33550/45000]\n",
            "cost: 0.132398, accuracy: 0.960000  [34050/45000]\n",
            "cost: 0.173728, accuracy: 0.920000  [34550/45000]\n",
            "cost: 0.062557, accuracy: 0.980000  [35050/45000]\n",
            "cost: 0.128716, accuracy: 0.960000  [35550/45000]\n",
            "cost: 0.160384, accuracy: 0.980000  [36050/45000]\n",
            "cost: 0.048014, accuracy: 0.980000  [36550/45000]\n",
            "cost: 0.059384, accuracy: 0.980000  [37050/45000]\n",
            "cost: 0.290144, accuracy: 0.880000  [37550/45000]\n",
            "cost: 0.129740, accuracy: 0.960000  [38050/45000]\n",
            "cost: 0.148956, accuracy: 0.940000  [38550/45000]\n",
            "cost: 0.184178, accuracy: 0.920000  [39050/45000]\n",
            "cost: 0.118245, accuracy: 0.940000  [39550/45000]\n",
            "cost: 0.068639, accuracy: 0.980000  [40050/45000]\n",
            "cost: 0.035247, accuracy: 1.000000  [40550/45000]\n",
            "cost: 0.042560, accuracy: 1.000000  [41050/45000]\n",
            "cost: 0.052171, accuracy: 0.980000  [41550/45000]\n",
            "cost: 0.061457, accuracy: 1.000000  [42050/45000]\n",
            "cost: 0.050936, accuracy: 0.980000  [42550/45000]\n",
            "cost: 0.097294, accuracy: 0.980000  [43050/45000]\n",
            "cost: 0.121641, accuracy: 0.960000  [43550/45000]\n",
            "cost: 0.083925, accuracy: 0.960000  [44050/45000]\n",
            "cost: 0.109857, accuracy: 0.960000  [44550/45000]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy: 87.28, best accuracy: 88.46\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import InputLayer\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn import model_selection\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "#from gensim.models.keyedvectors import KeyedVectors\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "device=torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "\n",
        "data=pd.read_csv(\"xaa\",encoding=\"utf-8\")\n",
        "\n",
        "vect  = CountVectorizer(stop_words=\"english\",max_df=0.7)\n",
        "\n",
        "glove_file=\"drive/MyDrive/Colab Notebooks/glove.6B/glove.6B.100d.txt\"\n",
        "embed_dim=100\n",
        "glove_data_f=np.genfromtxt(glove_file,dtype=float,invalid_raise=False)\n",
        "glove_data_s=np.genfromtxt(glove_file,dtype=str,usecols=0,invalid_raise=False)\n",
        "glove_vocab=dict(zip(glove_data_s,[x for x in range(1,len(glove_data_s)+1)]))\n",
        "dummy_vec=np.zeros(embed_dim)\n",
        "glove_vocab[\"</s>\"]=0\n",
        "glove_data_f=np.vstack((dummy_vec,glove_data_f[:,1:]))\n",
        "glove_model=glove_data_f\n",
        "print(glove_model.shape)\n",
        "# Initalise vect.vocabulary_\n",
        "vect.fit_transform(data[\"text\"])\n",
        "\n",
        "maxlen=0\n",
        "\n",
        "def transform(text,vect):\n",
        "    global maxlen\n",
        "    global glove_model\n",
        "    #d=vect.vocabulary_\n",
        "    d=glove_vocab\n",
        "    p=vect.build_preprocessor()\n",
        "    t=vect.build_tokenizer()\n",
        "    vec_list=[]\n",
        "    for doc in text:\n",
        "        tokens=t(p(doc))\n",
        "        doc_vec=np.array([d[token] for token in tokens if token in d])\n",
        "        s=len(doc_vec)\n",
        "        if s>maxlen:\n",
        "            maxlen=s\n",
        "        #doc_vec=sequence.pad_sequences(doc_vec,maxlen=maxlen)\n",
        "        vec_list.append(doc_vec)\n",
        "    vec_list=sequence.pad_sequences(vec_list,maxlen=maxlen,padding=\"post\")\n",
        "    corpus_vec=np.vstack(vec_list)\n",
        "    #return nn.functional.normalize(torch.tensor(corpus_vec).float())\n",
        "    return torch.tensor(corpus_vec)\n",
        "    #return torch.tensor(corpus_vec).float()\n",
        "\n",
        "# print(corpus_vec)\n",
        "\n",
        "bsize=50\n",
        "epochs=5\n",
        "lr=5e-4\n",
        "\n",
        "class corpus(Dataset):\n",
        "    def __init__(self,corpus,label,seq):\n",
        "        self.corpus=corpus\n",
        "        self.label=label\n",
        "        self.seq=seq\n",
        "    def __len__(self):\n",
        "        return len(self.corpus)\n",
        "    def __getitem__(self,idx):\n",
        "        return self.corpus[idx],self.label[idx]\n",
        "\n",
        "class lstm(nn.Module):\n",
        "    def __init__(self,input_size,hidden_size,seq):\n",
        "        super(lstm,self).__init__()\n",
        "        self.input_size=input_size\n",
        "        self.hidden_size=hidden_size\n",
        "        self.seq=seq\n",
        "        self.rnn=True\n",
        "        self.lstm=nn.LSTM(input_size,hidden_size,batch_first=True,num_layers=2)\n",
        "        self.fc=nn.Linear(self.hidden_size*seq,1)\n",
        "        #self.fc=nn.Linear(self.hidden_size,1)\n",
        "        #self.embed=nn.Embedding(len(vect.vocabulary_),input_size)\n",
        "        self.embed=nn.Embedding.from_pretrained(torch.tensor(glove_model).float(),freeze=False)\n",
        "\n",
        "    def forward(self,x,h0=None,c0=None):\n",
        "        x=self.embed(x)\n",
        "        if h0==None and c0==None:\n",
        "            x, (hn,cn) = self.lstm(x)\n",
        "        else:\n",
        "            x, (hn,cn) = self.lstm(x,(h0,c0))\n",
        "        #print(x[:,-1,:].shape)\n",
        "        #x = torch.flatten(x[:,-1,:],1)\n",
        "        # Flatten like this so that all information from previous time steps is fed into fully connected layer\n",
        "        x=torch.flatten(x,1)\n",
        "        x = self.fc(x)\n",
        "        return nn.Sigmoid()(x), hn,cn\n",
        "        #return nn.Softmax()(x), hn,cn\n",
        "\n",
        "class dense(nn.Module):\n",
        "    def __init__(self,seq,vocab,embed_dim):\n",
        "        super(dense,self).__init__()\n",
        "        self.seq=seq\n",
        "        self.rnn=False\n",
        "        self.network=nn.Sequential(\n",
        "            nn.Linear(embed_dim*seq,360),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(360,180),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(180,1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.embed=nn.Embedding(vocab,embed_dim)\n",
        "\n",
        "    def forward(self,x):\n",
        "        #print(x.shape)\n",
        "        x=self.embed(x)\n",
        "        x=torch.flatten(x,1)\n",
        "        #x=torch.transpose(x,1,2)\n",
        "        #x=torch.flatten(x,1)\n",
        "        return self.network(x)\n",
        "\n",
        "vocab=len(vect.vocabulary_)\n",
        "Encoder = LabelEncoder()\n",
        "corpus_vec = transform(data[\"text\"],vect)\n",
        "print(maxlen)\n",
        "print(corpus_vec.shape)\n",
        "print(data[\"label\"].shape)\n",
        "train_corpus_vec, test_corpus_vec, train_label, test_label = model_selection.train_test_split(corpus_vec,data[\"label\"],test_size=0.1)\n",
        "train_label = torch.from_numpy(Encoder.fit_transform(train_label)).float()\n",
        "test_label = torch.from_numpy(Encoder.fit_transform(test_label)).float()\n",
        "#train_corpus_vec = transform(train_corpus,vect)\n",
        "#test_corpus_vec = transform(test_corpus,vect)\n",
        "lstm_classifier=lstm(embed_dim,200,maxlen)\n",
        "loss_fn=nn.BCELoss()\n",
        "#loss_fn=nn.BCEWithLogitsLoss()\n",
        "#loss_fn=nn.MSELoss()\n",
        "optimizer=torch.optim.Adam(lstm_classifier.parameters(),lr=lr)\n",
        "#optimizer=torch.optim.SGD(lstm_classifier.parameters(),lr=lr)\n",
        "#print(len(lstm_classifier(torch.reshape(train_corpus_vec[0],(bsize,maxlen,1)))))\n",
        "\n",
        "dense_classifier=dense(maxlen,vocab,16)\n",
        "\n",
        "c=lstm_classifier\n",
        "\n",
        "c=c.to(device)\n",
        "\n",
        "train_dataloader=DataLoader(corpus(train_corpus_vec,train_label,maxlen),batch_size=bsize,shuffle=True)\n",
        "test_dataloader=DataLoader(corpus(test_corpus_vec,test_label,maxlen),batch_size=bsize,shuffle=True)\n",
        "\n",
        "def train(dataloader,model,loss_fn,optimizer):\n",
        "    hn,cn=None,None\n",
        "    size=len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch,(x,y) in enumerate(dataloader):\n",
        "        x,y=x.to(device),y.to(device)\n",
        "        #print(torch.sum(x[0]!=0))\n",
        "        if model.rnn==True:\n",
        "            #pred,hn,cn=model(x.reshape(bsize,dataloader.dataset.seq,1).to(device),hn,cn)\n",
        "            pred,hn,cn=model(x,hn,cn)\n",
        "        else:\n",
        "            pred=model(x)\n",
        "        #pred=model(x)\n",
        "        cost=loss_fn(pred.flatten(),y)\n",
        "        cost.backward()\n",
        "        #if model.rnn==True:\n",
        "        #    print(model.lstm.weight_ih_l0.grad[0][0])\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if model.rnn==True:\n",
        "            hn=hn.detach()\n",
        "            cn=cn.detach()\n",
        "        if batch % 10 == 0:\n",
        "            cost_val, current = cost.item(), batch * bsize + len(x)\n",
        "            print(f\"cost: {cost_val:>7f}, accuracy: {(torch.round(pred.flatten())==y).sum().item()/bsize:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x,y=x.to(device),y.to(device)\n",
        "            if model.rnn==True:\n",
        "                #pred,_,_=model(x.reshape(bsize,dataloader.dataset.seq,1).to(device))\n",
        "                pred,_,_=model(x)\n",
        "            else:\n",
        "                pred=model(x)\n",
        "            #pred=model(x)\n",
        "            #print(torch.round(pred.flatten()),y)\n",
        "            test_loss += loss_fn(pred.flatten(), y).item()\n",
        "            ncorrect = (torch.round(pred.flatten()) == y).sum().item()\n",
        "            #print(ncorrect)\n",
        "            correct += ncorrect\n",
        "\n",
        "    #print(correct,size)\n",
        "    #print(f\"Test Error: \\n Accuracy: {(100*correct/size):>0.1f}%, Avg loss: {100*test_loss/size:>8f} \\n\")\n",
        "    return 100*correct/size\n",
        "\n",
        "#keras_model=Sequential([InputLayer(input_shape=(maxlen,),batch_size=bsize),\n",
        "#                        Embedding(len(vect.vocabulary_),16),\n",
        "#                  Flatten(),\n",
        "#                  Dense(1,activation=\"sigmoid\")])\n",
        "keras_model=Sequential([InputLayer(shape=(maxlen,),batch_size=bsize),\n",
        "                        Embedding(len(glove_model),embed_dim),\n",
        "                        LSTM(20,return_sequences=True),\n",
        "                  Flatten(),\n",
        "                  Dense(1,activation=\"sigmoid\")])\n",
        "keras_model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "keras_model.summary()\n",
        "\n",
        "use_torch=True\n",
        "\n",
        "x=np.arange(epochs)\n",
        "y=np.zeros(epochs)\n",
        "#print(corpus_vec[0])\n",
        "if use_torch==True:\n",
        "    for epoch in range(epochs):\n",
        "        train(train_dataloader,c,loss_fn,optimizer)\n",
        "        y[epoch] = test_loop(test_dataloader,c,loss_fn)\n",
        "    plt.plot(x,y)\n",
        "    plt.show()\n",
        "    print(f\"Final accuracy: {y[-1]:.2f}, best accuracy: {y[np.argmax(y)]:.2f}\")\n",
        "else:\n",
        "    keras_model.fit(train_corpus_vec,train_label,batch_size=bsize,epochs=epochs,validation_data=(test_corpus_vec,test_label))\n",
        "    keras_model.evaluate(test_corpus_vec,test_label,batch_size=bsize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "cy5ekCL0mHOK",
        "outputId": "50bf64f8-6c00-4eea-de28-148134aac8bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "bb82bdc02b794425b75e0671de117afe",
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vx6v266o_lK-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EdHfJkrFBpo",
        "outputId": "93a61279-c917-4845-f223-6b7729de06f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3000000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([ 5.34057617e-04,  3.11279297e-02,  5.03540039e-03, -9.17968750e-02,\n",
              "       -8.36181641e-03, -1.66015625e-01,  3.93066406e-02,  2.97851562e-02,\n",
              "        1.69921875e-01, -2.04101562e-01,  2.41210938e-01, -3.04687500e-01,\n",
              "       -2.24609375e-02, -3.71093750e-01, -5.61523438e-02,  1.51367188e-01,\n",
              "       -1.21582031e-01,  3.41796875e-01,  3.05175781e-02, -2.94921875e-01,\n",
              "        6.54296875e-02, -9.27734375e-02,  1.49414062e-01,  8.15429688e-02,\n",
              "       -6.93359375e-02,  1.98242188e-01, -1.66015625e-01,  2.00195312e-01,\n",
              "        1.16699219e-01, -3.69140625e-01, -2.48046875e-01,  1.25976562e-01,\n",
              "        3.59375000e-01,  1.51367188e-01, -7.76367188e-02,  2.91015625e-01,\n",
              "       -1.74560547e-02, -1.21093750e-01, -1.00097656e-01,  1.43554688e-01,\n",
              "        5.92041016e-03,  2.35595703e-02,  3.20312500e-01,  1.82617188e-01,\n",
              "        9.52148438e-02,  9.22851562e-02,  8.30078125e-02, -1.33789062e-01,\n",
              "        9.57031250e-02,  1.66992188e-01,  1.87988281e-02, -2.79541016e-02,\n",
              "       -1.03149414e-02,  1.11816406e-01, -8.10546875e-02,  1.79687500e-01,\n",
              "        8.34960938e-02, -5.90820312e-02,  1.70898438e-01,  1.68457031e-02,\n",
              "        8.74023438e-02,  9.03320312e-02,  9.22851562e-02, -9.76562500e-02,\n",
              "       -2.39257812e-02, -2.07031250e-01, -1.21459961e-02,  1.44531250e-01,\n",
              "        6.20117188e-02, -1.44042969e-02,  2.81250000e-01,  6.83593750e-02,\n",
              "       -2.12890625e-01,  4.68750000e-02, -1.00097656e-01, -1.35742188e-01,\n",
              "        7.47070312e-02, -2.69531250e-01,  7.56835938e-02, -5.51757812e-02,\n",
              "       -2.01416016e-02, -3.80859375e-01,  1.67968750e-01, -3.90625000e-01,\n",
              "        5.54199219e-02,  2.23632812e-01, -6.28662109e-03,  7.76367188e-02,\n",
              "        2.03125000e-01, -1.04980469e-01, -3.12500000e-02,  3.53515625e-01,\n",
              "        1.54296875e-01, -1.25976562e-01, -2.24609375e-02, -3.80859375e-01,\n",
              "        3.12500000e-01,  2.12890625e-01,  1.97265625e-01, -4.49218750e-01,\n",
              "       -9.22851562e-02, -2.94921875e-01,  2.21679688e-01, -2.58789062e-02,\n",
              "        1.38671875e-01,  7.37304688e-02, -1.10839844e-01, -3.00781250e-01,\n",
              "        1.29882812e-01, -1.74804688e-01,  1.37939453e-02,  7.51953125e-02,\n",
              "        2.98828125e-01, -7.61718750e-02,  9.76562500e-02, -2.53906250e-01,\n",
              "       -8.69140625e-02, -9.86328125e-02, -4.49218750e-02,  1.00585938e-01,\n",
              "       -1.68945312e-01,  1.06933594e-01, -1.07910156e-01, -3.57421875e-01,\n",
              "       -3.58886719e-02, -3.24707031e-02,  1.62109375e-01, -1.17187500e-01,\n",
              "       -1.49414062e-01,  2.31933594e-02, -4.14062500e-01,  2.85644531e-02,\n",
              "       -2.57812500e-01, -6.59179688e-02, -4.80957031e-02, -1.87500000e-01,\n",
              "        5.10253906e-02,  7.86132812e-02, -7.56835938e-02,  3.20312500e-01,\n",
              "        7.08007812e-02, -1.08886719e-01, -3.03955078e-02,  1.53320312e-01,\n",
              "        8.93554688e-02,  8.83789062e-02, -2.01416016e-02, -1.66992188e-01,\n",
              "       -8.88671875e-02,  7.20214844e-03,  4.88281250e-01,  7.66601562e-02,\n",
              "        6.68945312e-02, -4.34570312e-02, -2.41210938e-01, -9.71679688e-02,\n",
              "        7.47070312e-02, -3.24218750e-01, -3.14453125e-01, -8.74023438e-02,\n",
              "       -8.20312500e-02,  2.33154297e-02,  2.55859375e-01, -1.06445312e-01,\n",
              "        1.13769531e-01, -4.71191406e-02, -4.83398438e-02, -4.31640625e-01,\n",
              "        3.41796875e-02,  1.66015625e-02, -6.00585938e-02, -1.82617188e-01,\n",
              "       -3.56445312e-02, -8.59375000e-02, -5.88378906e-02,  1.19628906e-01,\n",
              "        1.33789062e-01, -3.73535156e-02, -1.79687500e-01,  8.59375000e-02,\n",
              "       -2.63671875e-01, -3.36914062e-02, -2.22167969e-02,  9.52148438e-02,\n",
              "        1.05468750e-01, -1.63085938e-01,  2.65625000e-01,  1.77734375e-01,\n",
              "       -2.37304688e-01,  1.58203125e-01, -4.00390625e-02, -5.71289062e-02,\n",
              "        1.51367188e-01,  1.52343750e-01,  2.71484375e-01, -2.13867188e-01,\n",
              "        1.81884766e-02, -4.98046875e-02, -2.65625000e-01, -1.05468750e-01,\n",
              "        4.98046875e-02, -5.54687500e-01, -2.91015625e-01, -9.61914062e-02,\n",
              "       -9.52148438e-02, -4.17480469e-02, -2.57812500e-01, -6.25000000e-02,\n",
              "        9.37500000e-02, -2.09960938e-02, -2.48046875e-01,  4.51660156e-02,\n",
              "        1.56250000e-01, -1.74804688e-01, -1.37695312e-01,  1.54296875e-01,\n",
              "       -3.94531250e-01, -1.66992188e-01,  2.07031250e-01,  1.55273438e-01,\n",
              "        2.08984375e-01,  2.69531250e-01,  3.26171875e-01, -1.24023438e-01,\n",
              "        1.64794922e-02, -5.05371094e-02,  3.10546875e-01, -3.24707031e-02,\n",
              "        3.41796875e-01, -9.96093750e-02,  4.15039062e-02, -3.06640625e-01,\n",
              "        4.83398438e-02,  2.08007812e-01, -4.10156250e-01, -7.22656250e-02,\n",
              "        1.09863281e-01, -2.67578125e-01,  2.28515625e-01, -1.02050781e-01,\n",
              "        1.83593750e-01, -2.44140625e-01,  2.21679688e-01,  2.01171875e-01,\n",
              "        3.10546875e-01, -2.14843750e-01, -3.41796875e-02,  2.57812500e-01,\n",
              "        2.53906250e-02,  7.66601562e-02, -1.18164062e-01,  2.41210938e-01,\n",
              "       -9.61914062e-02, -1.16699219e-01, -8.34960938e-02,  2.37304688e-01,\n",
              "       -1.10839844e-01,  6.73828125e-02, -4.35546875e-01, -3.32641602e-03,\n",
              "       -1.27929688e-01, -6.53076172e-03,  2.72216797e-02,  2.83203125e-01,\n",
              "       -4.19921875e-02,  8.00781250e-02,  1.12792969e-01, -2.73437500e-01,\n",
              "       -2.63671875e-01,  2.04101562e-01, -8.54492188e-02,  1.91497803e-03,\n",
              "       -2.04101562e-01,  6.83593750e-02, -6.54296875e-02, -1.35742188e-01,\n",
              "       -2.57568359e-02, -3.96484375e-01, -2.94189453e-02,  4.33593750e-01,\n",
              "        6.03027344e-02,  3.41796875e-03,  1.74804688e-01,  6.44531250e-02,\n",
              "       -3.97949219e-02, -7.32421875e-02, -1.50390625e-01,  2.56347656e-02,\n",
              "        2.91015625e-01,  2.61718750e-01, -2.32421875e-01,  1.13769531e-01,\n",
              "       -2.53906250e-01,  1.75781250e-01,  1.89453125e-01,  2.65625000e-01,\n",
              "        1.66015625e-01,  2.85156250e-01, -1.63085938e-01,  6.07910156e-02],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(word2vec_model))\n",
        "word2vec_model[\"horse\"]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1GWdqo_CT23IvFsw6JlVd8ZVoqn9oo3GQ",
      "authorship_tag": "ABX9TyNHpSMO+IfIYSQzc8gsXrDs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}