{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nwon24/nlp/blob/main/LSTM_WordEmbeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "dWAcH6mWYxkE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1173ca67-6be1-497e-d105-aa55a8394484"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_34\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_34\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_34 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m167\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │     \u001b[38;5;34m6,000,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_34 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m167\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │        \u001b[38;5;34m25,680\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_34 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m3340\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │         \u001b[38;5;34m3,341\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">167</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,000,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">167</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,680</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3340</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,341</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,029,021\u001b[0m (23.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,029,021</span> (23.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,029,021\u001b[0m (23.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,029,021</span> (23.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost: 0.694157, accuracy: 0.460000  [   50/18000]\n",
            "cost: 0.753023, accuracy: 0.460000  [  550/18000]\n",
            "cost: 0.723265, accuracy: 0.440000  [ 1050/18000]\n",
            "cost: 0.690467, accuracy: 0.540000  [ 1550/18000]\n",
            "cost: 0.696410, accuracy: 0.440000  [ 2050/18000]\n",
            "cost: 0.686506, accuracy: 0.560000  [ 2550/18000]\n",
            "cost: 0.690782, accuracy: 0.480000  [ 3050/18000]\n",
            "cost: 0.691646, accuracy: 0.520000  [ 3550/18000]\n",
            "cost: 0.674452, accuracy: 0.560000  [ 4050/18000]\n",
            "cost: 0.672038, accuracy: 0.600000  [ 4550/18000]\n",
            "cost: 0.516048, accuracy: 0.740000  [ 5050/18000]\n",
            "cost: 0.755956, accuracy: 0.560000  [ 5550/18000]\n",
            "cost: 0.569716, accuracy: 0.720000  [ 6050/18000]\n",
            "cost: 0.607481, accuracy: 0.700000  [ 6550/18000]\n",
            "cost: 0.570439, accuracy: 0.740000  [ 7050/18000]\n",
            "cost: 0.539262, accuracy: 0.660000  [ 7550/18000]\n",
            "cost: 0.533020, accuracy: 0.800000  [ 8050/18000]\n",
            "cost: 0.542755, accuracy: 0.740000  [ 8550/18000]\n",
            "cost: 0.436054, accuracy: 0.800000  [ 9050/18000]\n",
            "cost: 0.641288, accuracy: 0.640000  [ 9550/18000]\n",
            "cost: 0.557629, accuracy: 0.720000  [10050/18000]\n",
            "cost: 0.359959, accuracy: 0.880000  [10550/18000]\n",
            "cost: 0.502233, accuracy: 0.840000  [11050/18000]\n",
            "cost: 0.441792, accuracy: 0.860000  [11550/18000]\n",
            "cost: 0.421603, accuracy: 0.820000  [12050/18000]\n",
            "cost: 0.445568, accuracy: 0.820000  [12550/18000]\n",
            "cost: 0.344221, accuracy: 0.840000  [13050/18000]\n",
            "cost: 0.458889, accuracy: 0.800000  [13550/18000]\n",
            "cost: 0.414082, accuracy: 0.840000  [14050/18000]\n",
            "cost: 0.419781, accuracy: 0.820000  [14550/18000]\n",
            "cost: 0.396334, accuracy: 0.840000  [15050/18000]\n",
            "cost: 0.314232, accuracy: 0.920000  [15550/18000]\n",
            "cost: 0.438651, accuracy: 0.780000  [16050/18000]\n",
            "cost: 0.273987, accuracy: 0.900000  [16550/18000]\n",
            "cost: 0.577455, accuracy: 0.740000  [17050/18000]\n",
            "cost: 0.434119, accuracy: 0.800000  [17550/18000]\n",
            "cost: 0.522654, accuracy: 0.760000  [   50/18000]\n",
            "cost: 0.582209, accuracy: 0.760000  [  550/18000]\n",
            "cost: 0.447580, accuracy: 0.800000  [ 1050/18000]\n",
            "cost: 0.345999, accuracy: 0.880000  [ 1550/18000]\n",
            "cost: 0.621719, accuracy: 0.840000  [ 2050/18000]\n",
            "cost: 0.323559, accuracy: 0.840000  [ 2550/18000]\n",
            "cost: 0.362939, accuracy: 0.840000  [ 3050/18000]\n",
            "cost: 0.308018, accuracy: 0.900000  [ 3550/18000]\n",
            "cost: 0.427858, accuracy: 0.780000  [ 4050/18000]\n",
            "cost: 0.498468, accuracy: 0.780000  [ 4550/18000]\n",
            "cost: 0.314240, accuracy: 0.880000  [ 5050/18000]\n",
            "cost: 0.674755, accuracy: 0.680000  [ 5550/18000]\n",
            "cost: 0.448033, accuracy: 0.780000  [ 6050/18000]\n",
            "cost: 0.328852, accuracy: 0.860000  [ 6550/18000]\n",
            "cost: 0.441099, accuracy: 0.800000  [ 7050/18000]\n",
            "cost: 0.380502, accuracy: 0.820000  [ 7550/18000]\n",
            "cost: 0.402120, accuracy: 0.780000  [ 8050/18000]\n",
            "cost: 0.363823, accuracy: 0.820000  [ 8550/18000]\n",
            "cost: 0.360055, accuracy: 0.840000  [ 9050/18000]\n",
            "cost: 0.495582, accuracy: 0.740000  [ 9550/18000]\n",
            "cost: 0.397755, accuracy: 0.840000  [10050/18000]\n",
            "cost: 0.430536, accuracy: 0.760000  [10550/18000]\n",
            "cost: 0.448530, accuracy: 0.800000  [11050/18000]\n",
            "cost: 0.378609, accuracy: 0.860000  [11550/18000]\n",
            "cost: 0.460361, accuracy: 0.720000  [12050/18000]\n",
            "cost: 0.482393, accuracy: 0.800000  [12550/18000]\n",
            "cost: 0.515664, accuracy: 0.780000  [13050/18000]\n",
            "cost: 0.314107, accuracy: 0.840000  [13550/18000]\n",
            "cost: 0.646928, accuracy: 0.760000  [14050/18000]\n",
            "cost: 0.350117, accuracy: 0.860000  [14550/18000]\n",
            "cost: 0.256204, accuracy: 0.900000  [15050/18000]\n",
            "cost: 0.446884, accuracy: 0.840000  [15550/18000]\n",
            "cost: 0.601192, accuracy: 0.700000  [16050/18000]\n",
            "cost: 0.347668, accuracy: 0.840000  [16550/18000]\n",
            "cost: 0.258572, accuracy: 0.940000  [17050/18000]\n",
            "cost: 0.364130, accuracy: 0.820000  [17550/18000]\n",
            "cost: 0.294148, accuracy: 0.880000  [   50/18000]\n",
            "cost: 0.311088, accuracy: 0.880000  [  550/18000]\n",
            "cost: 0.436325, accuracy: 0.800000  [ 1050/18000]\n",
            "cost: 0.258168, accuracy: 0.920000  [ 1550/18000]\n",
            "cost: 0.455667, accuracy: 0.820000  [ 2050/18000]\n",
            "cost: 0.516335, accuracy: 0.780000  [ 2550/18000]\n",
            "cost: 0.298397, accuracy: 0.880000  [ 3050/18000]\n",
            "cost: 0.277081, accuracy: 0.900000  [ 3550/18000]\n",
            "cost: 0.333524, accuracy: 0.800000  [ 4050/18000]\n",
            "cost: 0.366030, accuracy: 0.800000  [ 4550/18000]\n",
            "cost: 0.371528, accuracy: 0.820000  [ 5050/18000]\n",
            "cost: 0.432840, accuracy: 0.760000  [ 5550/18000]\n",
            "cost: 0.397726, accuracy: 0.860000  [ 6050/18000]\n",
            "cost: 0.388925, accuracy: 0.760000  [ 6550/18000]\n",
            "cost: 0.404160, accuracy: 0.820000  [ 7050/18000]\n",
            "cost: 0.317221, accuracy: 0.860000  [ 7550/18000]\n",
            "cost: 0.491702, accuracy: 0.740000  [ 8050/18000]\n",
            "cost: 0.399549, accuracy: 0.740000  [ 8550/18000]\n",
            "cost: 0.231890, accuracy: 0.880000  [ 9050/18000]\n",
            "cost: 0.250402, accuracy: 0.940000  [ 9550/18000]\n",
            "cost: 0.450437, accuracy: 0.800000  [10050/18000]\n",
            "cost: 0.373627, accuracy: 0.860000  [10550/18000]\n",
            "cost: 0.386662, accuracy: 0.820000  [11050/18000]\n",
            "cost: 0.380506, accuracy: 0.800000  [11550/18000]\n",
            "cost: 0.362695, accuracy: 0.780000  [12050/18000]\n",
            "cost: 0.286579, accuracy: 0.880000  [12550/18000]\n",
            "cost: 0.322623, accuracy: 0.860000  [13050/18000]\n",
            "cost: 0.410351, accuracy: 0.840000  [13550/18000]\n",
            "cost: 0.455773, accuracy: 0.780000  [14050/18000]\n",
            "cost: 0.404197, accuracy: 0.840000  [14550/18000]\n",
            "cost: 0.496173, accuracy: 0.780000  [15050/18000]\n",
            "cost: 0.530302, accuracy: 0.700000  [15550/18000]\n",
            "cost: 0.467511, accuracy: 0.760000  [16050/18000]\n",
            "cost: 0.438399, accuracy: 0.800000  [16550/18000]\n",
            "cost: 0.299236, accuracy: 0.900000  [17050/18000]\n",
            "cost: 0.263451, accuracy: 0.900000  [17550/18000]\n",
            "cost: 0.358453, accuracy: 0.860000  [   50/18000]\n",
            "cost: 0.460434, accuracy: 0.800000  [  550/18000]\n",
            "cost: 0.397133, accuracy: 0.840000  [ 1050/18000]\n",
            "cost: 0.429099, accuracy: 0.820000  [ 1550/18000]\n",
            "cost: 0.439174, accuracy: 0.820000  [ 2050/18000]\n",
            "cost: 0.224431, accuracy: 0.920000  [ 2550/18000]\n",
            "cost: 0.355701, accuracy: 0.900000  [ 3050/18000]\n",
            "cost: 0.412340, accuracy: 0.800000  [ 3550/18000]\n",
            "cost: 0.232923, accuracy: 0.880000  [ 4050/18000]\n",
            "cost: 0.220980, accuracy: 0.920000  [ 4550/18000]\n",
            "cost: 0.485876, accuracy: 0.800000  [ 5050/18000]\n",
            "cost: 0.380560, accuracy: 0.800000  [ 5550/18000]\n",
            "cost: 0.527109, accuracy: 0.740000  [ 6050/18000]\n",
            "cost: 0.325019, accuracy: 0.900000  [ 6550/18000]\n",
            "cost: 0.409274, accuracy: 0.800000  [ 7050/18000]\n",
            "cost: 0.309273, accuracy: 0.860000  [ 7550/18000]\n",
            "cost: 0.311126, accuracy: 0.860000  [ 8050/18000]\n",
            "cost: 0.467601, accuracy: 0.760000  [ 8550/18000]\n",
            "cost: 0.309262, accuracy: 0.900000  [ 9050/18000]\n",
            "cost: 0.227474, accuracy: 0.920000  [ 9550/18000]\n",
            "cost: 0.382081, accuracy: 0.840000  [10050/18000]\n",
            "cost: 0.244506, accuracy: 0.860000  [10550/18000]\n",
            "cost: 0.490912, accuracy: 0.780000  [11050/18000]\n",
            "cost: 0.288427, accuracy: 0.900000  [11550/18000]\n",
            "cost: 0.334101, accuracy: 0.880000  [12050/18000]\n",
            "cost: 0.366208, accuracy: 0.820000  [12550/18000]\n",
            "cost: 0.331868, accuracy: 0.860000  [13050/18000]\n",
            "cost: 0.354831, accuracy: 0.860000  [13550/18000]\n",
            "cost: 0.497739, accuracy: 0.780000  [14050/18000]\n",
            "cost: 0.349736, accuracy: 0.860000  [14550/18000]\n",
            "cost: 0.355200, accuracy: 0.820000  [15050/18000]\n",
            "cost: 0.449364, accuracy: 0.860000  [15550/18000]\n",
            "cost: 0.383094, accuracy: 0.840000  [16050/18000]\n",
            "cost: 0.348969, accuracy: 0.860000  [16550/18000]\n",
            "cost: 0.574408, accuracy: 0.700000  [17050/18000]\n",
            "cost: 0.587414, accuracy: 0.700000  [17550/18000]\n",
            "cost: 0.221803, accuracy: 0.900000  [   50/18000]\n",
            "cost: 0.324477, accuracy: 0.900000  [  550/18000]\n",
            "cost: 0.267622, accuracy: 0.900000  [ 1050/18000]\n",
            "cost: 0.404533, accuracy: 0.840000  [ 1550/18000]\n",
            "cost: 0.467705, accuracy: 0.740000  [ 2050/18000]\n",
            "cost: 0.275193, accuracy: 0.860000  [ 2550/18000]\n",
            "cost: 0.272653, accuracy: 0.920000  [ 3050/18000]\n",
            "cost: 0.308831, accuracy: 0.860000  [ 3550/18000]\n",
            "cost: 0.346859, accuracy: 0.820000  [ 4050/18000]\n",
            "cost: 0.397573, accuracy: 0.760000  [ 4550/18000]\n",
            "cost: 0.228363, accuracy: 0.940000  [ 5050/18000]\n",
            "cost: 0.450231, accuracy: 0.820000  [ 5550/18000]\n",
            "cost: 0.239359, accuracy: 0.900000  [ 6050/18000]\n",
            "cost: 0.279477, accuracy: 0.880000  [ 6550/18000]\n",
            "cost: 0.401174, accuracy: 0.800000  [ 7050/18000]\n",
            "cost: 0.358274, accuracy: 0.840000  [ 7550/18000]\n",
            "cost: 0.348247, accuracy: 0.840000  [ 8050/18000]\n",
            "cost: 0.314930, accuracy: 0.840000  [ 8550/18000]\n",
            "cost: 0.281528, accuracy: 0.860000  [ 9050/18000]\n",
            "cost: 0.382413, accuracy: 0.760000  [ 9550/18000]\n",
            "cost: 0.485532, accuracy: 0.820000  [10050/18000]\n",
            "cost: 0.296472, accuracy: 0.840000  [10550/18000]\n",
            "cost: 0.399521, accuracy: 0.820000  [11050/18000]\n",
            "cost: 0.331912, accuracy: 0.880000  [11550/18000]\n",
            "cost: 0.226541, accuracy: 0.920000  [12050/18000]\n",
            "cost: 0.448839, accuracy: 0.800000  [12550/18000]\n",
            "cost: 0.369804, accuracy: 0.860000  [13050/18000]\n",
            "cost: 0.253184, accuracy: 0.940000  [13550/18000]\n",
            "cost: 0.361568, accuracy: 0.780000  [14050/18000]\n",
            "cost: 0.279468, accuracy: 0.840000  [14550/18000]\n",
            "cost: 0.310884, accuracy: 0.920000  [15050/18000]\n",
            "cost: 0.395303, accuracy: 0.860000  [15550/18000]\n",
            "cost: 0.220115, accuracy: 0.960000  [16050/18000]\n",
            "cost: 0.255745, accuracy: 0.900000  [16550/18000]\n",
            "cost: 0.424119, accuracy: 0.760000  [17050/18000]\n",
            "cost: 0.254264, accuracy: 0.860000  [17550/18000]\n",
            "cost: 0.375439, accuracy: 0.860000  [   50/18000]\n",
            "cost: 0.272280, accuracy: 0.900000  [  550/18000]\n",
            "cost: 0.315789, accuracy: 0.840000  [ 1050/18000]\n",
            "cost: 0.331740, accuracy: 0.880000  [ 1550/18000]\n",
            "cost: 0.149790, accuracy: 0.980000  [ 2050/18000]\n",
            "cost: 0.310207, accuracy: 0.940000  [ 2550/18000]\n",
            "cost: 0.254162, accuracy: 0.840000  [ 3050/18000]\n",
            "cost: 0.360133, accuracy: 0.860000  [ 3550/18000]\n",
            "cost: 0.331590, accuracy: 0.840000  [ 4050/18000]\n",
            "cost: 0.434980, accuracy: 0.820000  [ 4550/18000]\n",
            "cost: 0.413126, accuracy: 0.860000  [ 5050/18000]\n",
            "cost: 0.346594, accuracy: 0.820000  [ 5550/18000]\n",
            "cost: 0.229648, accuracy: 0.880000  [ 6050/18000]\n",
            "cost: 0.628873, accuracy: 0.840000  [ 6550/18000]\n",
            "cost: 0.381121, accuracy: 0.820000  [ 7050/18000]\n",
            "cost: 0.394747, accuracy: 0.820000  [ 7550/18000]\n",
            "cost: 0.289868, accuracy: 0.860000  [ 8050/18000]\n",
            "cost: 0.341094, accuracy: 0.820000  [ 8550/18000]\n",
            "cost: 0.214320, accuracy: 0.920000  [ 9050/18000]\n",
            "cost: 0.200402, accuracy: 0.920000  [ 9550/18000]\n",
            "cost: 0.277070, accuracy: 0.900000  [10050/18000]\n",
            "cost: 0.330548, accuracy: 0.900000  [10550/18000]\n",
            "cost: 0.271974, accuracy: 0.880000  [11050/18000]\n",
            "cost: 0.195422, accuracy: 0.920000  [11550/18000]\n",
            "cost: 0.360780, accuracy: 0.840000  [12050/18000]\n",
            "cost: 0.264426, accuracy: 0.900000  [12550/18000]\n",
            "cost: 0.192085, accuracy: 0.900000  [13050/18000]\n",
            "cost: 0.290004, accuracy: 0.840000  [13550/18000]\n",
            "cost: 0.241099, accuracy: 0.920000  [14050/18000]\n",
            "cost: 0.407413, accuracy: 0.820000  [14550/18000]\n",
            "cost: 0.242152, accuracy: 0.900000  [15050/18000]\n",
            "cost: 0.256604, accuracy: 0.940000  [15550/18000]\n",
            "cost: 0.352930, accuracy: 0.820000  [16050/18000]\n",
            "cost: 0.358254, accuracy: 0.860000  [16550/18000]\n",
            "cost: 0.248080, accuracy: 0.920000  [17050/18000]\n",
            "cost: 0.490435, accuracy: 0.780000  [17550/18000]\n",
            "cost: 0.325244, accuracy: 0.880000  [   50/18000]\n",
            "cost: 0.210058, accuracy: 0.920000  [  550/18000]\n",
            "cost: 0.430020, accuracy: 0.800000  [ 1050/18000]\n",
            "cost: 0.323874, accuracy: 0.840000  [ 1550/18000]\n",
            "cost: 0.347625, accuracy: 0.840000  [ 2050/18000]\n",
            "cost: 0.300781, accuracy: 0.860000  [ 2550/18000]\n",
            "cost: 0.358556, accuracy: 0.820000  [ 3050/18000]\n",
            "cost: 0.240624, accuracy: 0.920000  [ 3550/18000]\n",
            "cost: 0.313187, accuracy: 0.840000  [ 4050/18000]\n",
            "cost: 0.284586, accuracy: 0.880000  [ 4550/18000]\n",
            "cost: 0.196291, accuracy: 0.960000  [ 5050/18000]\n",
            "cost: 0.401831, accuracy: 0.800000  [ 5550/18000]\n",
            "cost: 0.426275, accuracy: 0.820000  [ 6050/18000]\n",
            "cost: 0.361308, accuracy: 0.840000  [ 6550/18000]\n",
            "cost: 0.394134, accuracy: 0.840000  [ 7050/18000]\n",
            "cost: 0.481203, accuracy: 0.760000  [ 7550/18000]\n",
            "cost: 0.535901, accuracy: 0.760000  [ 8050/18000]\n",
            "cost: 0.202361, accuracy: 0.960000  [ 8550/18000]\n",
            "cost: 0.256251, accuracy: 0.880000  [ 9050/18000]\n",
            "cost: 0.339864, accuracy: 0.880000  [ 9550/18000]\n",
            "cost: 0.374185, accuracy: 0.820000  [10050/18000]\n",
            "cost: 0.263073, accuracy: 0.880000  [10550/18000]\n",
            "cost: 0.255419, accuracy: 0.920000  [11050/18000]\n",
            "cost: 0.309160, accuracy: 0.860000  [11550/18000]\n",
            "cost: 0.521613, accuracy: 0.760000  [12050/18000]\n",
            "cost: 0.343605, accuracy: 0.880000  [12550/18000]\n",
            "cost: 0.300459, accuracy: 0.900000  [13050/18000]\n",
            "cost: 0.211318, accuracy: 0.900000  [13550/18000]\n",
            "cost: 0.344262, accuracy: 0.800000  [14050/18000]\n",
            "cost: 0.320675, accuracy: 0.840000  [14550/18000]\n",
            "cost: 0.478307, accuracy: 0.840000  [15050/18000]\n",
            "cost: 0.253609, accuracy: 0.920000  [15550/18000]\n",
            "cost: 0.345845, accuracy: 0.880000  [16050/18000]\n",
            "cost: 0.337862, accuracy: 0.840000  [16550/18000]\n",
            "cost: 0.252031, accuracy: 0.920000  [17050/18000]\n",
            "cost: 0.348383, accuracy: 0.820000  [17550/18000]\n",
            "cost: 0.195171, accuracy: 0.960000  [   50/18000]\n",
            "cost: 0.271978, accuracy: 0.900000  [  550/18000]\n",
            "cost: 0.266116, accuracy: 0.880000  [ 1050/18000]\n",
            "cost: 0.297509, accuracy: 0.900000  [ 1550/18000]\n",
            "cost: 0.373466, accuracy: 0.880000  [ 2050/18000]\n",
            "cost: 0.398207, accuracy: 0.820000  [ 2550/18000]\n",
            "cost: 0.388080, accuracy: 0.820000  [ 3050/18000]\n",
            "cost: 0.316622, accuracy: 0.880000  [ 3550/18000]\n",
            "cost: 0.323086, accuracy: 0.860000  [ 4050/18000]\n",
            "cost: 0.395015, accuracy: 0.860000  [ 4550/18000]\n",
            "cost: 0.373417, accuracy: 0.800000  [ 5050/18000]\n",
            "cost: 0.202874, accuracy: 0.920000  [ 5550/18000]\n",
            "cost: 0.314422, accuracy: 0.880000  [ 6050/18000]\n",
            "cost: 0.205265, accuracy: 0.880000  [ 6550/18000]\n",
            "cost: 0.339683, accuracy: 0.900000  [ 7050/18000]\n",
            "cost: 0.298040, accuracy: 0.860000  [ 7550/18000]\n",
            "cost: 0.368174, accuracy: 0.880000  [ 8050/18000]\n",
            "cost: 0.368723, accuracy: 0.840000  [ 8550/18000]\n",
            "cost: 0.264433, accuracy: 0.840000  [ 9050/18000]\n",
            "cost: 0.295833, accuracy: 0.860000  [ 9550/18000]\n",
            "cost: 0.415721, accuracy: 0.780000  [10050/18000]\n",
            "cost: 0.229974, accuracy: 0.920000  [10550/18000]\n",
            "cost: 0.398608, accuracy: 0.800000  [11050/18000]\n",
            "cost: 0.191283, accuracy: 0.920000  [11550/18000]\n",
            "cost: 0.239180, accuracy: 0.900000  [12050/18000]\n",
            "cost: 0.221250, accuracy: 0.900000  [12550/18000]\n",
            "cost: 0.189239, accuracy: 0.940000  [13050/18000]\n",
            "cost: 0.282623, accuracy: 0.880000  [13550/18000]\n",
            "cost: 0.403307, accuracy: 0.780000  [14050/18000]\n",
            "cost: 0.241778, accuracy: 0.880000  [14550/18000]\n",
            "cost: 0.257932, accuracy: 0.920000  [15050/18000]\n",
            "cost: 0.367333, accuracy: 0.880000  [15550/18000]\n",
            "cost: 0.162515, accuracy: 0.920000  [16050/18000]\n",
            "cost: 0.309005, accuracy: 0.840000  [16550/18000]\n",
            "cost: 0.432305, accuracy: 0.860000  [17050/18000]\n",
            "cost: 0.278119, accuracy: 0.820000  [17550/18000]\n",
            "cost: 0.526015, accuracy: 0.800000  [   50/18000]\n",
            "cost: 0.241889, accuracy: 0.860000  [  550/18000]\n",
            "cost: 0.275206, accuracy: 0.860000  [ 1050/18000]\n",
            "cost: 0.195460, accuracy: 0.900000  [ 1550/18000]\n",
            "cost: 0.298011, accuracy: 0.920000  [ 2050/18000]\n",
            "cost: 0.329315, accuracy: 0.820000  [ 2550/18000]\n",
            "cost: 0.252357, accuracy: 0.900000  [ 3050/18000]\n",
            "cost: 0.256046, accuracy: 0.920000  [ 3550/18000]\n",
            "cost: 0.171007, accuracy: 0.960000  [ 4050/18000]\n",
            "cost: 0.274678, accuracy: 0.880000  [ 4550/18000]\n",
            "cost: 0.348547, accuracy: 0.860000  [ 5050/18000]\n",
            "cost: 0.303654, accuracy: 0.940000  [ 5550/18000]\n",
            "cost: 0.197888, accuracy: 0.920000  [ 6050/18000]\n",
            "cost: 0.250169, accuracy: 0.880000  [ 6550/18000]\n",
            "cost: 0.418585, accuracy: 0.800000  [ 7050/18000]\n",
            "cost: 0.332763, accuracy: 0.860000  [ 7550/18000]\n",
            "cost: 0.352628, accuracy: 0.840000  [ 8050/18000]\n",
            "cost: 0.286736, accuracy: 0.900000  [ 8550/18000]\n",
            "cost: 0.255720, accuracy: 0.920000  [ 9050/18000]\n",
            "cost: 0.186680, accuracy: 0.900000  [ 9550/18000]\n",
            "cost: 0.222022, accuracy: 0.960000  [10050/18000]\n",
            "cost: 0.375058, accuracy: 0.900000  [10550/18000]\n",
            "cost: 0.342721, accuracy: 0.860000  [11050/18000]\n",
            "cost: 0.262641, accuracy: 0.880000  [11550/18000]\n",
            "cost: 0.287992, accuracy: 0.900000  [12050/18000]\n",
            "cost: 0.443650, accuracy: 0.860000  [12550/18000]\n",
            "cost: 0.197186, accuracy: 0.900000  [13050/18000]\n",
            "cost: 0.183804, accuracy: 0.920000  [13550/18000]\n",
            "cost: 0.336275, accuracy: 0.820000  [14050/18000]\n",
            "cost: 0.292914, accuracy: 0.920000  [14550/18000]\n",
            "cost: 0.296466, accuracy: 0.880000  [15050/18000]\n",
            "cost: 0.413856, accuracy: 0.840000  [15550/18000]\n",
            "cost: 0.243162, accuracy: 0.880000  [16050/18000]\n",
            "cost: 0.545861, accuracy: 0.820000  [16550/18000]\n",
            "cost: 0.254097, accuracy: 0.880000  [17050/18000]\n",
            "cost: 0.315414, accuracy: 0.860000  [17550/18000]\n",
            "cost: 0.273926, accuracy: 0.920000  [   50/18000]\n",
            "cost: 0.255706, accuracy: 0.900000  [  550/18000]\n",
            "cost: 0.254397, accuracy: 0.840000  [ 1050/18000]\n",
            "cost: 0.185972, accuracy: 0.920000  [ 1550/18000]\n",
            "cost: 0.225506, accuracy: 0.920000  [ 2050/18000]\n",
            "cost: 0.195812, accuracy: 0.940000  [ 2550/18000]\n",
            "cost: 0.396053, accuracy: 0.840000  [ 3050/18000]\n",
            "cost: 0.197369, accuracy: 0.880000  [ 3550/18000]\n",
            "cost: 0.395633, accuracy: 0.820000  [ 4050/18000]\n",
            "cost: 0.203943, accuracy: 0.900000  [ 4550/18000]\n",
            "cost: 0.160384, accuracy: 0.940000  [ 5050/18000]\n",
            "cost: 0.108359, accuracy: 0.960000  [ 5550/18000]\n",
            "cost: 0.331736, accuracy: 0.840000  [ 6050/18000]\n",
            "cost: 0.307020, accuracy: 0.900000  [ 6550/18000]\n",
            "cost: 0.240857, accuracy: 0.880000  [ 7050/18000]\n",
            "cost: 0.230229, accuracy: 0.880000  [ 7550/18000]\n",
            "cost: 0.211676, accuracy: 0.960000  [ 8050/18000]\n",
            "cost: 0.465390, accuracy: 0.860000  [ 8550/18000]\n",
            "cost: 0.460482, accuracy: 0.840000  [ 9050/18000]\n",
            "cost: 0.152592, accuracy: 0.960000  [ 9550/18000]\n",
            "cost: 0.327039, accuracy: 0.820000  [10050/18000]\n",
            "cost: 0.237726, accuracy: 0.900000  [10550/18000]\n",
            "cost: 0.370155, accuracy: 0.840000  [11050/18000]\n",
            "cost: 0.334889, accuracy: 0.860000  [11550/18000]\n",
            "cost: 0.172226, accuracy: 0.940000  [12050/18000]\n",
            "cost: 0.245621, accuracy: 0.900000  [12550/18000]\n",
            "cost: 0.252078, accuracy: 0.940000  [13050/18000]\n",
            "cost: 0.358068, accuracy: 0.880000  [13550/18000]\n",
            "cost: 0.231854, accuracy: 0.880000  [14050/18000]\n",
            "cost: 0.171742, accuracy: 0.960000  [14550/18000]\n",
            "cost: 0.295057, accuracy: 0.920000  [15050/18000]\n",
            "cost: 0.267389, accuracy: 0.880000  [15550/18000]\n",
            "cost: 0.307750, accuracy: 0.900000  [16050/18000]\n",
            "cost: 0.246377, accuracy: 0.920000  [16550/18000]\n",
            "cost: 0.371969, accuracy: 0.780000  [17050/18000]\n",
            "cost: 0.200773, accuracy: 0.920000  [17550/18000]\n",
            "cost: 0.227738, accuracy: 0.880000  [   50/18000]\n",
            "cost: 0.178626, accuracy: 0.880000  [  550/18000]\n",
            "cost: 0.244948, accuracy: 0.840000  [ 1050/18000]\n",
            "cost: 0.283771, accuracy: 0.880000  [ 1550/18000]\n",
            "cost: 0.229815, accuracy: 0.880000  [ 2050/18000]\n",
            "cost: 0.155882, accuracy: 0.940000  [ 2550/18000]\n",
            "cost: 0.213521, accuracy: 0.900000  [ 3050/18000]\n",
            "cost: 0.179347, accuracy: 0.960000  [ 3550/18000]\n",
            "cost: 0.209255, accuracy: 0.860000  [ 4050/18000]\n",
            "cost: 0.358091, accuracy: 0.840000  [ 4550/18000]\n",
            "cost: 0.188175, accuracy: 0.920000  [ 5050/18000]\n",
            "cost: 0.184910, accuracy: 0.940000  [ 5550/18000]\n",
            "cost: 0.263628, accuracy: 0.860000  [ 6050/18000]\n",
            "cost: 0.284585, accuracy: 0.900000  [ 6550/18000]\n",
            "cost: 0.247214, accuracy: 0.900000  [ 7050/18000]\n",
            "cost: 0.368417, accuracy: 0.840000  [ 7550/18000]\n",
            "cost: 0.183116, accuracy: 0.920000  [ 8050/18000]\n",
            "cost: 0.253182, accuracy: 0.880000  [ 8550/18000]\n",
            "cost: 0.181610, accuracy: 0.860000  [ 9050/18000]\n",
            "cost: 0.317666, accuracy: 0.840000  [ 9550/18000]\n",
            "cost: 0.189007, accuracy: 0.900000  [10050/18000]\n",
            "cost: 0.226631, accuracy: 0.960000  [10550/18000]\n",
            "cost: 0.179139, accuracy: 0.900000  [11050/18000]\n",
            "cost: 0.348909, accuracy: 0.860000  [11550/18000]\n",
            "cost: 0.210155, accuracy: 0.960000  [12050/18000]\n",
            "cost: 0.256577, accuracy: 0.900000  [12550/18000]\n",
            "cost: 0.272496, accuracy: 0.820000  [13050/18000]\n",
            "cost: 0.270852, accuracy: 0.880000  [13550/18000]\n",
            "cost: 0.247192, accuracy: 0.900000  [14050/18000]\n",
            "cost: 0.252186, accuracy: 0.940000  [14550/18000]\n",
            "cost: 0.185693, accuracy: 0.940000  [15050/18000]\n",
            "cost: 0.122162, accuracy: 0.960000  [15550/18000]\n",
            "cost: 0.186808, accuracy: 0.940000  [16050/18000]\n",
            "cost: 0.324198, accuracy: 0.920000  [16550/18000]\n",
            "cost: 0.349235, accuracy: 0.880000  [17050/18000]\n",
            "cost: 0.267872, accuracy: 0.880000  [17550/18000]\n",
            "cost: 0.235026, accuracy: 0.860000  [   50/18000]\n",
            "cost: 0.346388, accuracy: 0.860000  [  550/18000]\n",
            "cost: 0.444590, accuracy: 0.820000  [ 1050/18000]\n",
            "cost: 0.194449, accuracy: 0.940000  [ 1550/18000]\n",
            "cost: 0.274883, accuracy: 0.920000  [ 2050/18000]\n",
            "cost: 0.067038, accuracy: 0.980000  [ 2550/18000]\n",
            "cost: 0.119584, accuracy: 0.980000  [ 3050/18000]\n",
            "cost: 0.217701, accuracy: 0.920000  [ 3550/18000]\n",
            "cost: 0.437732, accuracy: 0.780000  [ 4050/18000]\n",
            "cost: 0.241691, accuracy: 0.860000  [ 4550/18000]\n",
            "cost: 0.171555, accuracy: 0.920000  [ 5050/18000]\n",
            "cost: 0.519927, accuracy: 0.760000  [ 5550/18000]\n",
            "cost: 0.287613, accuracy: 0.880000  [ 6050/18000]\n",
            "cost: 0.330002, accuracy: 0.880000  [ 6550/18000]\n",
            "cost: 0.311643, accuracy: 0.860000  [ 7050/18000]\n",
            "cost: 0.300829, accuracy: 0.880000  [ 7550/18000]\n",
            "cost: 0.144337, accuracy: 0.960000  [ 8050/18000]\n",
            "cost: 0.294371, accuracy: 0.900000  [ 8550/18000]\n",
            "cost: 0.121883, accuracy: 0.980000  [ 9050/18000]\n",
            "cost: 0.234610, accuracy: 0.880000  [ 9550/18000]\n",
            "cost: 0.198871, accuracy: 0.900000  [10050/18000]\n",
            "cost: 0.126882, accuracy: 0.980000  [10550/18000]\n",
            "cost: 0.125307, accuracy: 0.960000  [11050/18000]\n",
            "cost: 0.175452, accuracy: 0.940000  [11550/18000]\n",
            "cost: 0.131525, accuracy: 0.960000  [12050/18000]\n",
            "cost: 0.200651, accuracy: 0.920000  [12550/18000]\n",
            "cost: 0.161546, accuracy: 0.940000  [13050/18000]\n",
            "cost: 0.181218, accuracy: 0.900000  [13550/18000]\n",
            "cost: 0.166786, accuracy: 0.960000  [14050/18000]\n",
            "cost: 0.241919, accuracy: 0.920000  [14550/18000]\n",
            "cost: 0.103489, accuracy: 0.980000  [15050/18000]\n",
            "cost: 0.124843, accuracy: 0.980000  [15550/18000]\n",
            "cost: 0.260180, accuracy: 0.920000  [16050/18000]\n",
            "cost: 0.317442, accuracy: 0.880000  [16550/18000]\n",
            "cost: 0.170275, accuracy: 0.960000  [17050/18000]\n",
            "cost: 0.247915, accuracy: 0.940000  [17550/18000]\n",
            "cost: 0.245233, accuracy: 0.940000  [   50/18000]\n",
            "cost: 0.138004, accuracy: 0.960000  [  550/18000]\n",
            "cost: 0.281153, accuracy: 0.860000  [ 1050/18000]\n",
            "cost: 0.196227, accuracy: 0.920000  [ 1550/18000]\n",
            "cost: 0.377003, accuracy: 0.860000  [ 2050/18000]\n",
            "cost: 0.421404, accuracy: 0.800000  [ 2550/18000]\n",
            "cost: 0.264947, accuracy: 0.900000  [ 3050/18000]\n",
            "cost: 0.234694, accuracy: 0.920000  [ 3550/18000]\n",
            "cost: 0.131655, accuracy: 0.940000  [ 4050/18000]\n",
            "cost: 0.141400, accuracy: 0.980000  [ 4550/18000]\n",
            "cost: 0.183052, accuracy: 0.940000  [ 5050/18000]\n",
            "cost: 0.218660, accuracy: 0.860000  [ 5550/18000]\n",
            "cost: 0.137470, accuracy: 0.940000  [ 6050/18000]\n",
            "cost: 0.195129, accuracy: 0.920000  [ 6550/18000]\n",
            "cost: 0.134019, accuracy: 0.960000  [ 7050/18000]\n",
            "cost: 0.453571, accuracy: 0.860000  [ 7550/18000]\n",
            "cost: 0.235899, accuracy: 0.900000  [ 8050/18000]\n",
            "cost: 0.203311, accuracy: 0.880000  [ 8550/18000]\n",
            "cost: 0.156416, accuracy: 0.920000  [ 9050/18000]\n",
            "cost: 0.291603, accuracy: 0.880000  [ 9550/18000]\n",
            "cost: 0.218525, accuracy: 0.880000  [10050/18000]\n",
            "cost: 0.193945, accuracy: 0.900000  [10550/18000]\n",
            "cost: 0.163526, accuracy: 0.900000  [11050/18000]\n",
            "cost: 0.129034, accuracy: 0.980000  [11550/18000]\n",
            "cost: 0.089019, accuracy: 0.940000  [12050/18000]\n",
            "cost: 0.140832, accuracy: 0.960000  [12550/18000]\n",
            "cost: 0.144130, accuracy: 0.920000  [13050/18000]\n",
            "cost: 0.391790, accuracy: 0.780000  [13550/18000]\n",
            "cost: 0.295532, accuracy: 0.860000  [14050/18000]\n",
            "cost: 0.242118, accuracy: 0.880000  [14550/18000]\n",
            "cost: 0.275357, accuracy: 0.860000  [15050/18000]\n",
            "cost: 0.248393, accuracy: 0.920000  [15550/18000]\n",
            "cost: 0.301539, accuracy: 0.880000  [16050/18000]\n",
            "cost: 0.223746, accuracy: 0.900000  [16550/18000]\n",
            "cost: 0.164413, accuracy: 0.920000  [17050/18000]\n",
            "cost: 0.202022, accuracy: 0.900000  [17550/18000]\n",
            "cost: 0.085461, accuracy: 0.960000  [   50/18000]\n",
            "cost: 0.226289, accuracy: 0.940000  [  550/18000]\n",
            "cost: 0.366913, accuracy: 0.840000  [ 1050/18000]\n",
            "cost: 0.138514, accuracy: 0.940000  [ 1550/18000]\n",
            "cost: 0.381836, accuracy: 0.900000  [ 2050/18000]\n",
            "cost: 0.280941, accuracy: 0.940000  [ 2550/18000]\n",
            "cost: 0.221349, accuracy: 0.880000  [ 3050/18000]\n",
            "cost: 0.117586, accuracy: 0.960000  [ 3550/18000]\n",
            "cost: 0.161735, accuracy: 0.940000  [ 4050/18000]\n",
            "cost: 0.159564, accuracy: 0.940000  [ 4550/18000]\n",
            "cost: 0.453010, accuracy: 0.840000  [ 5050/18000]\n",
            "cost: 0.168143, accuracy: 0.900000  [ 5550/18000]\n",
            "cost: 0.165631, accuracy: 0.940000  [ 6050/18000]\n",
            "cost: 0.117053, accuracy: 0.980000  [ 6550/18000]\n",
            "cost: 0.408174, accuracy: 0.820000  [ 7050/18000]\n",
            "cost: 0.210098, accuracy: 0.920000  [ 7550/18000]\n",
            "cost: 0.285632, accuracy: 0.820000  [ 8050/18000]\n",
            "cost: 0.144189, accuracy: 0.940000  [ 8550/18000]\n",
            "cost: 0.101298, accuracy: 0.980000  [ 9050/18000]\n",
            "cost: 0.301726, accuracy: 0.860000  [ 9550/18000]\n",
            "cost: 0.101835, accuracy: 0.940000  [10050/18000]\n",
            "cost: 0.137467, accuracy: 0.960000  [10550/18000]\n",
            "cost: 0.394054, accuracy: 0.860000  [11050/18000]\n",
            "cost: 0.197018, accuracy: 0.900000  [11550/18000]\n",
            "cost: 0.183127, accuracy: 0.900000  [12050/18000]\n",
            "cost: 0.218623, accuracy: 0.920000  [12550/18000]\n",
            "cost: 0.264526, accuracy: 0.900000  [13050/18000]\n",
            "cost: 0.280529, accuracy: 0.880000  [13550/18000]\n",
            "cost: 0.112909, accuracy: 0.980000  [14050/18000]\n",
            "cost: 0.268595, accuracy: 0.920000  [14550/18000]\n",
            "cost: 0.244118, accuracy: 0.880000  [15050/18000]\n",
            "cost: 0.089346, accuracy: 0.980000  [15550/18000]\n",
            "cost: 0.173327, accuracy: 0.920000  [16050/18000]\n",
            "cost: 0.175577, accuracy: 0.940000  [16550/18000]\n",
            "cost: 0.181087, accuracy: 0.920000  [17050/18000]\n",
            "cost: 0.082934, accuracy: 1.000000  [17550/18000]\n",
            "cost: 0.127437, accuracy: 0.960000  [   50/18000]\n",
            "cost: 0.150269, accuracy: 0.940000  [  550/18000]\n",
            "cost: 0.174606, accuracy: 0.960000  [ 1050/18000]\n",
            "cost: 0.284959, accuracy: 0.860000  [ 1550/18000]\n",
            "cost: 0.170999, accuracy: 0.940000  [ 2050/18000]\n",
            "cost: 0.218537, accuracy: 0.920000  [ 2550/18000]\n",
            "cost: 0.109523, accuracy: 0.980000  [ 3050/18000]\n",
            "cost: 0.126200, accuracy: 0.960000  [ 3550/18000]\n",
            "cost: 0.138633, accuracy: 0.940000  [ 4050/18000]\n",
            "cost: 0.213955, accuracy: 0.900000  [ 4550/18000]\n",
            "cost: 0.215980, accuracy: 0.940000  [ 5050/18000]\n",
            "cost: 0.199414, accuracy: 0.880000  [ 5550/18000]\n",
            "cost: 0.259106, accuracy: 0.860000  [ 6050/18000]\n",
            "cost: 0.266816, accuracy: 0.880000  [ 6550/18000]\n",
            "cost: 0.172799, accuracy: 0.960000  [ 7050/18000]\n",
            "cost: 0.193775, accuracy: 0.880000  [ 7550/18000]\n",
            "cost: 0.094928, accuracy: 0.960000  [ 8050/18000]\n",
            "cost: 0.121444, accuracy: 0.960000  [ 8550/18000]\n",
            "cost: 0.066036, accuracy: 0.960000  [ 9050/18000]\n",
            "cost: 0.207489, accuracy: 0.920000  [ 9550/18000]\n",
            "cost: 0.052563, accuracy: 0.980000  [10050/18000]\n",
            "cost: 0.192023, accuracy: 0.920000  [10550/18000]\n",
            "cost: 0.188708, accuracy: 0.880000  [11050/18000]\n",
            "cost: 0.111643, accuracy: 0.940000  [11550/18000]\n",
            "cost: 0.199593, accuracy: 0.880000  [12050/18000]\n",
            "cost: 0.229743, accuracy: 0.940000  [12550/18000]\n",
            "cost: 0.219021, accuracy: 0.840000  [13050/18000]\n",
            "cost: 0.191570, accuracy: 0.920000  [13550/18000]\n",
            "cost: 0.182501, accuracy: 0.920000  [14050/18000]\n",
            "cost: 0.219468, accuracy: 0.920000  [14550/18000]\n",
            "cost: 0.170567, accuracy: 0.920000  [15050/18000]\n",
            "cost: 0.097791, accuracy: 0.940000  [15550/18000]\n",
            "cost: 0.134674, accuracy: 0.920000  [16050/18000]\n",
            "cost: 0.140360, accuracy: 0.920000  [16550/18000]\n",
            "cost: 0.267195, accuracy: 0.900000  [17050/18000]\n",
            "cost: 0.150045, accuracy: 0.980000  [17550/18000]\n",
            "cost: 0.116149, accuracy: 0.920000  [   50/18000]\n",
            "cost: 0.138242, accuracy: 0.940000  [  550/18000]\n",
            "cost: 0.162480, accuracy: 0.940000  [ 1050/18000]\n",
            "cost: 0.068124, accuracy: 0.960000  [ 1550/18000]\n",
            "cost: 0.119829, accuracy: 0.920000  [ 2050/18000]\n",
            "cost: 0.214729, accuracy: 0.880000  [ 2550/18000]\n",
            "cost: 0.232027, accuracy: 0.860000  [ 3050/18000]\n",
            "cost: 0.159191, accuracy: 0.960000  [ 3550/18000]\n",
            "cost: 0.103389, accuracy: 0.960000  [ 4050/18000]\n",
            "cost: 0.127091, accuracy: 0.920000  [ 4550/18000]\n",
            "cost: 0.172982, accuracy: 0.940000  [ 5050/18000]\n",
            "cost: 0.201534, accuracy: 0.880000  [ 5550/18000]\n",
            "cost: 0.190944, accuracy: 0.940000  [ 6050/18000]\n",
            "cost: 0.162865, accuracy: 0.900000  [ 6550/18000]\n",
            "cost: 0.115372, accuracy: 0.940000  [ 7050/18000]\n",
            "cost: 0.102566, accuracy: 0.980000  [ 7550/18000]\n",
            "cost: 0.081679, accuracy: 0.980000  [ 8050/18000]\n",
            "cost: 0.127578, accuracy: 0.960000  [ 8550/18000]\n",
            "cost: 0.317434, accuracy: 0.840000  [ 9050/18000]\n",
            "cost: 0.161570, accuracy: 0.960000  [ 9550/18000]\n",
            "cost: 0.092027, accuracy: 0.960000  [10050/18000]\n",
            "cost: 0.218155, accuracy: 0.920000  [10550/18000]\n",
            "cost: 0.153457, accuracy: 0.940000  [11050/18000]\n",
            "cost: 0.115699, accuracy: 0.920000  [11550/18000]\n",
            "cost: 0.146694, accuracy: 0.940000  [12050/18000]\n",
            "cost: 0.157133, accuracy: 0.980000  [12550/18000]\n",
            "cost: 0.183396, accuracy: 0.920000  [13050/18000]\n",
            "cost: 0.153747, accuracy: 0.920000  [13550/18000]\n",
            "cost: 0.160028, accuracy: 0.920000  [14050/18000]\n",
            "cost: 0.320281, accuracy: 0.880000  [14550/18000]\n",
            "cost: 0.059950, accuracy: 0.980000  [15050/18000]\n",
            "cost: 0.167570, accuracy: 0.880000  [15550/18000]\n",
            "cost: 0.193473, accuracy: 0.920000  [16050/18000]\n",
            "cost: 0.154093, accuracy: 0.920000  [16550/18000]\n",
            "cost: 0.149592, accuracy: 0.960000  [17050/18000]\n",
            "cost: 0.312785, accuracy: 0.840000  [17550/18000]\n",
            "cost: 0.092063, accuracy: 0.980000  [   50/18000]\n",
            "cost: 0.156465, accuracy: 0.940000  [  550/18000]\n",
            "cost: 0.296130, accuracy: 0.920000  [ 1050/18000]\n",
            "cost: 0.205347, accuracy: 0.940000  [ 1550/18000]\n",
            "cost: 0.069903, accuracy: 0.960000  [ 2050/18000]\n",
            "cost: 0.111474, accuracy: 0.960000  [ 2550/18000]\n",
            "cost: 0.116250, accuracy: 0.960000  [ 3050/18000]\n",
            "cost: 0.332111, accuracy: 0.880000  [ 3550/18000]\n",
            "cost: 0.129288, accuracy: 0.920000  [ 4050/18000]\n",
            "cost: 0.077318, accuracy: 1.000000  [ 4550/18000]\n",
            "cost: 0.129200, accuracy: 0.920000  [ 5050/18000]\n",
            "cost: 0.090751, accuracy: 0.940000  [ 5550/18000]\n",
            "cost: 0.180858, accuracy: 0.920000  [ 6050/18000]\n",
            "cost: 0.266584, accuracy: 0.880000  [ 6550/18000]\n",
            "cost: 0.181326, accuracy: 0.900000  [ 7050/18000]\n",
            "cost: 0.061356, accuracy: 0.980000  [ 7550/18000]\n",
            "cost: 0.506650, accuracy: 0.940000  [ 8050/18000]\n",
            "cost: 0.160464, accuracy: 0.960000  [ 8550/18000]\n",
            "cost: 0.104714, accuracy: 0.960000  [ 9050/18000]\n",
            "cost: 0.230032, accuracy: 0.880000  [ 9550/18000]\n",
            "cost: 0.127515, accuracy: 0.960000  [10050/18000]\n",
            "cost: 0.061597, accuracy: 0.980000  [10550/18000]\n",
            "cost: 0.129745, accuracy: 0.940000  [11050/18000]\n",
            "cost: 0.114733, accuracy: 0.940000  [11550/18000]\n",
            "cost: 0.031109, accuracy: 1.000000  [12050/18000]\n",
            "cost: 0.185875, accuracy: 0.920000  [12550/18000]\n",
            "cost: 0.178575, accuracy: 0.920000  [13050/18000]\n",
            "cost: 0.128414, accuracy: 0.920000  [13550/18000]\n",
            "cost: 0.180957, accuracy: 0.920000  [14050/18000]\n",
            "cost: 0.188307, accuracy: 0.920000  [14550/18000]\n",
            "cost: 0.124771, accuracy: 0.940000  [15050/18000]\n",
            "cost: 0.114004, accuracy: 0.960000  [15550/18000]\n",
            "cost: 0.286998, accuracy: 0.860000  [16050/18000]\n",
            "cost: 0.132988, accuracy: 0.940000  [16550/18000]\n",
            "cost: 0.152501, accuracy: 0.920000  [17050/18000]\n",
            "cost: 0.106488, accuracy: 0.980000  [17550/18000]\n",
            "cost: 0.077321, accuracy: 0.960000  [   50/18000]\n",
            "cost: 0.089660, accuracy: 0.960000  [  550/18000]\n",
            "cost: 0.095250, accuracy: 0.940000  [ 1050/18000]\n",
            "cost: 0.102198, accuracy: 0.960000  [ 1550/18000]\n",
            "cost: 0.154618, accuracy: 0.960000  [ 2050/18000]\n",
            "cost: 0.067063, accuracy: 0.960000  [ 2550/18000]\n",
            "cost: 0.100786, accuracy: 0.980000  [ 3050/18000]\n",
            "cost: 0.142232, accuracy: 0.920000  [ 3550/18000]\n",
            "cost: 0.089914, accuracy: 0.980000  [ 4050/18000]\n",
            "cost: 0.098668, accuracy: 0.960000  [ 4550/18000]\n",
            "cost: 0.195585, accuracy: 0.880000  [ 5050/18000]\n",
            "cost: 0.194961, accuracy: 0.920000  [ 5550/18000]\n",
            "cost: 0.266147, accuracy: 0.860000  [ 6050/18000]\n",
            "cost: 0.115716, accuracy: 0.980000  [ 6550/18000]\n",
            "cost: 0.215800, accuracy: 0.940000  [ 7050/18000]\n",
            "cost: 0.105114, accuracy: 0.940000  [ 7550/18000]\n",
            "cost: 0.109892, accuracy: 0.960000  [ 8050/18000]\n",
            "cost: 0.177710, accuracy: 0.920000  [ 8550/18000]\n",
            "cost: 0.045764, accuracy: 1.000000  [ 9050/18000]\n",
            "cost: 0.092943, accuracy: 0.980000  [ 9550/18000]\n",
            "cost: 0.061657, accuracy: 0.960000  [10050/18000]\n",
            "cost: 0.108885, accuracy: 0.920000  [10550/18000]\n",
            "cost: 0.138936, accuracy: 0.940000  [11050/18000]\n",
            "cost: 0.146467, accuracy: 0.940000  [11550/18000]\n",
            "cost: 0.125626, accuracy: 0.960000  [12050/18000]\n",
            "cost: 0.046792, accuracy: 0.980000  [12550/18000]\n",
            "cost: 0.162082, accuracy: 0.940000  [13050/18000]\n",
            "cost: 0.209170, accuracy: 0.900000  [13550/18000]\n",
            "cost: 0.082195, accuracy: 0.980000  [14050/18000]\n",
            "cost: 0.121905, accuracy: 0.940000  [14550/18000]\n",
            "cost: 0.110513, accuracy: 0.980000  [15050/18000]\n",
            "cost: 0.108903, accuracy: 0.960000  [15550/18000]\n",
            "cost: 0.108700, accuracy: 0.940000  [16050/18000]\n",
            "cost: 0.287510, accuracy: 0.900000  [16550/18000]\n",
            "cost: 0.324028, accuracy: 0.920000  [17050/18000]\n",
            "cost: 0.060465, accuracy: 1.000000  [17550/18000]\n",
            "cost: 0.104803, accuracy: 0.940000  [   50/18000]\n",
            "cost: 0.102418, accuracy: 0.980000  [  550/18000]\n",
            "cost: 0.055749, accuracy: 1.000000  [ 1050/18000]\n",
            "cost: 0.135182, accuracy: 0.940000  [ 1550/18000]\n",
            "cost: 0.055196, accuracy: 1.000000  [ 2050/18000]\n",
            "cost: 0.071544, accuracy: 1.000000  [ 2550/18000]\n",
            "cost: 0.061851, accuracy: 0.960000  [ 3050/18000]\n",
            "cost: 0.222463, accuracy: 0.880000  [ 3550/18000]\n",
            "cost: 0.057371, accuracy: 1.000000  [ 4050/18000]\n",
            "cost: 0.108624, accuracy: 0.940000  [ 4550/18000]\n",
            "cost: 0.199435, accuracy: 0.940000  [ 5050/18000]\n",
            "cost: 0.183836, accuracy: 0.940000  [ 5550/18000]\n",
            "cost: 0.112712, accuracy: 0.920000  [ 6050/18000]\n",
            "cost: 0.086169, accuracy: 0.940000  [ 6550/18000]\n",
            "cost: 0.034478, accuracy: 1.000000  [ 7050/18000]\n",
            "cost: 0.112772, accuracy: 0.940000  [ 7550/18000]\n",
            "cost: 0.116276, accuracy: 0.940000  [ 8050/18000]\n",
            "cost: 0.070886, accuracy: 0.960000  [ 8550/18000]\n",
            "cost: 0.177663, accuracy: 0.940000  [ 9050/18000]\n",
            "cost: 0.063882, accuracy: 0.960000  [ 9550/18000]\n",
            "cost: 0.116579, accuracy: 0.920000  [10050/18000]\n",
            "cost: 0.090316, accuracy: 0.940000  [10550/18000]\n",
            "cost: 0.179454, accuracy: 0.920000  [11050/18000]\n",
            "cost: 0.058998, accuracy: 0.980000  [11550/18000]\n",
            "cost: 0.126439, accuracy: 0.940000  [12050/18000]\n",
            "cost: 0.107207, accuracy: 0.960000  [12550/18000]\n",
            "cost: 0.183481, accuracy: 0.940000  [13050/18000]\n",
            "cost: 0.062436, accuracy: 0.980000  [13550/18000]\n",
            "cost: 0.250427, accuracy: 0.920000  [14050/18000]\n",
            "cost: 0.118046, accuracy: 0.960000  [14550/18000]\n",
            "cost: 0.224290, accuracy: 0.920000  [15050/18000]\n",
            "cost: 0.183414, accuracy: 0.940000  [15550/18000]\n",
            "cost: 0.077003, accuracy: 0.980000  [16050/18000]\n",
            "cost: 0.221328, accuracy: 0.900000  [16550/18000]\n",
            "cost: 0.280338, accuracy: 0.880000  [17050/18000]\n",
            "cost: 0.111608, accuracy: 0.960000  [17550/18000]\n",
            "cost: 0.196375, accuracy: 0.940000  [   50/18000]\n",
            "cost: 0.087535, accuracy: 0.980000  [  550/18000]\n",
            "cost: 0.103065, accuracy: 0.940000  [ 1050/18000]\n",
            "cost: 0.159044, accuracy: 0.920000  [ 1550/18000]\n",
            "cost: 0.044617, accuracy: 1.000000  [ 2050/18000]\n",
            "cost: 0.115183, accuracy: 0.980000  [ 2550/18000]\n",
            "cost: 0.298966, accuracy: 0.900000  [ 3050/18000]\n",
            "cost: 0.108391, accuracy: 0.960000  [ 3550/18000]\n",
            "cost: 0.138514, accuracy: 0.940000  [ 4050/18000]\n",
            "cost: 0.104524, accuracy: 0.960000  [ 4550/18000]\n",
            "cost: 0.099107, accuracy: 0.980000  [ 5050/18000]\n",
            "cost: 0.080653, accuracy: 0.980000  [ 5550/18000]\n",
            "cost: 0.055425, accuracy: 0.980000  [ 6050/18000]\n",
            "cost: 0.104250, accuracy: 0.960000  [ 6550/18000]\n",
            "cost: 0.226811, accuracy: 0.880000  [ 7050/18000]\n",
            "cost: 0.192287, accuracy: 0.900000  [ 7550/18000]\n",
            "cost: 0.187371, accuracy: 0.880000  [ 8050/18000]\n",
            "cost: 0.085661, accuracy: 0.980000  [ 8550/18000]\n",
            "cost: 0.070265, accuracy: 0.980000  [ 9050/18000]\n",
            "cost: 0.062954, accuracy: 0.980000  [ 9550/18000]\n",
            "cost: 0.139192, accuracy: 0.940000  [10050/18000]\n",
            "cost: 0.180663, accuracy: 0.940000  [10550/18000]\n",
            "cost: 0.142081, accuracy: 0.940000  [11050/18000]\n",
            "cost: 0.031027, accuracy: 1.000000  [11550/18000]\n",
            "cost: 0.182316, accuracy: 0.940000  [12050/18000]\n",
            "cost: 0.125426, accuracy: 0.940000  [12550/18000]\n",
            "cost: 0.132792, accuracy: 0.960000  [13050/18000]\n",
            "cost: 0.044850, accuracy: 1.000000  [13550/18000]\n",
            "cost: 0.053569, accuracy: 0.980000  [14050/18000]\n",
            "cost: 0.098133, accuracy: 0.960000  [14550/18000]\n",
            "cost: 0.070603, accuracy: 0.960000  [15050/18000]\n",
            "cost: 0.171963, accuracy: 0.900000  [15550/18000]\n",
            "cost: 0.151046, accuracy: 0.940000  [16050/18000]\n",
            "cost: 0.148309, accuracy: 0.920000  [16550/18000]\n",
            "cost: 0.031714, accuracy: 1.000000  [17050/18000]\n",
            "cost: 0.103884, accuracy: 0.960000  [17550/18000]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy: 85.20, best accuracy: 86.95\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import InputLayer\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn import model_selection\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "device=torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "\n",
        "data=pd.read_csv(\"xaa\",encoding=\"utf-8\")\n",
        "\n",
        "word2vec_model = KeyedVectors.load_word2vec_format(\"drive/MyDrive/Colab Notebooks/GoogleNews-vectors-negative300.bin.gz\", binary=True, limit=20000)\n",
        "#print(word2vec_model.get_index(\"the\"))\n",
        "vect  = CountVectorizer(stop_words=\"english\",max_df=0.7)\n",
        "#corpus = vect.fit_transform(data[\"text\"])\n",
        "#train_corpus, test_corpus, train_label, test_label = model_selection.train_test_split(data[\"text\"],data[\"label\"],test_size=0.4)\n",
        "#Encoder = LabelEncoder()\n",
        "#train_label = Encoder.fit_transform(train_label)\n",
        "#test_label = Encoder.fit_transform(test_label)\n",
        "#train_corpus_vect=vect.transform(train_corpus)\n",
        "#test_corpus_vect=vect.transform(test_corpus)\n",
        "\n",
        "# Initalise vect.vocabulary_\n",
        "vect.fit_transform(data[\"text\"])\n",
        "\n",
        "maxlen=0\n",
        "\n",
        "def transform(text,vect):\n",
        "    global maxlen\n",
        "    global word2vec_model\n",
        "    #d=vect.vocabulary_\n",
        "    d=word2vec_model\n",
        "    p=vect.build_preprocessor()\n",
        "    t=vect.build_tokenizer()\n",
        "    vec_list=[]\n",
        "    for doc in text:\n",
        "        tokens=t(p(doc))\n",
        "        doc_vec=np.array([d.get_index(token) for token in tokens if token in d])\n",
        "        s=len(doc_vec)\n",
        "        if s>maxlen:\n",
        "            maxlen=s\n",
        "        #doc_vec=sequence.pad_sequences(doc_vec,maxlen=maxlen)\n",
        "        vec_list.append(doc_vec)\n",
        "    vec_list=sequence.pad_sequences(vec_list,maxlen=maxlen,padding=\"post\")\n",
        "    corpus_vec=np.vstack(vec_list)\n",
        "    #return nn.functional.normalize(torch.tensor(corpus_vec).float())\n",
        "    return torch.tensor(corpus_vec)\n",
        "    #return torch.tensor(corpus_vec).float()\n",
        "\n",
        "# print(corpus_vec)\n",
        "\n",
        "bsize=50\n",
        "epochs=20\n",
        "lr=5e-4\n",
        "embed_dim=300\n",
        "\n",
        "class corpus(Dataset):\n",
        "    def __init__(self,corpus,label,seq):\n",
        "        self.corpus=corpus\n",
        "        self.label=label\n",
        "        self.seq=seq\n",
        "    def __len__(self):\n",
        "        return len(self.corpus)\n",
        "    def __getitem__(self,idx):\n",
        "        return self.corpus[idx],self.label[idx]\n",
        "\n",
        "class lstm(nn.Module):\n",
        "    def __init__(self,input_size,hidden_size,seq):\n",
        "        super(lstm,self).__init__()\n",
        "        self.input_size=input_size\n",
        "        self.hidden_size=hidden_size\n",
        "        self.seq=seq\n",
        "        self.rnn=True\n",
        "        self.lstm=nn.LSTM(input_size,hidden_size,batch_first=True,num_layers=3)\n",
        "        self.fc=nn.Linear(self.hidden_size*seq,1)\n",
        "        #self.fc=nn.Linear(self.hidden_size,1)\n",
        "        #self.embed=nn.Embedding(len(vect.vocabulary_),input_size)\n",
        "        self.embed=nn.Embedding.from_pretrained(torch.from_numpy(word2vec_model.vectors),freeze=True)\n",
        "\n",
        "    def forward(self,x,h0=None,c0=None):\n",
        "        x=self.embed(x)\n",
        "        if h0==None and c0==None:\n",
        "            x, (hn,cn) = self.lstm(x)\n",
        "        else:\n",
        "            x, (hn,cn) = self.lstm(x,(h0,c0))\n",
        "        #print(x[:,-1,:].shape)\n",
        "        #x = torch.flatten(x[:,-1,:],1)\n",
        "        # Flatten like this so that all information from previous time steps is fed into fully connected layer\n",
        "        x=torch.flatten(x,1)\n",
        "        x = self.fc(x)\n",
        "        return nn.Sigmoid()(x), hn,cn\n",
        "        #return nn.Softmax()(x), hn,cn\n",
        "\n",
        "class dense(nn.Module):\n",
        "    def __init__(self,seq,vocab,embed_dim):\n",
        "        super(dense,self).__init__()\n",
        "        self.seq=seq\n",
        "        self.rnn=False\n",
        "        self.network=nn.Sequential(\n",
        "            nn.Linear(embed_dim*seq,360),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(360,180),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(180,1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.embed=nn.Embedding(vocab,embed_dim)\n",
        "\n",
        "    def forward(self,x):\n",
        "        #print(x.shape)\n",
        "        x=self.embed(x)\n",
        "        x=torch.flatten(x,1)\n",
        "        #x=torch.transpose(x,1,2)\n",
        "        #x=torch.flatten(x,1)\n",
        "        return self.network(x)\n",
        "\n",
        "vocab=len(vect.vocabulary_)\n",
        "Encoder = LabelEncoder()\n",
        "corpus_vec = transform(data[\"text\"],vect)\n",
        "train_corpus_vec, test_corpus_vec, train_label, test_label = model_selection.train_test_split(corpus_vec,data[\"label\"],test_size=0.1)\n",
        "train_label = torch.from_numpy(Encoder.fit_transform(train_label)).float()\n",
        "test_label = torch.from_numpy(Encoder.fit_transform(test_label)).float()\n",
        "#train_corpus_vec = transform(train_corpus,vect)\n",
        "#test_corpus_vec = transform(test_corpus,vect)\n",
        "lstm_classifier=lstm(embed_dim,100,maxlen)\n",
        "loss_fn=nn.BCELoss()\n",
        "#loss_fn=nn.BCEWithLogitsLoss()\n",
        "#loss_fn=nn.MSELoss()\n",
        "optimizer=torch.optim.Adam(lstm_classifier.parameters(),lr=lr)\n",
        "#optimizer=torch.optim.SGD(lstm_classifier.parameters(),lr=lr)\n",
        "#print(len(lstm_classifier(torch.reshape(train_corpus_vec[0],(bsize,maxlen,1)))))\n",
        "\n",
        "dense_classifier=dense(maxlen,vocab,16)\n",
        "\n",
        "c=lstm_classifier\n",
        "\n",
        "c=c.to(device)\n",
        "\n",
        "train_dataloader=DataLoader(corpus(train_corpus_vec,train_label,maxlen),batch_size=bsize,shuffle=True)\n",
        "test_dataloader=DataLoader(corpus(test_corpus_vec,test_label,maxlen),batch_size=bsize,shuffle=True)\n",
        "\n",
        "def train(dataloader,model,loss_fn,optimizer):\n",
        "    hn,cn=None,None\n",
        "    size=len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch,(x,y) in enumerate(dataloader):\n",
        "        x,y=x.to(device),y.to(device)\n",
        "        #print(torch.sum(x[0]!=0))\n",
        "        if model.rnn==True:\n",
        "            #pred,hn,cn=model(x.reshape(bsize,dataloader.dataset.seq,1).to(device),hn,cn)\n",
        "            pred,hn,cn=model(x,hn,cn)\n",
        "        else:\n",
        "            pred=model(x)\n",
        "        #pred=model(x)\n",
        "        cost=loss_fn(pred.flatten(),y)\n",
        "        cost.backward()\n",
        "        #if model.rnn==True:\n",
        "        #    print(model.lstm.weight_ih_l0.grad[0][0])\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if model.rnn==True:\n",
        "            hn=hn.detach()\n",
        "            cn=cn.detach()\n",
        "        if batch % 10 == 0:\n",
        "            cost_val, current = cost.item(), batch * bsize + len(x)\n",
        "            print(f\"cost: {cost_val:>7f}, accuracy: {(torch.round(pred.flatten())==y).sum().item()/bsize:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x,y=x.to(device),y.to(device)\n",
        "            if model.rnn==True:\n",
        "                #pred,_,_=model(x.reshape(bsize,dataloader.dataset.seq,1).to(device))\n",
        "                pred,_,_=model(x)\n",
        "            else:\n",
        "                pred=model(x)\n",
        "            #pred=model(x)\n",
        "            #print(torch.round(pred.flatten()),y)\n",
        "            test_loss += loss_fn(pred.flatten(), y).item()\n",
        "            ncorrect = (torch.round(pred.flatten()) == y).sum().item()\n",
        "            #print(ncorrect)\n",
        "            correct += ncorrect\n",
        "\n",
        "    #print(correct,size)\n",
        "    #print(f\"Test Error: \\n Accuracy: {(100*correct/size):>0.1f}%, Avg loss: {100*test_loss/size:>8f} \\n\")\n",
        "    return 100*correct/size\n",
        "\n",
        "#keras_model=Sequential([InputLayer(input_shape=(maxlen,),batch_size=bsize),\n",
        "#                        Embedding(len(vect.vocabulary_),16),\n",
        "#                  Flatten(),\n",
        "#                  Dense(1,activation=\"sigmoid\")])\n",
        "keras_model=Sequential([InputLayer(shape=(maxlen,),batch_size=bsize),\n",
        "                        Embedding(len(word2vec_model),embed_dim),\n",
        "                        LSTM(20,return_sequences=True),\n",
        "                  Flatten(),\n",
        "                  Dense(1,activation=\"sigmoid\")])\n",
        "keras_model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "keras_model.summary()\n",
        "\n",
        "use_torch=True\n",
        "\n",
        "x=np.arange(epochs)\n",
        "y=np.zeros(epochs)\n",
        "#print(corpus_vec[0])\n",
        "if use_torch==True:\n",
        "    for epoch in range(epochs):\n",
        "        train(train_dataloader,c,loss_fn,optimizer)\n",
        "        y[epoch] = test_loop(test_dataloader,c,loss_fn)\n",
        "    plt.plot(x,y)\n",
        "    plt.show()\n",
        "    print(f\"Final accuracy: {y[-1]:.2f}, best accuracy: {y[np.argmax(y)]:.2f}\")\n",
        "else:\n",
        "    keras_model.fit(train_corpus_vec,train_label,batch_size=bsize,epochs=epochs,validation_data=(test_corpus_vec,test_label))\n",
        "    keras_model.evaluate(test_corpus_vec,test_label,batch_size=bsize)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "cy5ekCL0mHOK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "outputId": "6e7936cf-ae69-44cc-83d3-b362ec70f1d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              },
              "id": "caaec4ead7d7420cabe39cb563415b7e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vx6v266o_lK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(word2vec_model))\n",
        "word2vec_model[\"horse\"]"
      ],
      "metadata": {
        "id": "0EdHfJkrFBpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a61279-c917-4845-f223-6b7729de06f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.34057617e-04,  3.11279297e-02,  5.03540039e-03, -9.17968750e-02,\n",
              "       -8.36181641e-03, -1.66015625e-01,  3.93066406e-02,  2.97851562e-02,\n",
              "        1.69921875e-01, -2.04101562e-01,  2.41210938e-01, -3.04687500e-01,\n",
              "       -2.24609375e-02, -3.71093750e-01, -5.61523438e-02,  1.51367188e-01,\n",
              "       -1.21582031e-01,  3.41796875e-01,  3.05175781e-02, -2.94921875e-01,\n",
              "        6.54296875e-02, -9.27734375e-02,  1.49414062e-01,  8.15429688e-02,\n",
              "       -6.93359375e-02,  1.98242188e-01, -1.66015625e-01,  2.00195312e-01,\n",
              "        1.16699219e-01, -3.69140625e-01, -2.48046875e-01,  1.25976562e-01,\n",
              "        3.59375000e-01,  1.51367188e-01, -7.76367188e-02,  2.91015625e-01,\n",
              "       -1.74560547e-02, -1.21093750e-01, -1.00097656e-01,  1.43554688e-01,\n",
              "        5.92041016e-03,  2.35595703e-02,  3.20312500e-01,  1.82617188e-01,\n",
              "        9.52148438e-02,  9.22851562e-02,  8.30078125e-02, -1.33789062e-01,\n",
              "        9.57031250e-02,  1.66992188e-01,  1.87988281e-02, -2.79541016e-02,\n",
              "       -1.03149414e-02,  1.11816406e-01, -8.10546875e-02,  1.79687500e-01,\n",
              "        8.34960938e-02, -5.90820312e-02,  1.70898438e-01,  1.68457031e-02,\n",
              "        8.74023438e-02,  9.03320312e-02,  9.22851562e-02, -9.76562500e-02,\n",
              "       -2.39257812e-02, -2.07031250e-01, -1.21459961e-02,  1.44531250e-01,\n",
              "        6.20117188e-02, -1.44042969e-02,  2.81250000e-01,  6.83593750e-02,\n",
              "       -2.12890625e-01,  4.68750000e-02, -1.00097656e-01, -1.35742188e-01,\n",
              "        7.47070312e-02, -2.69531250e-01,  7.56835938e-02, -5.51757812e-02,\n",
              "       -2.01416016e-02, -3.80859375e-01,  1.67968750e-01, -3.90625000e-01,\n",
              "        5.54199219e-02,  2.23632812e-01, -6.28662109e-03,  7.76367188e-02,\n",
              "        2.03125000e-01, -1.04980469e-01, -3.12500000e-02,  3.53515625e-01,\n",
              "        1.54296875e-01, -1.25976562e-01, -2.24609375e-02, -3.80859375e-01,\n",
              "        3.12500000e-01,  2.12890625e-01,  1.97265625e-01, -4.49218750e-01,\n",
              "       -9.22851562e-02, -2.94921875e-01,  2.21679688e-01, -2.58789062e-02,\n",
              "        1.38671875e-01,  7.37304688e-02, -1.10839844e-01, -3.00781250e-01,\n",
              "        1.29882812e-01, -1.74804688e-01,  1.37939453e-02,  7.51953125e-02,\n",
              "        2.98828125e-01, -7.61718750e-02,  9.76562500e-02, -2.53906250e-01,\n",
              "       -8.69140625e-02, -9.86328125e-02, -4.49218750e-02,  1.00585938e-01,\n",
              "       -1.68945312e-01,  1.06933594e-01, -1.07910156e-01, -3.57421875e-01,\n",
              "       -3.58886719e-02, -3.24707031e-02,  1.62109375e-01, -1.17187500e-01,\n",
              "       -1.49414062e-01,  2.31933594e-02, -4.14062500e-01,  2.85644531e-02,\n",
              "       -2.57812500e-01, -6.59179688e-02, -4.80957031e-02, -1.87500000e-01,\n",
              "        5.10253906e-02,  7.86132812e-02, -7.56835938e-02,  3.20312500e-01,\n",
              "        7.08007812e-02, -1.08886719e-01, -3.03955078e-02,  1.53320312e-01,\n",
              "        8.93554688e-02,  8.83789062e-02, -2.01416016e-02, -1.66992188e-01,\n",
              "       -8.88671875e-02,  7.20214844e-03,  4.88281250e-01,  7.66601562e-02,\n",
              "        6.68945312e-02, -4.34570312e-02, -2.41210938e-01, -9.71679688e-02,\n",
              "        7.47070312e-02, -3.24218750e-01, -3.14453125e-01, -8.74023438e-02,\n",
              "       -8.20312500e-02,  2.33154297e-02,  2.55859375e-01, -1.06445312e-01,\n",
              "        1.13769531e-01, -4.71191406e-02, -4.83398438e-02, -4.31640625e-01,\n",
              "        3.41796875e-02,  1.66015625e-02, -6.00585938e-02, -1.82617188e-01,\n",
              "       -3.56445312e-02, -8.59375000e-02, -5.88378906e-02,  1.19628906e-01,\n",
              "        1.33789062e-01, -3.73535156e-02, -1.79687500e-01,  8.59375000e-02,\n",
              "       -2.63671875e-01, -3.36914062e-02, -2.22167969e-02,  9.52148438e-02,\n",
              "        1.05468750e-01, -1.63085938e-01,  2.65625000e-01,  1.77734375e-01,\n",
              "       -2.37304688e-01,  1.58203125e-01, -4.00390625e-02, -5.71289062e-02,\n",
              "        1.51367188e-01,  1.52343750e-01,  2.71484375e-01, -2.13867188e-01,\n",
              "        1.81884766e-02, -4.98046875e-02, -2.65625000e-01, -1.05468750e-01,\n",
              "        4.98046875e-02, -5.54687500e-01, -2.91015625e-01, -9.61914062e-02,\n",
              "       -9.52148438e-02, -4.17480469e-02, -2.57812500e-01, -6.25000000e-02,\n",
              "        9.37500000e-02, -2.09960938e-02, -2.48046875e-01,  4.51660156e-02,\n",
              "        1.56250000e-01, -1.74804688e-01, -1.37695312e-01,  1.54296875e-01,\n",
              "       -3.94531250e-01, -1.66992188e-01,  2.07031250e-01,  1.55273438e-01,\n",
              "        2.08984375e-01,  2.69531250e-01,  3.26171875e-01, -1.24023438e-01,\n",
              "        1.64794922e-02, -5.05371094e-02,  3.10546875e-01, -3.24707031e-02,\n",
              "        3.41796875e-01, -9.96093750e-02,  4.15039062e-02, -3.06640625e-01,\n",
              "        4.83398438e-02,  2.08007812e-01, -4.10156250e-01, -7.22656250e-02,\n",
              "        1.09863281e-01, -2.67578125e-01,  2.28515625e-01, -1.02050781e-01,\n",
              "        1.83593750e-01, -2.44140625e-01,  2.21679688e-01,  2.01171875e-01,\n",
              "        3.10546875e-01, -2.14843750e-01, -3.41796875e-02,  2.57812500e-01,\n",
              "        2.53906250e-02,  7.66601562e-02, -1.18164062e-01,  2.41210938e-01,\n",
              "       -9.61914062e-02, -1.16699219e-01, -8.34960938e-02,  2.37304688e-01,\n",
              "       -1.10839844e-01,  6.73828125e-02, -4.35546875e-01, -3.32641602e-03,\n",
              "       -1.27929688e-01, -6.53076172e-03,  2.72216797e-02,  2.83203125e-01,\n",
              "       -4.19921875e-02,  8.00781250e-02,  1.12792969e-01, -2.73437500e-01,\n",
              "       -2.63671875e-01,  2.04101562e-01, -8.54492188e-02,  1.91497803e-03,\n",
              "       -2.04101562e-01,  6.83593750e-02, -6.54296875e-02, -1.35742188e-01,\n",
              "       -2.57568359e-02, -3.96484375e-01, -2.94189453e-02,  4.33593750e-01,\n",
              "        6.03027344e-02,  3.41796875e-03,  1.74804688e-01,  6.44531250e-02,\n",
              "       -3.97949219e-02, -7.32421875e-02, -1.50390625e-01,  2.56347656e-02,\n",
              "        2.91015625e-01,  2.61718750e-01, -2.32421875e-01,  1.13769531e-01,\n",
              "       -2.53906250e-01,  1.75781250e-01,  1.89453125e-01,  2.65625000e-01,\n",
              "        1.66015625e-01,  2.85156250e-01, -1.63085938e-01,  6.07910156e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Md7zxWTk9AhSbKVVPH3m-w-W4QP5_WDX",
      "authorship_tag": "ABX9TyPaGHkwWwRlqcBkSExjWvbr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}